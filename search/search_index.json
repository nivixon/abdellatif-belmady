{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"About Me","text":"Abdellatif BELMADY Morocco, Casablanca Data Scientist  Buy Me a Coffee Export Resume About Me <p>Hey! I\u2019m Abdellatif BELMADY, I graduated from Ecole Centrale Casablanca with a degree in data science and digitalization. My professional philosophy is \"Structuring and analyzing data allows me to build the story behind it in order to improve the future\".</p>  Experience - <p>CEO and Founder - Other Ways2022-PresentThe third eye that you need</p> <p>Currently, the possession and installation of cameras are indispensable in large organizations and in any sector. But despite their usefulness,these cameras still work in a traditional way in front of the evolution of the digital and intelligent world. Our solutions opt for intelligent cameras that integrate new technologies. Having smart cameras brings many advantages to your work and your business.       </p> <p>Machine Learning Intern20226 PERFORM \u00b7 Internship</p> <ul> <li>Images collection(using the Imageye extention).          <li>Image annotation with labelImg.exe.          <li>Training of Deep Learning models using the YOLO version 4 algorithm.          <li>Detection and recognition of surgical instruments.          <li>Detection of mask wearing.          <li>Detection of medical caps.          <li>Detection of gowns.          <li>Writing of scripts in Python.          </li> <p>Internship Operator2021VCR-Sodalmu, Berrechid</p> <ul> <li>Realization of an Excel application for inventory management.          <li>Implementation of a machine learning model to identify a waste problem in the production line.          <li>Development in knowing how to ask the right questions in order to get the requested data.          </li>  Education - <p>Data Science and digitalization2020-PresentEcole Centrale Casablanca</p><p> </p> <p>Physics Chemistry Engineering Science2018-2020Preparatory Classes Errazi, El Jadida</p>  Honors &amp; Awards - <p> Centrale Coding Competition, Ecole Centrale Casablanca, 2nd Place. (November 2021)       </p> <p>  Where I'm Located -  Community Involvement - <p> The Enactus association at Ecole Centrale Casablanca, Active member (Aug 2020 - Jan 2021)       </p> <p> The Rotaract Association at Ecole Centrale Casablanca Community member, student &amp; volunteer. (Aug 2020 - July 2021)       </p> <p> The association CentraleComm' at the Ecole Centrale Casablanca Community member, student &amp; volunteer. (Aug 2020 - July 2021)       </p> <p> @abdellatifbelmady On  Instagram -  What I'm Listening To - <p>"},{"location":"books/not%20yet/","title":"Books","text":""},{"location":"books/Hands%20on%20machine%20learning/Neural%20Networks%20and%20Deep%20Learning/4.1.%20Introduction%20to%20Artificial%20Neural%20Networks%20with%20Keras/","title":"Introduction to Artificial Neural Networks with Keras","text":""},{"location":"books/Hands%20on%20machine%20learning/Neural%20Networks%20and%20Deep%20Learning/4.2.%20Training%20Deep%20Neural%20Networks/","title":"Training Deep Neural Networks","text":""},{"location":"books/Hands%20on%20machine%20learning/Neural%20Networks%20and%20Deep%20Learning/4.3.%20Custom%20Models%20and%20Training%20with%20TensorFlow/","title":"Custom Models and Training with TensorFlow","text":""},{"location":"books/Hands%20on%20machine%20learning/Neural%20Networks%20and%20Deep%20Learning/4.4.%20Loading%20and%20Preprocessing%20Data%20with%20TensorFlow/","title":"Custom Models and Training with TensorFlow","text":""},{"location":"books/Hands%20on%20machine%20learning/Neural%20Networks%20and%20Deep%20Learning/4.5.%20Deep%20Computer%20Vision%20Using%20Convolutional%20Neural%20Networks/","title":"Deep Computer Vision Using Convolutional Neural Networks","text":""},{"location":"books/Hands%20on%20machine%20learning/Preface/2.1.%20The%20Machine%20Learning%20Tsunami/","title":"The Machine Learning Tsunami","text":"<p>In 2006, Geoffrey Hinton et al. published a paper 1 showing how to train a deep neural network capable of recognizing handwritten digits with state-of-the-art precision (&gt;98%). They branded this technique \u201cDeep Learning.\u201d Training a deep neural net was widely considered impossible at the time,2 and most researchers had abandoned the idea since the 1990s. This paper revived the interest of the scientific community and before long many new papers demonstrated that Deep Learning was not only possible, but capable of mind-blowing achievements that no other Machine Learning (ML) technique could hope to match (with the help of tremendous computing power and great amounts of data). This enthusiasm soon extended to many other areas of Machine Learning.</p> <p>Fast-forward 10 years and Machine Learning has conquered the industry: it is now at the heart of much of the magic in today\u2019s high-tech products, ranking your web search results, powering your smartphone\u2019s speech recognition, recommending videos, and beating the world champion at the game of Go. Before you know it, it will be driving your car.</p> <ol> <li> <p>Available on Hinton\u2019s home page at http://www.cs.toronto.edu/~hinton/.\u00a0\u21a9</p> </li> <li> <p>Despite the fact that Yann Lecun\u2019s deep convolutional neural networks had worked well for image recognition since the 1990s, although they were not as general purpose.\u00a0\u21a9</p> </li> </ol>"},{"location":"books/Hands%20on%20machine%20learning/Preface/2.2.%20Machine%20Learning%20in%20Your%20Projects/","title":"Machine Learning in Your Projects","text":"<p>So naturally you are excited about Machine Learning and you would love to join the party!</p> <p>Perhaps you would like to give your homemade robot a brain of its own? Make it recognize faces? Or learn to walk around?</p> <p>Or maybe your company has tons of data (user logs, financial data, production data, machine sensor data, hotline stats, HR reports, etc.), and more than likely you could unearth some hidden gems if you just knew where to look; for example:</p> <ul> <li> <p>Segment customers and find the best marketing strategy for each group</p> </li> <li> <p>Recommend products for each client based on what similar clients bought</p> </li> <li> <p>Detect which transactions are likely to be fraudulent</p> </li> <li> <p>Forecast next year\u2019s revenue</p> </li> <li> <p>And more</p> </li> </ul> <p>Whatever the reason, you have decided to learn Machine Learning and implement it in your projects. Great idea!</p>"},{"location":"books/Hands%20on%20machine%20learning/Preface/2.3.%20Objective%20and%20Approach/","title":"Objective and Approach","text":"<p>This book assumes that you know close to nothing about Machine Learning. Its goal is to give you the concepts, the intuitions, and the tools you need to actually implement programs capable of learning from data.</p> <p>We will cover a large number of techniques, from the simplest and most commonly used (such as linear regression) to some of the Deep Learning techniques that regularly win competitions.</p> <p>Rather than implementing our own toy versions of each algorithm, we will be using actual production-ready Python frameworks:</p> <ul> <li> <p>Scikit-Learn is very easy to use, yet it implements many Machine Learning algorithms efficiently, so it makes for a great entry point to learn Machine Learning.</p> </li> <li> <p>TensorFlow is a more complex library for distributed numerical computation. It makes it possible to train and run very large neural networks efficiently by distributing the computations across potentially hundreds of multi-GPU servers. TensorFlow was created at Google and supports many of their large-scale Machine Learning applications. It was open sourced in November 2015.</p> </li> <li> <p>Keras is a high level Deep Learning API that makes it very simple to train and run neural networks. It can run on top of either TensorFlow, Theano or Microsoft Cognitive Toolkit (formerly known as CNTK). TensorFlow comes with its own implementation of this API, called tf.keras, which provides support for some advanced TensorFlow features (e.g., to efficiently load data).</p> </li> </ul> <p>The book favors a hands-on approach, growing an intuitive understanding of Machine Learning through concrete working examples and just a little bit of theory. While you can read this book without picking up your laptop, we highly recommend you experiment with the code examples available online as Jupyter notebooks at https://github.com/ageron/handson-ml2.</p>"},{"location":"books/Hands%20on%20machine%20learning/Preface/2.4.%20Prerequisites/","title":"Prerequisites","text":"<p>This book assumes that you have some Python programming experience and that you are familiar with Python\u2019s main scientific libraries, in particular NumPy, Pandas, and Matplotlib.</p> <p>Also, if you care about what\u2019s under the hood you should have a reasonable understanding of college-level math as well (calculus, linear algebra, probabilities, and statistics).</p> <p>If you don\u2019t know Python yet, http://learnpython.org/ is a great place to start. The official tutorial on python.org is also quite good.</p> <p>If you have never used Jupyter, Chapter 2 will guide you through installation and the basics: it is a great tool to have in your toolbox.</p> <p>If you are not familiar with Python\u2019s scientific libraries, the provided Jupyter notebooks include a few tutorials. There is also a quick math tutorial for linear algebra.</p>"},{"location":"books/Hands%20on%20machine%20learning/Preface/2.5.%20Roadmap/","title":"Roadmap","text":"<p>This book is organized in two parts. The Fundamentals of Machine Learning, covers the following topics:</p> <ul> <li> <p>What is Machine Learning? What problems does it try to solve? What are the main categories and fundamental concepts of Machine Learning systems?</p> </li> <li> <p>The main steps in a typical Machine Learning project.</p> </li> <li> <p>Learning by fitting a model to data.</p> </li> <li> <p>Optimizing a cost function.</p> </li> <li> <p>Handling, cleaning, and preparing data.</p> </li> <li> <p>Selecting and engineering features.</p> </li> <li> <p>The main challenges of Machine Learning, in particular underfitting and overfitting (the bias/variance tradeoff).</p> </li> <li> <p>Reducing the dimensionality of the training data to fight the curse of dimensionality.</p> </li> <li> <p>Other unsupervised learning techniques, including clustering, density estimation and anomaly detection.</p> </li> <li> <p>The most common learning algorithms: Linear and Polynomial Regression, Logistic Regression, k-Nearest Neighbors, Support Vector Machines, Decision Trees, Random Forests, and Ensemble methods.</p> </li> </ul> <p>Neural Networks and Deep Learning, covers the following topics:</p> <ul> <li> <p>What are neural nets? What are they good for?</p> </li> <li> <p>The most important neural net architectures: feedforward neural nets, convolutional nets, recurrent nets, long short-term memory (LSTM) nets, autoencoders and generative adversarial networks (GANs).</p> </li> <li> <p>Techniques for training deep neural nets.</p> </li> <li> <p>Scaling neural networks for large datasets.</p> </li> <li> <p>Learning strategies with Reinforcement Learning.</p> </li> <li> <p>Handling uncertainty with Bayesian Deep Learning.</p> </li> </ul> <p>The first part is based mostly on Scikit-Learn while the second part uses TensorFlow and Keras.</p> <p>Warning</p> <p>Don\u2019t jump into deep waters too hastily: while Deep Learning is no doubt one of the most exciting areas in Machine Learning, you should master the fundamentals first. Moreover, most problems can be solved quite well using simpler techniques such as Random Forests and Ensemble methods (discussed in The Fundamentals of Machine Learning). Deep Learning is best suited for complex problems such as image recognition, speech recognition, or natural language processing, provided you have enough data, computing power, and patience.</p>"},{"location":"books/Hands%20on%20machine%20learning/Preface/2.6.%20Other%20Resources/","title":"Other Resources","text":"<p>Many resources are available to learn about Machine Learning. Andrew Ng\u2019s ML course on Coursera and Geoffrey Hinton\u2019s course on neural networks and Deep Learning are amazing, although they both require a significant time investment (think months).</p> <p>There are also many interesting websites about Machine Learning, including of course Scikit-Learn\u2019s exceptional User Guide. You may also enjoy Dataquest, which provides very nice interactive tutorials, and ML blogs such as those listed on Quora. Finally, the Deep Learning website has a good list of resources to learn more.</p> <p>Of course there are also many other introductory books about Machine Learning, in particular:</p> <ul> <li> <p>Joel Grus, Data Science from Scratch (O\u2019Reilly). This book presents the fundamentals of Machine Learning, and implements some of the main algorithms in pure Python (from scratch, as the name suggests).</p> </li> <li> <p>Stephen Marsland, Machine Learning: An Algorithmic Perspective (Chapman and Hall). This book is a great introduction to Machine Learning, covering a wide range of topics in depth, with code examples in Python (also from scratch, but using NumPy).</p> </li> <li> <p>Sebastian Raschka, Python Machine Learning (Packt Publishing). Also a great introduction to Machine Learning, this book leverages Python open source libra\u2010 ries (Pylearn 2 and Theano).</p> </li> <li> <p>Fran\u00e7ois Chollet, Deep Learning with Python (Manning). A very practical book that covers a large range of topics in a clear and concise way, as you might expect from the author of the excellent Keras library. It favors code examples over math\u2010 ematical theory.</p> </li> <li> <p>Yaser S. Abu-Mostafa, Malik Magdon-Ismail, and Hsuan-Tien Lin, Learning from Data (AMLBook). A rather theoretical approach to ML, this book provides deep insights, in particular on the bias/variance tradeoff (see Training Models).</p> </li> <li> <p>Stuart Russell and Peter Norvig, Artificial Intelligence: A Modern Approach, 3rd Edition (Pearson). This is a great (and huge) book covering an incredible amount of topics, including Machine Learning. It helps put ML into perspective.</p> </li> </ul> <p>Finally, a great way to learn is to join ML competition websites such as Kaggle.com this will allow you to practice your skills on real-world problems, with help and insights from some of the best ML professionals out there.</p>"},{"location":"books/Hands%20on%20machine%20learning/Preface/2.7.%20Conventions%20Used%20in%20This%20Book/","title":"Conventions Used in This Book","text":"<p>The following typographical conventions are used in this book: Italic     Indicates new terms, URLs, email addresses, filenames, and file extensions. Constant width     Used for program listings, as well as within paragraphs to refer to program elements such as variable or function names, databases, data types, environment variables, statements and keywords. Constant width bold     Shows commands or other text that should be typed literally by the user. Constant width italic     Shows text that should be replaced with user-supplied values or by values determined by context.</p> <p>Tip</p> <p>This element signifies a tip or suggestion.</p> <p>Note</p> <p>This element signifies a general note.</p> <p>Warning</p> <p>This element indicates a warning or caution.</p>"},{"location":"books/Hands%20on%20machine%20learning/Preface/2.8.%20Code%20Examples/","title":"Code Examples","text":"<p>Supplemental material (code examples, exercises, etc.) is available for download at https://github.com/ageron/handson-ml2. It is mostly composed of Jupyter notebooks.</p> <p>Some of the code examples in the book leave out some repetitive sections, or details that are obvious or unrelated to Machine Learning. This keeps the focus on the important parts of the code, and it saves space to cover more topics. However, if you want the full code examples, they are all available in the Jupyter notebooks.</p> <p>Note that when the code examples display some outputs, then these code examples are shown with Python prompts (&gt;&gt;&gt; and \u2026), as in a Python shell, to clearly distinguish the code from the outputs. For example, this code defines the square() function then it computes and displays the square of 3:</p> <p><pre><code>def square(x):\nreturn x ** 2\n...\nresult = square(3)\nresult\n</code></pre> 9</p> <p>When code does not display anything, prompts are not used. However, the result may sometimes be shown as a comment like this:</p> <pre><code>def square(x):\nreturn x ** 2\nresult = square(3)\nresult # result is 9\n</code></pre>"},{"location":"books/Hands%20on%20machine%20learning/Preface/2.9.%20Using%20Code%20Examples/","title":"Using Code Examples","text":"<p>This book is here to help you get your job done. In general, if example code is offered with this book, you may use it in your programs and documentation. You do not need to contact us for permission unless you\u2019re reproducing a significant portion of the code. For example, writing a program that uses several chunks of code from this book does not require permission. Selling or distributing a CD-ROM of examples from O\u2019Reilly books does require permission. Answering a question by citing this book and quoting example code does not require permission. Incorporating a significant amount of example code from this book into your product\u2019s documentation does require permission.</p> <p>We appreciate, but do not require, attribution. An attribution usually includes the title, author, publisher, and ISBN. For example: \u201cHands-On Machine Learning with Scikit-Learn, Keras and TensorFlow by Aur\u00e9lien G\u00e9ron (O\u2019Reilly). Copyright 2019 Aur\u00e9lien G\u00e9ron, 978-1-492-03264-9.\u201d If you feel your use of code examples falls outside fair use or the permission given above, feel free to contact us at permissions@oreilly.com.</p>"},{"location":"books/Hands%20on%20machine%20learning/Preface/3.1.%20%20O%E2%80%99Reilly%20Safari/","title":"O\u2019Reilly Safari","text":"<p>Safari (formerly Safari Books Online) is a membership-based training and reference platform for enterprise, government, educators, and individuals.</p> <p>Members have access to thousands of books, training videos, Learning Paths, interactive tutorials, and curated playlists from over 250 publishers, including O\u2019Reilly Media, Harvard Business Review, Prentice Hall Professional, Addison-Wesley Professional, Microsoft Press, Sams, Que, Peachpit Press, Adobe, Focal Press, Cisco Press, John Wiley &amp; Sons, Syngress, Morgan Kaufmann, IBM Redbooks, Packt, Adobe Press, FT Press, Apress, Manning, New Riders, McGraw-Hill, Jones &amp; Bartlett, and Course Technology, among others.</p> <p>For more information, please visit http://oreilly.com/safari.</p>"},{"location":"books/Hands%20on%20machine%20learning/Preface/3.2.%20How%20to%20Contact%20Us/","title":"How to Contact Us","text":"Please address comments and questions concerning this book to the publisher: <p>O\u2019Reilly Media, Inc.</p> <p>1005 Gravenstein Highway North</p> <p>Sebastopol, CA 95472</p> <p>800-998-9938 (in the United States or Canada)</p> <p>707-829-0515 (international or local)</p> <p>707-829-0104 (fax)</p> <p>We have a web page for this book, where we list errata, examples, and any additional information. You can access this page at http://bit.ly/hands-on-machine-learning-with-scikit-learn-and-tensorflow or https://homl.info/oreilly.</p> <p>To comment or ask technical questions about this book, send email to bookques\u2010tions@oreilly.com.</p> <p>For more information about our books, courses, conferences, and news, see our website at http://www.oreilly.com.</p> <p>Find us on Facebook: http://facebook.com/oreilly</p> <p>Follow us on Twitter: http://twitter.com/oreillymedia</p> <p>Watch us on YouTube: http://www.youtube.com/oreillymedia</p>"},{"location":"books/Hands%20on%20machine%20learning/Preface/3.3.%20Changes%20in%20the%20Second%20Edition/","title":"Changes in the Second Edition","text":"<p>This second edition has five main objectives:</p> <ol> <li> <p>Cover additional topics: additional unsupervised learning techniques (including clustering, anomaly detection, density estimation and mixture models), additional techniques for training deep nets (including self-normalized networks), additional computer vision techniques (including the Xception, SENet, object detection with YOLO, and semantic segmentation using R-CNN), handling sequences using CNNs (including WaveNet), natural language processing using RNNs, CNNs and Transformers, generative adversarial networks, deploying TensorFlow models, and more.</p> </li> <li> <p>Update the book to mention some of the latest results from Deep Learning research.</p> </li> <li> <p>Migrate all TensorFlow chapters to TensorFlow 2, and use TensorFlow\u2019s implementation of the Keras API (called tf.keras) whenever possible, to simplify the code examples.</p> </li> <li> <p>Update the code examples to use the latest version of Scikit-Learn, NumPy, Pandas, Matplotlib and other libraries.</p> </li> <li> <p>Clarify some sections and fix some errors, thanks to plenty of great feedback from readers.</p> </li> </ol> <p>Some chapters were added, others were rewritten and a few were reordered. Table P-1 shows the mapping between the 1st edition chapters and the 2nd edition chapters:</p> <p>Table P-1. Chapter mapping between 1st and 2nd edition</p> 1st Ed.chapter 2nd Ed.chapter % Changes 2nd Ed.chapter 1 1 &lt;10% The Machine Learning Landscape 2 2 &lt;10% End-to-End Machine Learning Project 3 3 &lt;10% Classification 4 4 &lt;10% Training Models 5 5 &lt;10% Support Vector Machines 6 6 &lt;10% Decision Trees 7 7 &lt;10% Ensemble Learning and Random Forests 8 8 &lt;10% Dimensionality Reduction N/A 9 100% new Unsupervised Learning Techniques 10 10 ~75% Introduction to Artificial Neural Networks with Keras 11 11 ~50% Training Deep Neural Networks 9 12 100% rewritten Custom Models and Training with TensorFlow Part of 12 13 100% rewritten Loading and Preprocessing Data with TensorFlow 13 14 ~50% Deep Computer Vision Using Convolutional Neural Networks Part of 14 15 ~75% Processing Sequences Using RNNs and CNNs Part of 14 16 ~90% Natural Language Processing with RNNs and Attention 15 17 ~75% Autoencoders and GANs 16 18 ~75% Reinforcement Learning Part of 12 19 100% rewritten Deploying your TensorFlow Models <p>More specifically, here are the main changes for each 2nd edition chapter (other than clarifications, corrections and code updates):</p> <ul> <li> <p>Chapter 1</p> <ul> <li>Added a section on handling mismatch between the training set and the validation &amp; test sets.</li> </ul> </li> <li> <p>Chapter 2</p> <ul> <li>Added how to compute a confidence interval.</li> <li>Improved the installation instructions (e.g., for Windows).</li> <li>Introduced the upgraded OneHotEncoder and the new ColumnTransformer.</li> </ul> </li> <li> <p>Chapter 4</p> <ul> <li>Explained the need for training instances to be Independent and Identically Distributed (IID).</li> </ul> </li> <li> <p>Chapter 7</p> <ul> <li>Added a short section about XGBoost.</li> </ul> </li> <li> <p>Chapter 9 \u2013 new chapter including:</p> <ul> <li>Clustering with K-Means, how to choose the number of clusters, how to use it for dimensionality reduction, semi-supervised learning, image segmentation, and more.</li> <li>Gaussian mixture models, the Expectation-Maximization (EM) algorithm, Bayesian variational inference, and how mixture models can be used for clustering, density estimation, anomaly detection and novelty detection.</li> <li>Overview of other anomaly detection and novelty detection algorithms.</li> </ul> </li> <li> <p>Chapter 10 (mostly new)</p> <ul> <li>Added an introduction to the Keras API, including all its APIs (Sequential, Functional and Subclassing), persistence and callbacks (including the Tensor Board callback).</li> </ul> </li> <li> <p>Chapter 11 (many changes)</p> <ul> <li>Introduced self-normalizing nets, the SELU activation function and Alpha Dropout.</li> <li>Introduced self-supervised learning.</li> <li>Added Nadam optimization.</li> <li>Added Monte-Carlo Dropout.</li> <li>Added a note about the risks of adaptive optimization methods.</li> <li>Updated the practical guidelines.</li> </ul> </li> <li> <p>Chapter 12 \u2013 completely rewritten chapter, including:</p> <ul> <li>A tour of TensorFlow 2</li> <li>TensorFlow\u2019s lower-level Python API</li> <li>Writing custom loss functions, metrics, layers, models</li> <li>Using auto-differentiation and creating custom training algorithms.</li> <li>TensorFlow Functions and graphs (including tracing and autograph).</li> </ul> </li> <li> <p>Chapter 13 \u2013 new chapter, including:</p> <ul> <li>The Data API</li> <li>Loading/Storing data efficiently using TFRecords</li> <li>The Features API (including an introduction to embeddings).</li> <li>An overview of TF Transform and TF Datasets</li> <li>Moved the low-level implementation of the neural network to the exercises.</li> <li>Removed details about queues and readers that are now superseded by the Data API.</li> </ul> </li> <li> <p>Chapter 14</p> <ul> <li>Added Xception and SENet architectures.</li> <li>Added a Keras implementation of ResNet-34.</li> <li>Showed how to use pretrained models using Keras.</li> <li>Added an end-to-end transfer learning example.</li> <li>Added classification and localization.</li> <li>Introduced Fully Convolutional Networks (FCNs).</li> <li>Introduced object detection using the YOLO architecture.</li> <li>Introduced semantic segmentation using R-CNN.</li> </ul> </li> <li> <p>Chapter 15</p> <ul> <li>Added an introduction to Wavenet.</li> <li>Moved the Encoder\u2013Decoder architecture and Bidirectional RNNs to Chapter 16.</li> </ul> </li> <li> <p>Chapter 16</p> <ul> <li>Explained how to use the Data API to handle sequential data.</li> <li>Showed an end-to-end example of text generation using a Character RNN, using both a stateless and a stateful RNN.</li> <li>Showed an end-to-end example of sentiment analysis using an LSTM.</li> <li>Explained masking in Keras.</li> <li>Showed how to reuse pretrained embeddings using TF Hub.</li> <li>Showed how to build an Encoder\u2013Decoder for Neural Machine Translation using TensorFlow Addons/seq2seq.</li> <li>Introduced beam search.</li> <li>Explained attention mechanisms.</li> <li>Added a short overview of visual attention and a note on explainability.</li> <li>Introduced the fully attention-based Transformer architecture, including positional embeddings and multi-head attention.</li> <li>Added an overview of recent language models (2018).</li> </ul> </li> <li> <p>Chapters 17, 18 and 19: coming soon.</p> </li> </ul>"},{"location":"books/Hands%20on%20machine%20learning/Preface/3.4.%20Acknowledgments/","title":"Acknowledgments","text":"<p>Never in my wildest dreams did I imagine that the first edition of this book would get such a large audience. I received so many messages from readers, many asking questions, some kindly pointing out errata, and most sending me encouraging words. I cannot express how grateful I am to all these readers for their tremendous support. Thank you all so very much! Please do not hesitate to file issues on github if you find errors in the code examples (or just to ask questions), or to submit errata if you find errors in the text. Some readers also shared how this book helped them get their first job, or how it helped them solve a concrete problem they were working on: I find such feedback incredibly motivating. If you find this book helpful, I would love it if you could share your story with me, either privately (e.g., via LinkedIn) or publicly (e.g., in an Amazon review).</p> <p>I am also incredibly thankful to all the amazing people who took time out of their busy lives to review my book with such care. In particular, I would like to thank Fran\u00e7ois Chollet for reviewing all the chapters based on Keras &amp; TensorFlow, and giving me some great, in-depth feedback. Since Keras is one of the main additions to this 2nd edition, having its author review the book was invaluable. I highly recommend Fran\u00e7ois\u2019s excellent book Deep Learning with Python1: it has the conciseness, clarity and depth of the Keras library itself. Big thanks as well to Ankur Patel, who reviewed every chapter of this 2nd edition and gave me excellent feedback.</p> <p>This book also benefited from plenty of help from members of the TensorFlow team, in particular Martin Wicke, who tirelessly answered dozens of my questions and dispatched the rest to the right people, including Alexandre Passos, Allen Lavoie, Andr\u00e9 Susano Pinto, Anna Revinskaya, Anthony Platanios, Clemens Mewald, Dan Moldo\u2010van, Daniel Dobson, Dustin Tran, Edd Wilder-James, Goldie Gadde, Jiri Simsa, Karmel Allison, Nick Felt, Paige Bailey, Pete Warden (who also reviewed the 1st edition), Ryan Sepassi, Sandeep Gupta, Sean Morgan, Todd Wang, Tom O\u2019Malley, William Chargin, and Yuefeng Zhou, all of whom were tremendously helpful. A huge thank you to all of you, and to all other members of the TensorFlow team. Not just for your help, but also for making such a great library.</p> <p>Big thanks to Haesun Park, who gave me plenty of excellent feedback and caught several errors while he was writing the Korean translation of the 1st edition of this book. He also translated the Jupyter notebooks to Korean, not to mention TensorFlow\u2019s documentation. I do not speak Korean, but judging by the quality of his feedback, all his translations must be truly excellent! Moreover, he kindly contributed some of the solutions to the exercises in this book.</p> <p>Many thanks as well to O\u2019Reilly\u2019s fantastic staff, in particular Nicole Tache, who gave me insightful feedback, always cheerful, encouraging, and helpful: I could not dream of a better editor. Big thanks to Michele Cronin as well, who was very helpful (and patient) at the start of this 2nd edition. Thanks to Marie Beaugureau, Ben Lorica, Mike Loukides, and Laurel Ruma for believing in this project and helping me define its scope. Thanks to Matt Hacker and all of the Atlas team for answering all my technical questions regarding formatting, asciidoc, and LaTeX, and thanks to Rachel Monaghan, Nick Adams, and all of the production team for their final review and their hundreds of corrections.</p> <p>I would also like to thank my former Google colleagues, in particular the YouTube video classification team, for teaching me so much about Machine Learning. I could never have started the first edition without them. Special thanks to my personal ML gurus: Cl\u00e9ment Courbet, Julien Dubois, Mathias Kende, Daniel Kitachewsky, James Pack, Alexander Pak, Anosh Raj, Vitor Sessak, Wiktor Tomczak, Ingrid von Glehn, Rich Washington, and everyone I worked with at YouTube and in the amazing Google research teams in Mountain View. All these people are just as nice and helpful as they are bright, and that\u2019s saying a lot.</p> <p>I will never forget the kind people who reviewed the 1st edition of this book, including David Andrzejewski, Eddy Hung, Gr\u00e9goire Mesnil, Iain Smears, Ingrid von Glehn, Justin Francis, Karim Matrah, Lukas Biewald, Michel Tessier, Salim S\u00e9maoune, Vincent Guilbeau and of course my dear brother Sylvain.</p> <p>Last but not least, I am infinitely grateful to my beloved wife, Emmanuelle, and to our three wonderful children, Alexandre, R\u00e9mi, and Gabrielle, for encouraging me to work hard on this book, as well as for their insatiable curiosity: explaining some of the most difficult concepts in this book to my wife and children helped me clarify my thoughts and directly improved many parts of this book. Plus, they keep bringing me cookies and coffee! What more can one dream of?</p> <ol> <li> <p>\u201cDeep Learning with Python,\u201d Fran\u00e7ois Chollet (2017).\u00a0\u21a9</p> </li> </ol>"},{"location":"books/Hands%20on%20machine%20learning/The%20Fundamentals%20of%20Machine%20Learning/3.1.%20The%20Machine%20Learning%20Landscape/","title":"The Machine Learning Landscape","text":"<p>Note</p> <p>With Early Release ebooks, you get books in their earliest form the author\u2019s raw and unedited content as he or she writes\u2014so you can take advantage of these technologies long before the official release of these titles. The following will be Chapter 1 in the final release of the book.</p> <p>When most people hear \u201cMachine Learning,\u201d they picture a robot: a dependable but\u2010ler or a deadly Terminator depending on who you ask. But Machine Learning is not just a futuristic fantasy, it\u2019s already here. In fact, it has been around for decades in some specialized applications, such as Optical Character Recognition (OCR). But the first ML application that really became mainstream, improving the lives of hundreds of millions of people, took over the world back in the 1990s: it was the spam filter. Not exactly a self-aware Skynet, but it does technically qualify as Machine Learning (it has actually learned so well that you seldom need to flag an email as spam anymore). It was followed by hundreds of ML applications that now quietly power hundreds of products and features that you use regularly, from better recommendations to voice search.</p> <p>Where does Machine Learning start and where does it end? What exactly does it mean for a machine to learn something? If I download a copy of Wikipedia, has my computer really \u201clearned\u201d something? Is it suddenly smarter? In this chapter we will start by clarifying what Machine Learning is and why you may want to use it.</p> <p>Then, before we set out to explore the Machine Learning continent, we will take a look at the map and learn about the main regions and the most notable landmarks: supervised versus unsupervised learning, online versus batch learning, instance-based versus model-based learning. Then we will look at the workflow of a typical ML project, discuss the main challenges you may face, and cover how to evaluate and fine-tune a Machine Learning system.</p> <p>his chapter introduces a lot of fundamental concepts (and jargon) that every data scientist should know by heart. It will be a high-level overview (the only chapter without much code), all rather simple, but you should make sure everything is crystal-clear to you before continuing to the rest of the book. So grab a coffee and let\u2019s get started!</p> <p>Tip</p> <p>If you already know all the Machine Learning basics, you may want to skip directly to End-to-End Machine Learning Project. If you are not sure, try to answer all the questions listed at the end of the chapter before moving on.</p>"},{"location":"books/Hands%20on%20machine%20learning/The%20Fundamentals%20of%20Machine%20Learning/3.1.%20The%20Machine%20Learning%20Landscape/#what-is-machine-learning","title":"What Is Machine Learning?","text":"<p>Machine Learning is the science (and art) of programming computers so they can learn from data.</p> <p>Here is a slightly more general definition:     * [Machine Learning is the] field of study that gives computers the ability to learn without being explicitly programmed.         - Arthur Samuel, 1959</p>"},{"location":"books/Hands%20on%20machine%20learning/The%20Fundamentals%20of%20Machine%20Learning/3.2.%20End-to-End%20Machine%20Learning%20Project/","title":"End-to-End Machine Learning Project","text":""},{"location":"books/Hands%20on%20machine%20learning/The%20Fundamentals%20of%20Machine%20Learning/3.3.%20Classification/","title":"Classification","text":""},{"location":"books/Hands%20on%20machine%20learning/The%20Fundamentals%20of%20Machine%20Learning/3.4.%20Training%20Models/","title":"Training Models","text":""},{"location":"books/Hands%20on%20machine%20learning/The%20Fundamentals%20of%20Machine%20Learning/3.5.%20Support%20Vector%20Machines/","title":"Support Vector Machines","text":""},{"location":"books/Hands%20on%20machine%20learning/The%20Fundamentals%20of%20Machine%20Learning/3.6.%20Decision%20Trees/","title":"Decision Trees","text":""},{"location":"books/Hands%20on%20machine%20learning/The%20Fundamentals%20of%20Machine%20Learning/3.7.%20Ensemble%20Learning%20and%20Random%20Forests/","title":"Ensemble Learning and Random Forests","text":""},{"location":"books/Hands%20on%20machine%20learning/The%20Fundamentals%20of%20Machine%20Learning/3.8.%20Dimensionality%20Reduction/","title":"Dimensionality Reduction","text":""},{"location":"books/Hands%20on%20machine%20learning/The%20Fundamentals%20of%20Machine%20Learning/3.9.%20Unsupervised%20Learning%20Techniques/","title":"Unsupervised Learning Techniques","text":""},{"location":"courses/Algorithmes%20de%20machine%20learning/","title":"Algorithmes de machine learning","text":""},{"location":"courses/Algorithmes%20de%20machine%20learning/#les-algorithmes-les-plus-utilises-en-machine-learning","title":"Les algorithmes les plus utilis\u00e9s en machine learning","text":"<p>Les algorithmes les plus utilis\u00e9s en machine learning sont les suivants:</p> <p>R\u00e9gression lin\u00e9aire</p> <p>C\u2019est un algorithme simple qui est utilis\u00e9 pour pr\u00e9dire la valeur d\u2019une variable continue en utilisant une ou plusieurs variables explicatives.</p> <p>R\u00e9gression logistique</p> <p>C\u2019est un algorithme de classification utilis\u00e9 pour pr\u00e9dire une variable de sortie binaire.</p> <p>For\u00eat al\u00e9atoire (Random Forest)</p> <p>C\u2019est un algorithme de classification et de r\u00e9gression bas\u00e9 sur l\u2019apprentissage ensembliste qui utilise plusieurs arbres de d\u00e9cision pour pr\u00e9dire la sortie.</p> <p>K-Nearest Neighbors (K-NN)</p> <p>C\u2019est un algorithme de classification et de r\u00e9gression bas\u00e9 sur l\u2019apprentissage par instance qui pr\u00e9dit la sortie en utilisant les donn\u00e9es les plus proches de l\u2019exemple \u00e0 pr\u00e9dire.</p> <p>Naive Bayes</p> <p>C\u2019est un algorithme de classification probabiliste qui pr\u00e9dit la classe d\u2019une instance en utilisant les probabilit\u00e9s conditionnelles de chaque classe donn\u00e9e les caract\u00e9ristiques de l\u2019instance.</p> <p>Arbre de d\u00e9cision</p> <p>C\u2019est un algorithme de classification et de r\u00e9gression qui cr\u00e9e un arbre de d\u00e9cision pour repr\u00e9senter les relations entre les variables d\u2019entr\u00e9e et les sorties.</p> <p>Support Vector Machine (SVM)</p> <p>C\u2019est un algorithme de classification qui d\u00e9finit une fronti\u00e8re de d\u00e9cision en utilisant les donn\u00e9es d\u2019entra\u00eenement les plus repr\u00e9sentatives pour s\u00e9parer les diff\u00e9rentes classes.</p> <p>R\u00e9seau de neurones artificiels (RNA)</p> <p>C\u2019est un algorithme de deep learning qui mod\u00e9lise les connexions entre les neurones pour effectuer des t\u00e2ches complexes telles que la reconnaissance d\u2019images ou la g\u00e9n\u00e9ration de langage.</p> Note <p>Il est important de noter que le choix de l\u2019algorithme d\u00e9pend des donn\u00e9es d\u2019entr\u00e9e, de la t\u00e2che de machine learning et de l\u2019objectif de l\u2019analyse. Il est donc souvent n\u00e9cessaire d\u2019essayer plusieurs algorithmes pour trouver le meilleur pour chaque cas d\u2019utilisation.</p>"},{"location":"courses/Algorithmes%20de%20machine%20learning/#implementation-simple-de-la-regression-lineaire","title":"Impl\u00e9mentation simple de la r\u00e9gression lin\u00e9aire","text":"<p>Voici une impl\u00e9mentation simple de la r\u00e9gression lin\u00e9aire en utilisant Python avec le module scikit-learn:</p> <pre><code># importation des biblioth\u00e8ques n\u00e9cessaires\nimport numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\n# chargement des donn\u00e9es\ndata = pd.read_csv(\"data.csv\")\n# s\u00e9lection des variables explicatives et de la variable cible\nX = data[['Variable_1', 'Variable_2', 'Variable_3']]\ny = data['Variable_cible']\n# cr\u00e9ation d'un mod\u00e8le de r\u00e9gression lin\u00e9aire\nreg = LinearRegression().fit(X, y)\n# coefficients de r\u00e9gression\nprint(\"Coefficients de r\u00e9gression:\", reg.coef_)\n# intercept de la r\u00e9gression\nprint(\"Intercept de la r\u00e9gression:\", reg.intercept_)\n# pr\u00e9diction sur les donn\u00e9es d'entra\u00eenement\ny_pred = reg.predict(X)\n# calcul de la performance du mod\u00e8le\nr2_score = reg.score(X, y)\nprint(\"Score R^2:\", r2_score)\n</code></pre> <p>Dans cet exemple, nous importons les biblioth\u00e8ques numpy et pandas pour charger et manipuler les donn\u00e9es. Le mod\u00e8le de r\u00e9gression lin\u00e9aire est cr\u00e9\u00e9 en utilisant la fonction <code>LinearRegression</code> du module scikit-learn. Ensuite, nous utilisons le mod\u00e8le pour pr\u00e9dire la variable cible en utilisant les variables explicatives, en stockant les pr\u00e9dictions dans la variable <code>y_pred</code>. Enfin, nous calculons le score R^2 pour \u00e9valuer la performance du mod\u00e8le.</p>"},{"location":"courses/Algorithmes%20de%20machine%20learning/#implementation-simple-de-la-regression-logistique","title":"Impl\u00e9mentation simple de la r\u00e9gression logistique","text":"<p>Voici une impl\u00e9mentation simple de la r\u00e9gression logistique en utilisant Python avec le module scikit-learn:</p> <pre><code># importation des biblioth\u00e8ques n\u00e9cessaires\nimport numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LogisticRegression\n# chargement des donn\u00e9es\ndata = pd.read_csv(\"data.csv\")\n# s\u00e9lection des variables explicatives et de la variable cible\nX = data[['Variable_1', 'Variable_2', 'Variable_3']]\ny = data['Variable_cible']\n# cr\u00e9ation d'un mod\u00e8le de r\u00e9gression logistique\nlogreg = LogisticRegression().fit(X, y)\n# coefficients de r\u00e9gression\nprint(\"Coefficients de r\u00e9gression:\", logreg.coef_)\n# intercept de la r\u00e9gression\nprint(\"Intercept de la r\u00e9gression:\", logreg.intercept_)\n# pr\u00e9diction sur les donn\u00e9es d'entra\u00eenement\ny_pred = logreg.predict(X)\n# calcul de la performance du mod\u00e8le\naccuracy = logreg.score(X, y)\nprint(\"Pr\u00e9cision:\", accuracy)\n</code></pre> <p>Dans cet exemple, nous importons les biblioth\u00e8ques numpy et pandas pour charger et manipuler les donn\u00e9es. Le mod\u00e8le de r\u00e9gression logistique est cr\u00e9\u00e9 en utilisant la fonction <code>LogisticRegression</code> du module scikit-learn. Ensuite, nous utilisons le mod\u00e8le pour pr\u00e9dire la variable cible en utilisant les variables explicatives, en stockant les pr\u00e9dictions dans la variable <code>y_pred</code>. Enfin, nous calculons la pr\u00e9cision du mod\u00e8le pour \u00e9valuer la performance. Notez que la r\u00e9gression logistique est un algorithme de classification binaire, donc la variable cible doit \u00eatre binaire.</p>"},{"location":"courses/Algorithmes%20de%20machine%20learning/#implementation-simple-de-foret-aleatoire-random-forest","title":"Impl\u00e9mentation simple de For\u00eat al\u00e9atoire (Random Forest)","text":"<p>Voici une impl\u00e9mentation simple de l\u2019algorithme Random Forest en utilisant Python avec le module scikit-learn:</p> <pre><code># importation des biblioth\u00e8ques n\u00e9cessaires\nimport numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\n# chargement des donn\u00e9es\ndata = pd.read_csv(\"data.csv\")\n# s\u00e9lection des variables explicatives et de la variable cible\nX = data.drop('Variable_cible', axis=1)\ny = data['Variable_cible']\n# cr\u00e9ation d'un mod\u00e8le de Random Forest\nclf = RandomForestClassifier(n_estimators=100)\nclf.fit(X, y)\n# pr\u00e9diction sur les donn\u00e9es d'entra\u00eenement\ny_pred = clf.predict(X)\n# calcul de la performance du mod\u00e8le\naccuracy = clf.score(X, y)\nprint(\"Pr\u00e9cision:\", accuracy)\n</code></pre> <p>Dans cet exemple, nous importons les biblioth\u00e8ques numpy et pandas pour charger et manipuler les donn\u00e9es. Le mod\u00e8le de Random Forest est cr\u00e9\u00e9 en utilisant la fonction <code>RandomForestClassifier</code> du module scikit-learn. Ensuite, nous utilisons le mod\u00e8le pour pr\u00e9dire la variable cible en utilisant les variables explicatives, en stockant les pr\u00e9dictions dans la variable <code>y_pred</code>. Enfin, nous calculons la pr\u00e9cision du mod\u00e8le pour \u00e9valuer la performance. Notez que ce code impl\u00e9mente un mod\u00e8le de Random Forest pour une classification binaire, mais vous pouvez \u00e9galement utiliser l\u2019algorithme pour des t\u00e2ches de r\u00e9gression en utilisant la fonction <code>RandomForestRegressor</code> au lieu de <code>RandomForestClassifier</code>.</p>"},{"location":"courses/Algorithmes%20de%20machine%20learning/#implementation-simple-de-k-nearest-neighbors-k-nn","title":"Impl\u00e9mentation simple de K-Nearest Neighbors (K-NN)","text":"<p>Voici une impl\u00e9mentation simple de l\u2019algorithme K-Nearest Neighbors (K-NN) en utilisant Python avec le module scikit-learn:</p> <pre><code># importation des biblioth\u00e8ques n\u00e9cessaires\nimport numpy as np\nimport pandas as pd\nfrom sklearn.neighbors import KNeighborsClassifier\n# chargement des donn\u00e9es\ndata = pd.read_csv(\"data.csv\")\n# s\u00e9lection des variables explicatives et de la variable cible\nX = data.drop('Variable_cible', axis=1)\ny = data['Variable_cible']\n# cr\u00e9ation d'un mod\u00e8le K-NN\nknn = KNeighborsClassifier(n_neighbors=5)\nknn.fit(X, y)\n# pr\u00e9diction sur les donn\u00e9es d'entra\u00eenement\ny_pred = knn.predict(X)\n# calcul de la performance du mod\u00e8le\naccuracy = knn.score(X, y)\nprint(\"Pr\u00e9cision:\", accuracy)\n</code></pre> <p>Dans cet exemple, nous importons les biblioth\u00e8ques numpy et pandas pour charger et manipuler les donn\u00e9es. Le mod\u00e8le K-NN est cr\u00e9\u00e9 en utilisant la fonction <code>KNeighborsClassifier</code> du module scikit-learn. Ensuite, nous utilisons le mod\u00e8le pour pr\u00e9dire la variable cible en utilisant les variables explicatives, en stockant les pr\u00e9dictions dans la variable y_pred. Enfin, nous calculons la pr\u00e9cision du mod\u00e8le pour \u00e9valuer la performance. Notez que ce code impl\u00e9mente un mod\u00e8le K-NN pour une classification binaire, mais vous pouvez \u00e9galement utiliser l\u2019algorithme pour des t\u00e2ches de r\u00e9gression en utilisant la fonction <code>KNeighborsRegressor</code> au lieu de <code>KNeighborsClassifier</code>.</p>"},{"location":"courses/Algorithmes%20de%20machine%20learning/#implementation-simple-de-naive-bayes","title":"Impl\u00e9mentation simple de Naive Bayes","text":"<p>Voici une impl\u00e9mentation simple de l\u2019algorithme Naive Bayes en utilisant Python avec le module scikit-learn:</p> <pre><code># importation des biblioth\u00e8ques n\u00e9cessaires\nimport numpy as np\nimport pandas as pd\nfrom sklearn.naive_bayes import GaussianNB\n# chargement des donn\u00e9es\ndata = pd.read_csv(\"data.csv\")\n# s\u00e9lection des variables explicatives et de la variable cible\nX = data.drop('Variable_cible', axis=1)\ny = data['Variable_cible']\n# cr\u00e9ation d'un mod\u00e8le Naive Bayes\ngnb = GaussianNB()\ngnb.fit(X, y)\n# pr\u00e9diction sur les donn\u00e9es d'entra\u00eenement\ny_pred = gnb.predict(X)\n# calcul de la performance du mod\u00e8le\naccuracy = gnb.score(X, y)\nprint(\"Pr\u00e9cision:\", accuracy)\n</code></pre> <p>Dans cet exemple, nous importons les biblioth\u00e8ques numpy et pandas pour charger et manipuler les donn\u00e9es. Le mod\u00e8le Naive Bayes est cr\u00e9\u00e9 en utilisant la fonction <code>GaussianNB</code> du module scikit-learn. Ensuite, nous utilisons le mod\u00e8le pour pr\u00e9dire la variable cible en utilisant les variables explicatives, en stockant les pr\u00e9dictions dans la variable <code>y_pred</code>. Enfin, nous calculons la pr\u00e9cision du mod\u00e8le pour \u00e9valuer la performance. Notez que ce code impl\u00e9mente un mod\u00e8le Naive Bayes pour une classification binaire, mais vous pouvez \u00e9galement utiliser l\u2019algorithme pour des t\u00e2ches de r\u00e9gression en utilisant la fonction <code>MultinomialNB</code> ou <code>BernoulliNB</code> selon le type de donn\u00e9es.</p>"},{"location":"courses/Algorithmes%20de%20machine%20learning/#implementation-simple-darbre-de-decision","title":"Impl\u00e9mentation simple d\u2019Arbre de d\u00e9cision","text":"<p>Voici une impl\u00e9mentation simple de l\u2019algorithme d\u2019Arbre de d\u00e9cision en utilisant Python avec le module scikit-learn:</p> <pre><code># importation des biblioth\u00e8ques n\u00e9cessaires\nimport numpy as np\nimport pandas as pd\nfrom sklearn.tree import DecisionTreeClassifier\n# chargement des donn\u00e9es\ndata = pd.read_csv(\"data.csv\")\n# s\u00e9lection des variables explicatives et de la variable cible\nX = data.drop('Variable_cible', axis=1)\ny = data['Variable_cible']\n# cr\u00e9ation d'un mod\u00e8le d'Arbre de d\u00e9cision\ndt = DecisionTreeClassifier()\ndt.fit(X, y)\n# pr\u00e9diction sur les donn\u00e9es d'entra\u00eenement\ny_pred = dt.predict(X)\n# calcul de la performance du mod\u00e8le\naccuracy = dt.score(X, y)\nprint(\"Pr\u00e9cision:\", accuracy)\n</code></pre> <p>Dans cet exemple, nous importons les biblioth\u00e8ques numpy et pandas pour charger et manipuler les donn\u00e9es. Le mod\u00e8le d\u2019Arbre de d\u00e9cision est cr\u00e9\u00e9 en utilisant la fonction <code>DecisionTreeClassifier</code> du module scikit-learn. Ensuite, nous utilisons le mod\u00e8le pour pr\u00e9dire la variable cible en utilisant les variables explicatives, en stockant les pr\u00e9dictions dans la variable <code>y_pred</code>. Enfin, nous calculons la pr\u00e9cision du mod\u00e8le pour \u00e9valuer la performance. Notez que ce code impl\u00e9mente un mod\u00e8le d\u2019Arbre de d\u00e9cision pour une classification binaire, mais vous pouvez \u00e9galement utiliser l\u2019algorithme pour des t\u00e2ches de r\u00e9gression en utilisant la fonction <code>DecisionTreeRegressor</code>.</p>"},{"location":"courses/Algorithmes%20de%20machine%20learning/#implementation-simple-de-support-vector-machine-svm","title":"Impl\u00e9mentation simple de Support Vector Machine (SVM)","text":"<p>Voici une impl\u00e9mentation simple de l\u2019algorithme Support Vector Machine (SVM) en utilisant Python avec le module scikit-learn:</p> <pre><code># importation des biblioth\u00e8ques n\u00e9cessaires\nimport numpy as np\nimport pandas as pd\nfrom sklearn import svm\n# chargement des donn\u00e9es\ndata = pd.read_csv(\"data.csv\")\n# s\u00e9lection des variables explicatives et de la variable cible\nX = data.drop('Variable_cible', axis=1)\ny = data['Variable_cible']\n# cr\u00e9ation d'un mod\u00e8le SVM\nclf = svm.SVC(kernel='linear', C=1)\nclf.fit(X, y)\n# pr\u00e9diction sur les donn\u00e9es d'entra\u00eenement\ny_pred = clf.predict(X)\n# calcul de la performance du mod\u00e8le\naccuracy = clf.score(X, y)\nprint(\"Pr\u00e9cision:\", accuracy)\n</code></pre> <p>Dans cet exemple, nous importons les biblioth\u00e8ques numpy et pandas pour charger et manipuler les donn\u00e9es. Le mod\u00e8le SVM est cr\u00e9\u00e9 en utilisant la classe <code>SVC</code> du module scikit-learn. Nous sp\u00e9cifions ici que nous souhaitons utiliser un noyau lin\u00e9aire et un coefficient de r\u00e9gularisation <code>C</code> de 1. Ensuite, nous utilisons le mod\u00e8le pour pr\u00e9dire la variable cible en utilisant les variables explicatives, en stockant les pr\u00e9dictions dans la variable <code>y_pred</code>. Enfin, nous calculons la pr\u00e9cision du mod\u00e8le pour \u00e9valuer la performance. Notez que vous pouvez \u00e9galement utiliser d\u2019autres types de noyaux, tels que les noyaux polynomiaux et les noyaux Gaussiens, pour r\u00e9soudre des t\u00e2ches de classification et de r\u00e9gression.</p>"},{"location":"courses/Algorithmes%20de%20machine%20learning/#implementation-simple-de-reseau-de-neurones-artificiels-rna","title":"Impl\u00e9mentation simple de R\u00e9seau de neurones artificiels (RNA)","text":"<p>Voici une impl\u00e9mentation simple de l\u2019algorithme R\u00e9seau de neurones artificiels (RNA) en utilisant Python avec le module Keras :</p> <pre><code># importation des biblioth\u00e8ques n\u00e9cessaires\nimport numpy as np\nimport pandas as pd\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n# chargement des donn\u00e9es\ndata = pd.read_csv(\"data.csv\")\n# s\u00e9lection des variables explicatives et de la variable cible\nX = data.drop('Variable_cible', axis=1)\ny = data['Variable_cible']\n# normalisation des donn\u00e9es\nX = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n# cr\u00e9ation d'un mod\u00e8le de RNA\nmodel = Sequential()\nmodel.add(Dense(64, activation='relu', input_shape=(X.shape[1],)))\nmodel.add(Dense(1, activation='sigmoid'))\n# compilation du mod\u00e8le\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n# entra\u00eenement du mod\u00e8le\nmodel.fit(X, y, epochs=50, batch_size=32, validation_split=0.2)\n# \u00e9valuation du mod\u00e8le\nscore = model.evaluate(X, y)\nprint(\"Pr\u00e9cision:\", score[1])\n</code></pre> <p>Dans cet exemple, nous importons les biblioth\u00e8ques numpy et pandas pour charger et manipuler les donn\u00e9es, et nous utilisons Keras pour construire et entra\u00eener le mod\u00e8le de RNA. Nous normalisons d\u2019abord les donn\u00e9es pour am\u00e9liorer la convergence de l\u2019entra\u00eenement. Ensuite, nous d\u00e9finissons un mod\u00e8le s\u00e9quentiel avec deux couches cach\u00e9es utilisant la fonction d\u2019activation <code>relu</code>, ainsi qu\u2019une couche de sortie utilisant la fonction d\u2019activation <code>sigmoid</code>. Nous compilons le mod\u00e8le en sp\u00e9cifiant l\u2019optimiseur <code>adam</code>, la fonction de co\u00fbt <code>binary_crossentropy</code> (car nous r\u00e9solvons ici une t\u00e2che de classification binaire) et les m\u00e9triques d\u2019\u00e9valuation <code>accuracy</code>. Enfin, nous entra\u00eenons le mod\u00e8le en utilisant les donn\u00e9es d\u2019entra\u00eenement, et nous \u00e9valuons la performance en utilisant la pr\u00e9cision. Il est important de noter que ceci n\u2019est qu\u2019une impl\u00e9mentation simple, et qu\u2019il est souvent n\u00e9cessaire d\u2019exp\u00e9rimenter avec diff\u00e9rents architectures et hyperparam\u00e8tres pour obtenir les meilleurs r\u00e9sultats sur les donn\u00e9es r\u00e9elles.</p>"},{"location":"courses/Natural%20Language%20Processing/","title":"Index","text":""},{"location":"courses/Natural%20Language%20Processing/#what-is-nlp","title":"What is NLP?","text":""},{"location":"courses/Natural%20Language%20Processing/#history-of-nlp","title":"History of NLP","text":""},{"location":"courses/Natural%20Language%20Processing/#challenges","title":"Challenges","text":""},{"location":"courses/Natural%20Language%20Processing/#applications","title":"Applications","text":""},{"location":"courses/Natural%20Language%20Processing/advanced/","title":"Advanced","text":""},{"location":"courses/Natural%20Language%20Processing/advanced/#text-classification","title":"Text Classification","text":""},{"location":"courses/Natural%20Language%20Processing/advanced/#text-clustering","title":"Text Clustering","text":""},{"location":"courses/Natural%20Language%20Processing/advanced/#latent-dirichlet-allocation-lda","title":"Latent Dirichlet Allocation (LDA)","text":""},{"location":"courses/Natural%20Language%20Processing/advanced/#non-negative-matrix-factorization-nmf","title":"Non-Negative Matrix Factorization (NMF)","text":""},{"location":"courses/Natural%20Language%20Processing/advanced/#glove","title":"GloVe","text":""},{"location":"courses/Natural%20Language%20Processing/advanced/#lexicons","title":"Lexicons","text":""},{"location":"courses/Natural%20Language%20Processing/advanced/#ngrams","title":"NGrams","text":""},{"location":"courses/Natural%20Language%20Processing/advanced/#langague-modeling","title":"Langague Modeling","text":""},{"location":"courses/Natural%20Language%20Processing/advanced/#text-generation","title":"Text Generation","text":""},{"location":"courses/Natural%20Language%20Processing/advanced/#sentimental-analysis","title":"Sentimental Analysis","text":""},{"location":"courses/Natural%20Language%20Processing/advanced/#naive-bayes","title":"Na\u00efve Bayes","text":""},{"location":"courses/Natural%20Language%20Processing/advanced/#vader","title":"Vader","text":""},{"location":"courses/Natural%20Language%20Processing/advanced/#auto-correct","title":"Auto Correct","text":""},{"location":"courses/Natural%20Language%20Processing/advanced/#answering-questions","title":"Answering Questions","text":""},{"location":"courses/Natural%20Language%20Processing/advanced/#summarization","title":"Summarization","text":""},{"location":"courses/Natural%20Language%20Processing/bases/","title":"Bases","text":""},{"location":"courses/Natural%20Language%20Processing/bases/#libraries","title":"Libraries","text":""},{"location":"courses/Natural%20Language%20Processing/bases/#reading-text","title":"Reading Text","text":""},{"location":"courses/Natural%20Language%20Processing/bases/#handling-pdf","title":"Handling PDF","text":""},{"location":"courses/Natural%20Language%20Processing/bases/#search-in-text","title":"Search in Text","text":""},{"location":"courses/Natural%20Language%20Processing/collection/","title":"Collection","text":""},{"location":"courses/Natural%20Language%20Processing/collection/#tweet-collecting","title":"Tweet Collecting","text":""},{"location":"courses/Natural%20Language%20Processing/collection/#data-scraping","title":"Data Scraping","text":""},{"location":"courses/Natural%20Language%20Processing/collection/#information-extraction","title":"Information Extraction","text":""},{"location":"courses/Natural%20Language%20Processing/collection/#information-retrieval","title":"Information Retrieval","text":""},{"location":"courses/Natural%20Language%20Processing/collection/#relative-extraction","title":"Relative Extraction","text":""},{"location":"courses/Natural%20Language%20Processing/collection/#search-engine","title":"Search Engine","text":""},{"location":"courses/Natural%20Language%20Processing/modern/","title":"Modern","text":""},{"location":"courses/Natural%20Language%20Processing/modern/#teacher-forcing","title":"Teacher Forcing","text":""},{"location":"courses/Natural%20Language%20Processing/modern/#attention-models","title":"Attention Models","text":""},{"location":"courses/Natural%20Language%20Processing/modern/#hugging-face","title":"Hugging Face","text":""},{"location":"courses/Natural%20Language%20Processing/modern/#bert","title":"Bert","text":""},{"location":"courses/Natural%20Language%20Processing/modern/#fasttext","title":"FastText","text":""},{"location":"courses/Natural%20Language%20Processing/modern/#gensim","title":"Gensim","text":""},{"location":"courses/Natural%20Language%20Processing/modern/#chatbot","title":"Chatbot","text":""},{"location":"courses/Natural%20Language%20Processing/modern/#translation","title":"Translation","text":""},{"location":"courses/Natural%20Language%20Processing/reseaunn/","title":"Reseaunn","text":""},{"location":"courses/Natural%20Language%20Processing/reseaunn/#rnn","title":"RNN","text":""},{"location":"courses/Natural%20Language%20Processing/reseaunn/#lstm","title":"LSTM","text":""},{"location":"courses/Natural%20Language%20Processing/reseaunn/#gru","title":"GRU","text":""},{"location":"courses/Natural%20Language%20Processing/reseaunn/#tnn","title":"TNN","text":""},{"location":"courses/Natural%20Language%20Processing/reseaunn/#cnn","title":"CNN","text":""},{"location":"courses/Natural%20Language%20Processing/simple/","title":"Simple","text":""},{"location":"courses/Natural%20Language%20Processing/simple/#word-meaning","title":"Word Meaning","text":""},{"location":"courses/Natural%20Language%20Processing/simple/#word-embedding","title":"Word Embedding","text":""},{"location":"courses/Natural%20Language%20Processing/simple/#text-vectors","title":"Text Vectors","text":""},{"location":"courses/Natural%20Language%20Processing/simple/#word2vec","title":"Word2Vec","text":""},{"location":"courses/Natural%20Language%20Processing/simple/#bag-of-words-bow","title":"Bag Of Words (BOW)","text":""},{"location":"courses/Natural%20Language%20Processing/simple/#tf-idf","title":"TF-IDF","text":""},{"location":"courses/Natural%20Language%20Processing/simple/#text-similarity","title":"Text Similarity","text":""},{"location":"courses/Natural%20Language%20Processing/simple/#distributional-similarity","title":"Distributional Similarity","text":""},{"location":"courses/Natural%20Language%20Processing/tools/","title":"Tools","text":""},{"location":"courses/Natural%20Language%20Processing/tools/#tokenization","title":"Tokenization","text":""},{"location":"courses/Natural%20Language%20Processing/tools/#sentence-segmentation","title":"Sentence Segmentation","text":""},{"location":"courses/Natural%20Language%20Processing/tools/#part-of-speech-pos","title":"Part of Speech (POS)","text":""},{"location":"courses/Natural%20Language%20Processing/tools/#stemming-lemmatization","title":"Stemming &amp; Lemmatization","text":""},{"location":"courses/Natural%20Language%20Processing/tools/#named-entity-recognition-ner","title":"Named-Entity Recognition (NER)","text":""},{"location":"courses/Natural%20Language%20Processing/tools/#stopwords","title":"Stopwords","text":""},{"location":"courses/Natural%20Language%20Processing/tools/#matchers","title":"Matchers","text":""},{"location":"courses/Natural%20Language%20Processing/tools/#syntactic-structure","title":"Syntactic Structure","text":""},{"location":"courses/Natural%20Language%20Processing/tools/#text-visualization","title":"Text Visualization","text":""},{"location":"courses/Tools/numpy/","title":"Tools - NumPy","text":"<p>NumPy is the fundamental library for scientific computing with Python. NumPy is centered around a powerful N-dimensional array object, and it also contains useful linear algebra, Fourier transform, and random number functions.</p>"},{"location":"courses/Tools/numpy/#creating-arrays","title":"Creating Arrays","text":"<p>Now let\u2019s import <code>numpy</code>. Most people import it as <code>np</code>:</p> <pre><code>import numpy as np\n</code></pre>"},{"location":"courses/Tools/numpy/#npzeros","title":"np.zeros","text":"<p>The <code>zeros</code> function creates an array containing any number of zeros:</p> <pre><code>np.zeros(5)\n</code></pre> Output <p>array([0., 0., 0., 0., 0.])</p> <p>It\u2019s just as easy to create a 2D array (ie. a matrix) by providing a tuple with the desired number of rows and columns. For example, here\u2019s a 3x4 matrix:</p> <pre><code>np.zeros((3,4))\n</code></pre> Output <p>array([[0., 0., 0., 0.],        [0., 0., 0., 0.],        [0., 0., 0., 0.]])</p>"},{"location":"courses/Tools/numpy/#some-vocabulary","title":"Some vocabulary","text":"<ul> <li> <p>In NumPy, each dimension is called an axis.</p> </li> <li> <p>The number of axes is called the rank.</p> <ul> <li> <p>For example, the above 3x4 matrix is an array of rank 2 (it is 2-dimensional).</p> </li> <li> <p>The first axis has length 3, the second has length 4.</p> </li> </ul> </li> <li> <p>An array\u2019s list of axis lengths is called the shape of the array.</p> <ul> <li> <p>For example, the above matrix\u2019s shape is <code>(3, 4)</code>.</p> </li> <li> <p>The rank is equal to the shape\u2019s length.</p> </li> </ul> </li> <li> <p>The size of an array is the total number of elements, which is the product of all axis lengths (eg. 3*4=12)</p> </li> </ul> <pre><code>a = np.zeros((3,4))\na\n</code></pre> Output <p>array([[0., 0., 0., 0.],        [0., 0., 0., 0.],        [0., 0., 0., 0.]])</p> <pre><code>a.shape\n</code></pre> Output <p>(3, 4)</p> <pre><code>a.ndim  # equal to len(a.shape)\n</code></pre> Output <p>2</p> <pre><code>a.size\n</code></pre> Output <p>12</p>"},{"location":"courses/Tools/numpy/#n-dimensional-arrays","title":"N-dimensional arrays","text":"<p>You can also create an N-dimensional array of arbitrary rank. For example, here\u2019s a 3D array (rank=3), with shape <code>(2,3,4)</code>:</p> <pre><code>np.zeros((2,3,4))\n</code></pre> Output <p>array([[[0., 0., 0., 0.],         [0., 0., 0., 0.],         [0., 0., 0., 0.]],</p> <pre><code>   [[0., 0., 0., 0.],\n    [0., 0., 0., 0.],\n    [0., 0., 0., 0.]]])\n</code></pre>"},{"location":"courses/Tools/numpy/#array-type","title":"Array type","text":"<p>NumPy arrays have the type <code>ndarrays</code>:</p> <pre><code>type(np.zeros((3,4)))\n</code></pre> Output <p>numpy.ndarray</p>"},{"location":"courses/Tools/numpy/#npones","title":"np.ones","text":"<p>Many other NumPy functions create ndarrays.</p> <p>Here\u2019s a 3x4 matrix full of ones:</p> <pre><code>np.ones((3,4))\n</code></pre> Output <p>array([[1., 1., 1., 1.],        [1., 1., 1., 1.],        [1., 1., 1., 1.]])</p>"},{"location":"courses/Tools/numpy/#npfull","title":"np.full","text":"<p>Creates an array of the given shape initialized with the given value. Here\u2019s a 3x4 matrix full of <code>\u03c0</code>.</p> <pre><code>np.full((3,4), np.pi)\n</code></pre> Output <p>array([[3.14159265, 3.14159265, 3.14159265, 3.14159265],        [3.14159265, 3.14159265, 3.14159265, 3.14159265],        [3.14159265, 3.14159265, 3.14159265, 3.14159265]])</p>"},{"location":"courses/Tools/numpy/#npempty","title":"np.empty","text":"<p>An uninitialized 2x3 array (its content is not predictable, as it is whatever is in memory at that point):</p> <pre><code>np.empty((2,3))\n</code></pre> Output <p>array([[0., 0., 0.],        [0., 0., 0.]])</p>"},{"location":"courses/Tools/numpy/#nparray","title":"np.array","text":"<p>Of course you can initialize an <code>ndarray</code> using a regular python array. Just call the <code>array</code> function:</p> <pre><code>np.array([[1,2,3,4], [10, 20, 30, 40]])\n</code></pre> Output <p>array([[ 1,  2,  3,  4],        [10, 20, 30, 40]])</p>"},{"location":"courses/Tools/numpy/#nparange","title":"np.arange","text":"<p>You can create an <code>ndarray</code> using NumPy\u2019s <code>arange</code> function, which is similar to python\u2019s built-in <code>range</code> function:</p> <pre><code>np.arange(1, 5)\n</code></pre> Output <p>array([1, 2, 3, 4])</p> <p>It also works with floats:</p> <pre><code>np.arange(1.0, 5.0)\n</code></pre> Output <p>array([1., 2., 3., 4.])</p> <p>Of course you can provide a step parameter:</p> <pre><code>np.arange(1, 5, 0.5)\n</code></pre> Output <p>array([1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5])</p> <p>However, when dealing with floats, the exact number of elements in the array is not always predictible. For example, consider this:</p> <pre><code>print(np.arange(0, 5/3, 1/3)) # depending on floating point errors, the max value is 4/3 or 5/3.\nprint(np.arange(0, 5/3, 0.333333333))\nprint(np.arange(0, 5/3, 0.333333334))\n</code></pre> Output <p>[0.         0.33333333 0.66666667 1.         1.33333333 1.66666667] [0.         0.33333333 0.66666667 1.         1.33333333 1.66666667] [0.         0.33333333 0.66666667 1.         1.33333334]</p>"},{"location":"courses/Tools/numpy/#nplinspace","title":"np.linspace","text":"<p>For this reason, it is generally preferable to use the <code>linspace</code> function instead of <code>arange</code> when working with floats. The <code>linspace</code> function returns an array containing a specific number of points evenly distributed between two values (note that the maximum value is included, contrary to <code>arange</code>):</p> <pre><code>print(np.linspace(0, 5/3, 6))\n</code></pre> Output <p>[0.         0.33333333 0.66666667 1.         1.33333333 1.66666667]</p>"},{"location":"courses/Tools/numpy/#nprand-and-nprandn","title":"np.rand and np.randn","text":"<p>A number of functions are available in NumPy\u2019s <code>random</code> module to create <code>ndarray</code>s initialized with random values. For example, here is a 3x4 matrix initialized with random floats between 0 and 1 (uniform distribution):</p> <pre><code>np.random.rand(3,4)\n</code></pre> Output <p>array([[0.07951522, 0.82516403, 0.54524215, 0.46662691],        [0.12016334, 0.74912183, 0.183234  , 0.105027  ],        [0.22051959, 0.26931151, 0.02739192, 0.4721405 ]])</p> <p>Here\u2019s a 3x4 matrix containing random floats sampled from a univariate normal distribution (Gaussian distribution) of mean 0 and variance 1:</p> <pre><code>np.random.randn(3,4)\n</code></pre> Output <p>array([[ 0.09545957,  0.14828368, -0.91504156, -0.36224068],        [ 0.55434999,  0.41143633,  0.84385243, -0.3652369 ],        [ 1.48071803, -1.45297797,  1.24551713,  0.4508626 ]])</p> <p>To give you a feel of what these distributions look like, let\u2019s use matplotlib (see the matplotlib tutorial for more details):</p> <pre><code>%matplotlib inline\nimport matplotlib.pyplot as plt\n</code></pre> <pre><code>plt.hist(np.random.rand(100000), density=True, bins=100, histtype=\"step\", color=\"blue\", label=\"rand\")\nplt.hist(np.random.randn(100000), density=True, bins=100, histtype=\"step\", color=\"red\", label=\"randn\")\nplt.axis([-2.5, 2.5, 0, 1.1])\nplt.legend(loc = \"upper left\")\nplt.title(\"Random distributions\")\nplt.xlabel(\"Value\")\nplt.ylabel(\"Density\")\nplt.show()\n</code></pre> Output <p></p>"},{"location":"courses/Tools/numpy/#npfromfunction","title":"np.fromfunction","text":"<p>You can also initialize an <code>ndarray</code> using a function:</p> <pre><code>def my_function(z, y, x):\nreturn x + 10 * y + 100 * z\nnp.fromfunction(my_function, (3, 2, 10))\n</code></pre> Output <p>array([[[  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.],         [ 10.,  11.,  12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.]],</p> <pre><code>   [[100., 101., 102., 103., 104., 105., 106., 107., 108., 109.],\n    [110., 111., 112., 113., 114., 115., 116., 117., 118., 119.]],\n\n   [[200., 201., 202., 203., 204., 205., 206., 207., 208., 209.],\n    [210., 211., 212., 213., 214., 215., 216., 217., 218., 219.]]])\n</code></pre> <p>NumPy first creates three <code>ndarrays</code> (one per dimension), each of shape <code>(3, 2, 10)</code>. Each array has values equal to the coordinate along a specific axis. For example, all elements in the <code>z</code> array are equal to their z-coordinate:</p> <pre><code>[[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n\n [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n  [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n\n [[ 2.  2.  2.  2.  2.  2.  2.  2.  2.  2.]\n  [ 2.  2.  2.  2.  2.  2.  2.  2.  2.  2.]]]\n</code></pre> <p>So the terms <code>x</code>, <code>y</code> and <code>z</code> in the expression <code>x + 10 * y + 100 * z</code> above are in fact <code>ndarrays</code> (we will discuss arithmetic operations on arrays below). The point is that the function <code>my_function</code> is only called once, instead of once per element. This makes initialization very efficient.</p>"},{"location":"courses/Tools/numpy/#array-data","title":"Array data","text":""},{"location":"courses/Tools/numpy/#dtype","title":"dtype","text":"<p>NumPy\u2019s <code>ndarrays</code> are also efficient in part because all their elements must have the same type (usually numbers). You can check what the data type is by looking at the <code>dtype</code> attribute:</p> <pre><code>c = np.arange(1, 5)\nprint(c.dtype, c)\n</code></pre> Output <p>int64 [1 2 3 4]</p> <pre><code>c = np.arange(1.0, 5.0)\nprint(c.dtype, c)\n</code></pre> Output <p>float64 [ 1.  2.  3.  4.]</p> <p>Instead of letting NumPy guess what data type to use, you can set it explicitly when creating an array by setting the <code>dtype</code> parameter:</p> Output <p>complex64 [ 1.+0.j  2.+0.j  3.+0.j  4.+0.j]</p> <p>Available data types include <code>int8</code>, <code>int16</code>, <code>int32</code>, <code>int64</code>, <code>uint8</code>|<code>16</code>|<code>32</code>|<code>64</code>, <code>float16</code>|<code>32</code>|<code>64</code> and <code>complex64</code>|<code>128</code>. Check out the documentation for the full list.</p>"},{"location":"courses/Tools/numpy/#itemsize","title":"itemsize","text":"<p>The <code>itemsize</code> attribute returns the size (in bytes) of each item:</p> <pre><code>e = np.arange(1, 5, dtype=np.complex64)\ne.itemsize\n</code></pre> Output <p>8</p>"},{"location":"courses/Tools/numpy/#data-buffer","title":"data buffer","text":"<p>An array\u2019s data is actually stored in memory as a flat (one dimensional) byte buffer. It is available via the <code>data</code> attribute (you will rarely need it, though).</p> <pre><code>f = np.array([[1,2],[1000, 2000]], dtype=np.int32)\nf.data\n</code></pre> Output <p> <p>In python 2, <code>f.data</code> is a buffer. In python 3, it is a memoryview.</p> <pre><code>if (hasattr(f.data, \"tobytes\")):\ndata_bytes = f.data.tobytes() # python 3\nelse:\ndata_bytes = memoryview(f.data).tobytes() # python 2\ndata_bytes\n</code></pre> Output <p>\u2018\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\xe8\\x03\\x00\\x00\\xd0\\x07\\x00\\x00\u2019</p> <p>Several <code>ndarrays</code> can share the same data buffer, meaning that modifying one will also modify the others. We will see an example in a minute.</p>"},{"location":"courses/Tools/numpy/#reshaping-an-array","title":"Reshaping an array","text":""},{"location":"courses/Tools/numpy/#in-place","title":"In place","text":"<p>Changing the shape of an <code>ndarray</code> is as simple as setting its <code>shape</code> attribute. However, the array\u2019s size must remain the same.</p> <pre><code>g = np.arange(24)\nprint(g)\nprint(\"Rank:\", g.ndim)\n</code></pre> Output <p>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23] Rank: 1</p> <pre><code>g.shape = (6, 4)\nprint(g)\nprint(\"Rank:\", g.ndim)\n</code></pre> Output <p>[[ 0  1  2  3]  [ 4  5  6  7]  [ 8  9 10 11]  [12 13 14 15]  [16 17 18 19]  [20 21 22 23]] Rank: 2</p> <pre><code>g.shape = (2, 3, 4)\nprint(g)\nprint(\"Rank:\", g.ndim)\n</code></pre> Output <p>[[[ 0  1  2  3]   [ 4  5  6  7]   [ 8  9 10 11]]</p> <p>[[12 13 14 15]   [16 17 18 19]   [20 21 22 23]]] Rank: 3</p>"},{"location":"courses/Tools/numpy/#reshape","title":"reshape","text":"<p>The <code>reshape</code> function returns a new <code>ndarray</code> object pointing at the same data. This means that modifying one array will also modify the other.</p> <pre><code>g2 = g.reshape(4,6)\nprint(g2)\nprint(\"Rank:\", g2.ndim)\n</code></pre> Output <p>[[ 0  1  2  3  4  5]  [ 6  7  8  9 10 11]  [12 13 14 15 16 17]  [18 19 20 21 22 23]] Rank: 2</p> <p>Set item at row 1, col 2 to 999 (more about indexing below).</p> <pre><code>g2[1, 2] = 999\ng2\n</code></pre> Output <p>array([[  0,   1,   2,   3,   4,   5],        [  6,   7, 999,   9,  10,  11],        [ 12,  13,  14,  15,  16,  17],        [ 18,  19,  20,  21,  22,  23]])</p> <p>The corresponding element in <code>g</code> has been modified.</p> Output <p>array([[[  0,   1,   2,   3],         [  4,   5,   6,   7],         [999,   9,  10,  11]],</p> <pre><code>   [[ 12,  13,  14,  15],\n    [ 16,  17,  18,  19],\n    [ 20,  21,  22,  23]]])\n</code></pre>"},{"location":"courses/Tools/numpy/#ravel","title":"ravel","text":"<p>Finally, the <code>ravel</code> function returns a new one-dimensional <code>ndarray</code> that also points to the same data:</p> <pre><code>g.ravel()\n</code></pre> Output <p>array([  0,   1,   2,   3,   4,   5,   6,   7, 999,   9,  10,  11,  12,         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23])</p>"},{"location":"courses/Tools/numpy/#arithmetic-operations","title":"Arithmetic operations","text":"<p>All the usual arithmetic operators (<code>+</code>, <code>-</code>, <code>*</code>, <code>/</code>, <code>//</code>, <code>**</code>, etc.) can be used with <code>ndarray</code>s. They apply elementwise:</p> <pre><code>a = np.array([14, 23, 32, 41])\nb = np.array([5,  4,  3,  2])\nprint(\"a + b  =\", a + b)\nprint(\"a - b  =\", a - b)\nprint(\"a * b  =\", a * b)\nprint(\"a / b  =\", a / b)\nprint(\"a // b  =\", a // b)\nprint(\"a % b  =\", a % b)\nprint(\"a ** b =\", a ** b)\n</code></pre> Output <p>a + b  = [19 27 35 43] a - b  = [ 9 19 29 39] a * b  = [70 92 96 82] a / b  = [  2.8          5.75        10.66666667  20.5       ] a // b  = [ 2  5 10 20] a % b  = [4 3 2 1] a ** b = [537824 279841  32768   1681]</p> <p>Note that the multiplication is not a matrix multiplication. We will discuss matrix operations below.</p> <p>The arrays must have the same shape. If they do not, NumPy will apply the broadcasting rules.</p>"},{"location":"courses/Tools/numpy/#broadcasting","title":"Broadcasting","text":"<p>In general, when NumPy expects arrays of the same shape but finds that this is not the case, it applies the so-called broadcasting rules:</p>"},{"location":"courses/Tools/numpy/#first-rule","title":"First rule","text":"<p>If the arrays do not have the same rank, then a 1 will be prepended to the smaller ranking arrays until their ranks match.</p> <pre><code>h = np.arange(5).reshape(1, 1, 5)\nh\n</code></pre> Output <p>array([[[0, 1, 2, 3, 4]]])</p> <p>Now let\u2019s try to add a 1D array of shape <code>(5,)</code> to this 3D array of shape <code>(1,1,5)</code>. Applying the first rule of broadcasting!</p> <pre><code>h + [10, 20, 30, 40, 50]  # same as: h + [[[10, 20, 30, 40, 50]]]\n</code></pre> Output <p>array([[[10, 21, 32, 43, 54]]])</p>"},{"location":"courses/Tools/numpy/#second-rule","title":"Second rule","text":"<p>Arrays with a 1 along a particular dimension act as if they had the size of the array with the largest shape along that dimension. The value of the array element is repeated along that dimension.</p> <pre><code>k = np.arange(6).reshape(2, 3)\nk\n</code></pre> Output <p>array([[0, 1, 2],        [3, 4, 5]])</p> <p>Let\u2019s try to add a 2D array of shape <code>(2,1)</code> to this 2D <code>ndarray</code> of shape <code>(2, 3)</code>. NumPy will apply the second rule of broadcasting:</p> <pre><code>k + [[100], [200]]  # same as: k + [[100, 100, 100], [200, 200, 200]]\n</code></pre> Output <p>array([[100, 101, 102],        [203, 204, 205]])</p> <p>Combining rules 1 &amp; 2, we can do this:</p> <pre><code>k + [100, 200, 300]  # after rule 1: [[100, 200, 300]], and after rule 2: [[100, 200, 300], [100, 200, 300]]\n</code></pre> Output <p>array([[100, 201, 302],        [103, 204, 305]])</p> <p>And also, very simply:</p> <pre><code>k + 1000  # same as: k + [[1000, 1000, 1000], [1000, 1000, 1000]]\n</code></pre> Output <p>array([[1000, 1001, 1002],        [1003, 1004, 1005]])</p>"},{"location":"courses/Tools/numpy/#third-rule","title":"Third rule","text":"<p>After rules 1 &amp; 2, the sizes of all arrays must match.</p> <pre><code>try:\nk + [33, 44]\nexcept ValueError as e:\nprint(e)\n</code></pre> Output <p>operands could not be broadcast together with shapes (2,3) (2,) </p> <p>Broadcasting rules are used in many NumPy operations, not just arithmetic operations, as we will see below. For more details about broadcasting, check out the documentation.</p>"},{"location":"courses/Tools/numpy/#upcasting","title":"Upcasting","text":"<p>When trying to combine arrays with different <code>dtype</code>s, NumPy will upcast to a type capable of handling all possible values (regardless of what the actual values are).</p> <pre><code>k1 = np.arange(0, 5, dtype=np.uint8)\nprint(k1.dtype, k1)\n</code></pre> Output <p>uint8 [0 1 2 3 4]</p> <pre><code>k2 = k1 + np.array([5, 6, 7, 8, 9], dtype=np.int8)\nprint(k2.dtype, k2)\n</code></pre> Output <p>int16 [ 5  7  9 11 13]</p> <p>Note that <code>int16</code> is required to represent all possible <code>int8</code> and <code>uint8</code> values (from -128 to 255), even though in this case a uint8 would have sufficed.</p> <pre><code>k3 = k1 + 1.5\nprint(k3.dtype, k3)\n</code></pre> Output <p>float64 [ 1.5  2.5  3.5  4.5  5.5]</p>"},{"location":"courses/Tools/numpy/#conditional-operators","title":"Conditional operators","text":"<p>The conditional operators also apply elementwise:</p> <pre><code>m = np.array([20, -5, 30, 40])\nm &lt; [15, 16, 35, 36]\n</code></pre> Output <p>array([False,  True,  True, False], dtype=bool)</p> <p>And using broadcasting:</p> <pre><code>m &lt; 25  # equivalent to m &lt; [25, 25, 25, 25]\n</code></pre> Output <p>array([ True,  True, False, False], dtype=bool)</p> <p>This is most useful in conjunction with boolean indexing (discussed below).</p> <pre><code>m[m &lt; 25]\n</code></pre> Output <p>array([20, -5])</p>"},{"location":"courses/Tools/numpy/#mathematical-and-statistical-functions","title":"Mathematical and statistical functions","text":"<p>Many mathematical and statistical functions are available for <code>ndarray</code>s.</p>"},{"location":"courses/Tools/numpy/#ndarray-methods","title":"ndarray methods","text":"<p>Some functions are simply <code>ndarray</code> methods, for example:</p> <pre><code>a = np.array([[-2.5, 3.1, 7], [10, 11, 12]])\nprint(a)\nprint(\"mean =\", a.mean())\n</code></pre> Output <p>[[ -2.5   3.1   7. ]  [ 10.   11.   12. ]] mean = 6.76666666667</p> <p>Note that this computes the mean of all elements in the <code>ndarray</code>, regardless of its shape.</p> <p>Here are a few more useful <code>ndarray</code> methods:</p> <pre><code>for func in (a.min, a.max, a.sum, a.prod, a.std, a.var):\nprint(func.__name__, \"=\", func())\n</code></pre> Output <p>min = -2.5 max = 12.0 sum = 40.6 prod = -71610.0 std = 5.08483584352 var = 25.8555555556</p> <p>These functions accept an optional argument <code>axis</code> which lets you ask for the operation to be performed on elements along the given axis. For example:</p> <pre><code>c=np.arange(24).reshape(2,3,4)\nc\n</code></pre> Output <p>array([[[ 0,  1,  2,  3],         [ 4,  5,  6,  7],         [ 8,  9, 10, 11]],</p> <pre><code>   [[12, 13, 14, 15],\n    [16, 17, 18, 19],\n    [20, 21, 22, 23]]])\n</code></pre> <pre><code>c.sum(axis=0)  # sum across matrices\n</code></pre> Output <p>array([[12, 14, 16, 18],        [20, 22, 24, 26],        [28, 30, 32, 34]])</p> <pre><code>c.sum(axis=1)  # sum across rows\n</code></pre> Output <p>array([[12, 15, 18, 21],        [48, 51, 54, 57]])</p> <p>You can also sum over multiple axes:</p> <pre><code>c.sum(axis=(0,2))  # sum across matrices and columns\n</code></pre> Output <p>array([ 60,  92, 124])</p> <pre><code>0+1+2+3 + 12+13+14+15, 4+5+6+7 + 16+17+18+19, 8+9+10+11 + 20+21+22+23\n</code></pre> Output <p>(60, 92, 124)</p>"},{"location":"courses/Tools/numpy/#universal-functions","title":"Universal functions","text":"<p>NumPy also provides fast elementwise functions called universal functions, or ufunc. They are vectorized wrappers of simple functions. For example <code>square</code> returns a new <code>ndarray</code> which is a copy of the original <code>ndarray</code> except that each element is squared:</p> <pre><code>a = np.array([[-2.5, 3.1, 7], [10, 11, 12]])\nnp.square(a)\n</code></pre> Output <p>array([[   6.25,    9.61,   49.  ],        [ 100.  ,  121.  ,  144.  ]])</p> <p>Here are a few more useful unary ufuncs:</p> <pre><code>print(\"Original ndarray\")\nprint(a)\nfor func in (np.abs, np.sqrt, np.exp, np.log, np.sign, np.ceil, np.modf, np.isnan, np.cos):\nprint(\"\\n\", func.__name__)\nprint(func(a))\n</code></pre> Output <p>Original ndarray [[ -2.5   3.1   7. ]  [ 10.   11.   12. ]]</p> <p>absolute [[  2.5   3.1   7. ]  [ 10.   11.   12. ]]</p> <p>sqrt [[        nan  1.76068169  2.64575131]  [ 3.16227766  3.31662479  3.46410162]]</p> <p>exp [[  8.20849986e-02   2.21979513e+01   1.09663316e+03]  [  2.20264658e+04   5.98741417e+04   1.62754791e+05]]</p> <p>log [[        nan  1.13140211  1.94591015]  [ 2.30258509  2.39789527  2.48490665]]</p> <p>sign [[-1.  1.  1.]  [ 1.  1.  1.]]</p> <p>ceil [[ -2.   4.   7.]  [ 10.  11.  12.]]</p> <p>modf (array([[-0.5,  0.1,  0. ],        [ 0. ,  0. ,  0. ]]), array([[ -2.,   3.,   7.],        [ 10.,  11.,  12.]]))</p> <p>isnan [[False False False]  [False False False]]</p> <p>cos [[-0.80114362 -0.99913515  0.75390225]  [-0.83907153  0.0044257   0.84385396]] -c:5: RuntimeWarning: invalid value encountered in sqrt -c:5: RuntimeWarning: invalid value encountered in log</p>"},{"location":"courses/Tools/numpy/#binary-ufuncs","title":"Binary ufuncs","text":"<p>There are also many binary ufuncs, that apply elementwise on two <code>ndarray</code>s. Broadcasting rules are applied if the arrays do not have the same shape:</p> <pre><code>a = np.array([1, -2, 3, 4])\nb = np.array([2, 8, -1, 7])\nnp.add(a, b)  # equivalent to a + b\n</code></pre> Output <p>array([ 3,  6,  2, 11])</p> <pre><code>np.greater(a, b)  # equivalent to a &gt; b\n</code></pre> Output <p>array([False, False,  True, False], dtype=bool)</p> <pre><code>np.maximum(a, b)\n</code></pre> Output <p>array([2, 8, 3, 7])</p> <pre><code>np.copysign(a, b)\n</code></pre> Output <p>array([ 1.,  2., -3.,  4.])</p>"},{"location":"courses/Tools/numpy/#array-indexing","title":"Array indexing","text":""},{"location":"courses/Tools/numpy/#one-dimensional-arrays","title":"One-dimensional arrays","text":"<p>One-dimensional NumPy arrays can be accessed more or less like regular python arrays:</p> <pre><code>a = np.array([1, 5, 3, 19, 13, 7, 3])\na[3]\n</code></pre> Output <p>19</p> <pre><code>a[2:5]\n</code></pre> Output <p>array([ 3, 19, 13])</p> <pre><code>a[2:-1]\n</code></pre> Output <p>array([ 3, 19, 13,  7])</p> <pre><code>a[:2]\n</code></pre> Output <p>array([1, 5])</p> <pre><code>a[2::2]\n</code></pre> Output <p>array([ 3, 13,  3])</p> <pre><code>a[::-1]\n</code></pre> Output <p>array([ 3,  7, 13, 19,  3,  5,  1])</p> <p>Of course, you can modify elements:</p> <pre><code>a[3]=999\na\n</code></pre> Output <p>array([  1,   5,   3, 999,  13,   7,   3])</p> <p>You can also modify an <code>ndarray</code> slice:</p> <pre><code>a[2:5] = [997, 998, 999]\na\n</code></pre> Output <p>array([  1,   5, 997, 998, 999,   7,   3])</p>"},{"location":"courses/Tools/numpy/#differences-with-regular-python-arrays","title":"Differences with regular python arrays","text":"<p>Contrary to regular python arrays, if you assign a single value to an <code>ndarray</code> slice, it is copied across the whole slice, thanks to broadcasting rules discussed above.</p> <pre><code>a[2:5] = -1\na\n</code></pre> Output <p>array([ 1,  5, -1, -1, -1,  7,  3])</p> <p>Also, you cannot grow or shrink <code>ndarrays</code> this way:</p> <pre><code>try:\na[2:5] = [1,2,3,4,5,6]  # too long\nexcept ValueError as e:\nprint(e)\n</code></pre> Output <p>cannot copy sequence with size 6 to array axis with dimension 3</p> <p>You cannot delete elements either:</p> <pre><code>try:\ndel a[2:5]\nexcept ValueError as e:\nprint(e)\n</code></pre> Output <p>cannot delete array elements</p> <p>Last but not least, <code>ndarray</code> slices are actually views on the same data buffer. This means that if you create a slice and modify it, you are actually going to modify the original <code>ndarray</code> as well!</p> <pre><code>a_slice = a[2:6]\na_slice[1] = 1000\na  # the original array was modified!\n</code></pre> Output <p>array([   1,    5,   -1, 1000,   -1,    7,    3])</p> <pre><code>a[3] = 2000\na_slice  # similarly, modifying the original array modifies the slice!\n</code></pre> Output <p>array([  -1, 2000,   -1,    7])</p> <p>If you want a copy of the data, you need to use the <code>copy</code> method:</p> <pre><code>another_slice = a[2:6].copy()\nanother_slice[1] = 3000\na  # the original array is untouched\n</code></pre> Output <p>array([   1,    5,   -1, 2000,   -1,    7,    3])</p> <pre><code>a[3] = 4000\nanother_slice  # similary, modifying the original array does not affect the slice copy\n</code></pre> Output <p>array([  -1, 3000,   -1,    7])</p>"},{"location":"courses/Tools/numpy/#multi-dimensional-arrays","title":"Multi-dimensional arrays","text":"<p>Multi-dimensional arrays can be accessed in a similar way by providing an index or slice for each axis, separated by commas:</p> <pre><code>b = np.arange(48).reshape(4, 12)\nb\n</code></pre> Output <p>array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11],        [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23],        [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35],        [36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]])</p> <pre><code>b[1, 2]  # row 1, col 2\n</code></pre> Output <p>14</p> <pre><code>b[1, :]  # row 1, all columns\n</code></pre> Output <p>array([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23])</p> <pre><code>b[:, 1]  # all rows, column 1\n</code></pre> Output <p>array([ 1, 13, 25, 37])</p> <p>Caution</p> <p>note the subtle difference between these two expressions:</p> <pre><code>b[1, :]\n</code></pre> Output <p>array([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23])</p> <pre><code>b[1:2, :]\n</code></pre> Output <p>array([[12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]])</p> <p>The first expression returns row 1 as a 1D array of shape <code>(12,)</code>, while the second returns that same row as a 2D array of shape <code>(1, 12)</code>.</p>"},{"location":"courses/Tools/numpy/#fancy-indexing","title":"Fancy indexing","text":"<p>You may also specify a list of indices that you are interested in. This is referred to as fancy indexing.</p> <pre><code>b[(0,2), 2:5]  # rows 0 and 2, columns 2 to 4 (5-1)\n</code></pre> Output <p>array([[ 2,  3,  4],        [26, 27, 28]])</p> <pre><code>b[:, (-1, 2, -1)]  # all rows, columns -1 (last), 2 and -1 (again, and in this order)\n</code></pre> Output <p>array([[11,  2, 11],        [23, 14, 23],        [35, 26, 35],        [47, 38, 47]])</p> <p>If you provide multiple index arrays, you get a 1D <code>ndarray</code> containing the values of the elements at the specified coordinates.</p> <pre><code>b[(-1, 2, -1, 2), (5, 9, 1, 9)]  # returns a 1D array with b[-1, 5], b[2, 9], b[-1, 1] and b[2, 9] (again)\n</code></pre> Output <p>array([41, 33, 37, 33])</p>"},{"location":"courses/Tools/numpy/#higher-dimensions","title":"Higher dimensions","text":"<p>Everything works just as well with higher dimensional arrays, but it\u2019s useful to look at a few examples:</p> <pre><code>c = b.reshape(4,2,6)\nc\n</code></pre> Output <p>array([[[ 0,  1,  2,  3,  4,  5],         [ 6,  7,  8,  9, 10, 11]],</p> <pre><code>   [[12, 13, 14, 15, 16, 17],\n    [18, 19, 20, 21, 22, 23]],\n\n   [[24, 25, 26, 27, 28, 29],\n    [30, 31, 32, 33, 34, 35]],\n\n   [[36, 37, 38, 39, 40, 41],\n    [42, 43, 44, 45, 46, 47]]])\n</code></pre> <pre><code>c[2, 1, 4]  # matrix 2, row 1, col 4\n</code></pre> Output <p>34</p> <pre><code>c[2, :, 3]  # matrix 2, all rows, col 3\n</code></pre> Output <p>array([27, 33])</p> <p>If you omit coordinates for some axes, then all elements in these axes are returned:</p> <pre><code>c[2, 1]  # Return matrix 2, row 1, all columns.  This is equivalent to c[2, 1, :]\n</code></pre> Output <p>array([30, 31, 32, 33, 34, 35])</p>"},{"location":"courses/Tools/numpy/#ellipsis","title":"Ellipsis (\u2026)","text":"<p>You may also write an ellipsis (<code>...</code>) to ask that all non-specified axes be entirely included.</p> <pre><code>c[2, ...]  #  matrix 2, all rows, all columns.  This is equivalent to c[2, :, :]\n</code></pre> Output <p>array([[24, 25, 26, 27, 28, 29],        [30, 31, 32, 33, 34, 35]])</p> <pre><code>c[2, 1, ...]  # matrix 2, row 1, all columns.  This is equivalent to c[2, 1, :]\n</code></pre> Output <p>array([30, 31, 32, 33, 34, 35])</p> <pre><code>c[2, ..., 3]  # matrix 2, all rows, column 3.  This is equivalent to c[2, :, 3]\n</code></pre> Output <p>array([27, 33])</p> <pre><code>c[..., 3]  # all matrices, all rows, column 3.  This is equivalent to c[:, :, 3]\n</code></pre> Output <p>array([[ 3,  9],        [15, 21],        [27, 33],        [39, 45]])</p>"},{"location":"courses/Tools/numpy/#boolean-indexing","title":"Boolean indexing","text":"<p>You can also provide an <code>ndarray</code> of boolean values on one axis to specify the indices that you want to access.</p> <pre><code>b = np.arange(48).reshape(4, 12)\nb\n</code></pre> Output <p>array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11],        [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23],        [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35],        [36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]])</p> <pre><code>rows_on = np.array([True, False, True, False])\nb[rows_on, :]  # Rows 0 and 2, all columns. Equivalent to b[(0, 2), :]\n</code></pre> Output <p>array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11],        [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]])</p> <pre><code>cols_on = np.array([False, True, False] * 4)\nb[:, cols_on]  # All rows, columns 1, 4, 7 and 10\n</code></pre> Output <p>array([[ 1,  4,  7, 10],        [13, 16, 19, 22],        [25, 28, 31, 34],        [37, 40, 43, 46]])</p>"},{"location":"courses/Tools/numpy/#npix_","title":"np.ix_","text":"<p>You cannot use boolean indexing this way on multiple axes, but you can work around this by using the <code>ix_</code> function:</p> <pre><code>b[np.ix_(rows_on, cols_on)]\n</code></pre> Output <p>array([[ 1,  4,  7, 10],        [25, 28, 31, 34]])</p> <pre><code>np.ix_(rows_on, cols_on)\n</code></pre> Output <p>(array([[0],         [2]]), array([[ 1,  4,  7, 10]]))</p> <p>If you use a boolean array that has the same shape as the <code>ndarray</code>, then you get in return a 1D array containing all the values that have <code>True</code> at their coordinate. This is generally used along with conditional operators:</p> <pre><code>b[b % 3 == 1]\n</code></pre> Output <p>array([ 1,  4,  7, 10, 13, 16, 19, 22, 25, 28, 31, 34, 37, 40, 43, 46])</p>"},{"location":"courses/Tools/numpy/#iterating","title":"Iterating","text":"<p>Iterating over <code>ndarrays</code> is very similar to iterating over regular python arrays. Note that iterating over multidimensional arrays is done with respect to the first axis.</p> <pre><code>c = np.arange(24).reshape(2, 3, 4)  # A 3D array (composed of two 3x4 matrices)\nc\n</code></pre> Output <p>array([[[ 0,  1,  2,  3],         [ 4,  5,  6,  7],         [ 8,  9, 10, 11]],</p> <pre><code>   [[12, 13, 14, 15],\n    [16, 17, 18, 19],\n    [20, 21, 22, 23]]])\n</code></pre> <pre><code>for m in c:\nprint(\"Item:\")\nprint(m)\n</code></pre> Output <p>Item: [[ 0  1  2  3]  [ 4  5  6  7]  [ 8  9 10 11]] Item: [[12 13 14 15]  [16 17 18 19]  [20 21 22 23]]</p> <pre><code>for i in range(len(c)):  # Note that len(c) == c.shape[0]\nprint(\"Item:\")\nprint(c[i])\n</code></pre> Output <p>Item: [[ 0  1  2  3]  [ 4  5  6  7]  [ 8  9 10 11]] Item: [[12 13 14 15]  [16 17 18 19]  [20 21 22 23]]</p> <p>If you want to iterate on all elements in the <code>ndarray</code>, simply iterate over the <code>flat</code> attribute:</p> <pre><code>for i in c.flat:\nprint(\"Item:\", i)\n</code></pre> Output <p>Item: 0 Item: 1 Item: 2 Item: 3 Item: 4 Item: 5 Item: 6 Item: 7 Item: 8 Item: 9 Item: 10 Item: 11 Item: 12 Item: 13 Item: 14 Item: 15 Item: 16 Item: 17 Item: 18 Item: 19 Item: 20 Item: 21 Item: 22 Item: 23</p>"},{"location":"courses/Tools/numpy/#stacking-arrays","title":"Stacking arrays","text":"<p>It is often useful to stack together different arrays. NumPy offers several functions to do just that. Let\u2019s start by creating a few arrays.</p> <pre><code>q1 = np.full((3,4), 1.0)\nq1\n</code></pre> Output <p>array([[ 1.,  1.,  1.,  1.],        [ 1.,  1.,  1.,  1.],        [ 1.,  1.,  1.,  1.]])</p> <pre><code>q2 = np.full((4,4), 2.0)\nq2\n</code></pre> Output <p>array([[ 2.,  2.,  2.,  2.],        [ 2.,  2.,  2.,  2.],        [ 2.,  2.,  2.,  2.],        [ 2.,  2.,  2.,  2.]])</p> <pre><code>q3 = np.full((3,4), 3.0)\nq3\n</code></pre> Output <p>array([[ 3.,  3.,  3.,  3.],        [ 3.,  3.,  3.,  3.],        [ 3.,  3.,  3.,  3.]])</p>"},{"location":"courses/Tools/numpy/#vstack","title":"vstack","text":"<p>Now let\u2019s stack them vertically using <code>vstack</code>:</p> <pre><code>q4 = np.vstack((q1, q2, q3))\nq4\n</code></pre> Output <p>array([[ 1.,  1.,  1.,  1.],        [ 1.,  1.,  1.,  1.],        [ 1.,  1.,  1.,  1.],        [ 2.,  2.,  2.,  2.],        [ 2.,  2.,  2.,  2.],        [ 2.,  2.,  2.,  2.],        [ 2.,  2.,  2.,  2.],        [ 3.,  3.,  3.,  3.],        [ 3.,  3.,  3.,  3.],        [ 3.,  3.,  3.,  3.]])</p> <pre><code>q4.shape\n</code></pre> Output <p>(10, 4)</p> <p>This was possible because q1, q2 and q3 all have the same shape (except for the vertical axis, but that\u2019s ok since we are stacking on that axis).</p>"},{"location":"courses/Tools/numpy/#hstack","title":"hstack","text":"<p>We can also stack arrays horizontally using <code>hstack</code>:</p> <pre><code>q5 = np.hstack((q1, q3))\nq5\n</code></pre> Output <p>array([[ 1.,  1.,  1.,  1.,  3.,  3.,  3.,  3.],        [ 1.,  1.,  1.,  1.,  3.,  3.,  3.,  3.],        [ 1.,  1.,  1.,  1.,  3.,  3.,  3.,  3.]])</p> <pre><code>q5.shape\n</code></pre> Output <p>(3, 8)</p> <p>This is possible because q1 and q3 both have 3 rows. But since q2 has 4 rows, it cannot be stacked horizontally with q1 and q3:</p> <pre><code>try:\nq5 = np.hstack((q1, q2, q3))\nexcept ValueError as e:\nprint(e)\n</code></pre> Output <p>all the input array dimensions except for the concatenation axis must match exactly</p>"},{"location":"courses/Tools/numpy/#concatenate","title":"concatenate","text":"<p>The <code>concatenate</code> function stacks arrays along any given existing axis.</p> <pre><code>q7 = np.concatenate((q1, q2, q3), axis=0)  # Equivalent to vstack\nq7\n</code></pre> Output <p>array([[ 1.,  1.,  1.,  1.],        [ 1.,  1.,  1.,  1.],        [ 1.,  1.,  1.,  1.],        [ 2.,  2.,  2.,  2.],        [ 2.,  2.,  2.,  2.],        [ 2.,  2.,  2.,  2.],        [ 2.,  2.,  2.,  2.],        [ 3.,  3.,  3.,  3.],        [ 3.,  3.,  3.,  3.],        [ 3.,  3.,  3.,  3.]])</p> <pre><code>q7.shape\n</code></pre> Output <p>(10, 4)</p> <p>As you might guess, <code>hstack</code> is equivalent to calling <code>concatenate</code> with <code>axis=1</code>.</p>"},{"location":"courses/Tools/numpy/#stack","title":"stack","text":"<p>The <code>stack</code> function stacks arrays along a new axis. All arrays have to have the same shape.</p> <pre><code>q8 = np.stack((q1, q3))\nq8\n</code></pre> Output <p>array([[[ 1.,  1.,  1.,  1.],         [ 1.,  1.,  1.,  1.],         [ 1.,  1.,  1.,  1.]],</p> <pre><code>   [[ 3.,  3.,  3.,  3.],\n    [ 3.,  3.,  3.,  3.],\n    [ 3.,  3.,  3.,  3.]]])\n</code></pre> <pre><code>q8.shape\n</code></pre> Output <p>(2, 3, 4)</p>"},{"location":"courses/Tools/numpy/#splitting-arrays","title":"Splitting arrays","text":"<p>Splitting is the opposite of stacking. For example, let\u2019s use the <code>vsplit</code> function to split a matrix vertically.</p> <p>First let\u2019s create a 6x4 matrix:</p> <pre><code>r = np.arange(24).reshape(6,4)\nr\n</code></pre> Output <p>array([[ 0,  1,  2,  3],        [ 4,  5,  6,  7],        [ 8,  9, 10, 11],        [12, 13, 14, 15],        [16, 17, 18, 19],        [20, 21, 22, 23]])</p> <p>Now let\u2019s split it in three equal parts, vertically:</p> <pre><code>r1, r2, r3 = np.vsplit(r, 3)\nr1\n</code></pre> Output <p>array([[0, 1, 2, 3],        [4, 5, 6, 7]])</p> <pre><code>r2\n</code></pre> Output <p>array([[ 8,  9, 10, 11],        [12, 13, 14, 15]])</p> <pre><code>r3\n</code></pre> Output <p>array([[16, 17, 18, 19],        [20, 21, 22, 23]])</p> <p>There is also a <code>split</code> function which splits an array along any given axis. Calling <code>vsplit</code> is equivalent to calling <code>split</code> with <code>axis=0</code>. There is also an <code>hsplit</code> function, equivalent to calling <code>split</code> with <code>axis=1</code>:</p> <pre><code>r4, r5 = np.hsplit(r, 2)\nr4\n</code></pre> Output <p>array([[ 0,  1],        [ 4,  5],        [ 8,  9],        [12, 13],        [16, 17],        [20, 21]])</p> <pre><code>r5\n</code></pre> Output <p>array([[ 2,  3],        [ 6,  7],        [10, 11],        [14, 15],        [18, 19],        [22, 23]])</p>"},{"location":"courses/Tools/numpy/#transposing-arrays","title":"Transposing arrays","text":"<p>The <code>transpose</code> method creates a new view on an <code>ndarray</code>\u2018s data, with axes permuted in the given order.</p> <p>For example, let\u2019s create a 3D array:</p> <pre><code>t = np.arange(24).reshape(4,2,3)\nt\n</code></pre> Output <p>array([[[ 0,  1,  2],         [ 3,  4,  5]],</p> <pre><code>   [[ 6,  7,  8],\n    [ 9, 10, 11]],\n\n   [[12, 13, 14],\n    [15, 16, 17]],\n\n   [[18, 19, 20],\n    [21, 22, 23]]])\n</code></pre> <p>Now let\u2019s create an <code>ndarray</code> such that the axes <code>0, 1, 2</code> (depth, height, width) are re-ordered to <code>1, 2, 0</code> (depth\u2192width, height\u2192depth, width\u2192height):</p> <pre><code>t1 = t.transpose((1,2,0))\nt1\n</code></pre> Output <p>array([[[ 0,  6, 12, 18],         [ 1,  7, 13, 19],         [ 2,  8, 14, 20]],</p> <pre><code>   [[ 3,  9, 15, 21],\n    [ 4, 10, 16, 22],\n    [ 5, 11, 17, 23]]])\n</code></pre> <pre><code>t1.shape\n</code></pre> Output <p>(2, 3, 4)</p> <p>By default, <code>transpose</code> reverses the order of the dimensions:</p> <pre><code>t2 = t.transpose()  # equivalent to t.transpose((2, 1, 0))\nt2\n</code></pre> Output <p>array([[[ 0,  6, 12, 18],         [ 3,  9, 15, 21]],</p> <pre><code>   [[ 1,  7, 13, 19],\n    [ 4, 10, 16, 22]],\n\n   [[ 2,  8, 14, 20],\n    [ 5, 11, 17, 23]]])\n</code></pre> <pre><code>t2.shape\n</code></pre> Output <p>(3, 2, 4)</p> <p>NumPy provides a convenience function <code>swapaxes</code> to swap two axes. For example, let\u2019s create a new view of <code>t</code> with depth and height swapped:</p> <pre><code>t3 = t.swapaxes(0,1)  # equivalent to t.transpose((1, 0, 2))\nt3\n</code></pre> Output <p>array([[[ 0,  1,  2],         [ 6,  7,  8],         [12, 13, 14],         [18, 19, 20]],</p> <pre><code>   [[ 3,  4,  5],\n    [ 9, 10, 11],\n    [15, 16, 17],\n    [21, 22, 23]]])\n</code></pre> <pre><code>t3.shape\n</code></pre> Output <p>(2, 4, 3)</p>"},{"location":"courses/Tools/numpy/#linear-algebra","title":"Linear algebra","text":"<p>NumPy 2D arrays can be used to represent matrices efficiently in python. We will just quickly go through some of the main matrix operations available. For more details about Linear Algebra, vectors and matrics, go through the Linear Algebra tutorial.</p>"},{"location":"courses/Tools/numpy/#matrix-transpose","title":"Matrix transpose","text":"<p>The <code>T</code> attribute is equivalent to calling <code>transpose()</code> when the rank is \u22652:</p> <pre><code>m1 = np.arange(10).reshape(2,5)\nm1\n</code></pre> Output <p>array([[0, 1, 2, 3, 4],        [5, 6, 7, 8, 9]])</p> <pre><code>m1.T\n</code></pre> Output <p>array([[0, 5],        [1, 6],        [2, 7],        [3, 8],        [4, 9]])</p> <p>The <code>T</code> attribute has no effect on rank 0 (empty) or rank 1 arrays:</p> <pre><code>m2 = np.arange(5)\nm2\n</code></pre> Output <p>array([0, 1, 2, 3, 4])</p> <pre><code>m2.T\n</code></pre> Output <p>array([0, 1, 2, 3, 4])</p> <p>We can get the desired transposition by first reshaping the 1D array to a single-row matrix (2D):</p> <pre><code>m2r = m2.reshape(1,5)\nm2r\n</code></pre> Output <p>array([[0, 1, 2, 3, 4]])</p> <pre><code>m2r.T\n</code></pre> Output <p>array([[0],       [1],       [2],       [3],       [4]])</p>"},{"location":"courses/Tools/numpy/#matrix-multiplication","title":"Matrix multiplication","text":"<p>Let\u2019s create two matrices and execute a matrix multiplication using the <code>dot()</code> method.</p> <pre><code>n1 = np.arange(10).reshape(2, 5)\nn1\n</code></pre> Output <p>array([[0, 1, 2, 3, 4],        [5, 6, 7, 8, 9]])</p> <pre><code>n2 = np.arange(15).reshape(5,3)\nn2\n</code></pre> Output <p>array([[ 0,  1,  2],        [ 3,  4,  5],        [ 6,  7,  8],        [ 9, 10, 11],        [12, 13, 14]])</p> <pre><code>n1.dot(n2)\n</code></pre> Output <p>array([[ 90, 100, 110],        [240, 275, 310]])</p> <p>Caution</p> <p>As mentionned previously, <code>n1*n2</code> is not a matric multiplication, it is an elementwise product (also called a Hadamard product).</p>"},{"location":"courses/Tools/numpy/#matrix-inverse-and-pseudo-inverse","title":"Matrix inverse and pseudo-inverse","text":"<p>Many of the linear algebra functions are available in the <code>numpy.linalg</code> module, in particular the <code>inv</code> function to compute a square matrix\u2019s inverse:</p> <pre><code>import numpy.linalg as linalg\nm3 = np.array([[1,2,3],[5,7,11],[21,29,31]])\nm3\n</code></pre> Output <p>array([[ 1,  2,  3],        [ 5,  7, 11],        [21, 29, 31]])</p> <pre><code>linalg.inv(m3)\n</code></pre> Output <p>array([[-2.31818182,  0.56818182,  0.02272727],        [ 1.72727273, -0.72727273,  0.09090909],        [-0.04545455,  0.29545455, -0.06818182]])</p> <p>You can also compute the pseudoinverse using <code>pinv</code>:</p> <pre><code>linalg.pinv(m3)\n</code></pre> Output <p>array([[-2.31818182,  0.56818182,  0.02272727],        [ 1.72727273, -0.72727273,  0.09090909],        [-0.04545455,  0.29545455, -0.06818182]])</p>"},{"location":"courses/Tools/numpy/#identity-matrix","title":"Identity matrix","text":"<p>The product of a matrix by its inverse returns the identiy matrix (with small floating point errors):</p> <pre><code>m3.dot(linalg.inv(m3))\n</code></pre> Output <p>array([[  1.00000000e+00,  -1.11022302e-16,  -6.93889390e-18],        [ -1.33226763e-15,   1.00000000e+00,  -5.55111512e-17],        [  2.88657986e-15,   0.00000000e+00,   1.00000000e+00]])</p> <p>You can create an identity matrix of size NxN by calling <code>eye</code>:</p> <pre><code>np.eye(3)\n</code></pre> Output <p>array([[ 1.,  0.,  0.],        [ 0.,  1.,  0.],        [ 0.,  0.,  1.]])</p>"},{"location":"courses/Tools/numpy/#qr-decomposition","title":"QR decomposition","text":"<p>The <code>qr</code> function computes the QR decomposition of a matrix:</p> <pre><code>q, r = linalg.qr(m3)\nq\n</code></pre> Output <p>array([[-0.04627448,  0.98786672,  0.14824986],        [-0.23137241,  0.13377362, -0.96362411],        [-0.97176411, -0.07889213,  0.22237479]])</p> <pre><code>r\n</code></pre> Output <p>array([[-21.61018278, -29.89331494, -32.80860727],        [  0.        ,   0.62427688,   1.9894538 ],        [  0.        ,   0.        ,  -3.26149699]])</p> <pre><code>q.dot(r)  # q.r equals m3\n</code></pre> Output <p>array([[  1.,   2.,   3.],        [  5.,   7.,  11.],        [ 21.,  29.,  31.]])</p>"},{"location":"courses/Tools/numpy/#determinant","title":"Determinant","text":"<p>The <code>det</code> function computes the matrix determinant:</p> <pre><code>linalg.det(m3)  # Computes the matrix determinant\n</code></pre> Output <p>43.999999999999972</p>"},{"location":"courses/Tools/numpy/#eigenvalues-and-eigenvectors","title":"Eigenvalues and eigenvectors","text":"<p>The <code>eig</code> function computes the eigenvalues and eigenvectors of a square matrix:</p> <pre><code>eigenvalues, eigenvectors = linalg.eig(m3)\neigenvalues # \u03bb\n</code></pre> Output <p>array([ 42.26600592,  -0.35798416,  -2.90802176])</p> <pre><code>eigenvectors # v\n</code></pre> Output <p>array([[-0.08381182, -0.76283526, -0.18913107],        [-0.3075286 ,  0.64133975, -0.6853186 ],        [-0.94784057, -0.08225377,  0.70325518]])</p> <pre><code>m3.dot(eigenvectors) - eigenvalues * eigenvectors  # m3.v - \u03bb*v = 0\n</code></pre> Output <p>array([[  8.88178420e-15,   2.49800181e-15,  -3.33066907e-16],        [  1.77635684e-14,  -1.66533454e-16,  -3.55271368e-15],        [  3.55271368e-14,   3.61516372e-15,  -4.44089210e-16]])</p>"},{"location":"courses/Tools/numpy/#singular-value-decomposition","title":"Singular Value Decomposition","text":"<p>The <code>svd</code> function takes a matrix and returns its singular value decomposition:</p> <pre><code>m4 = np.array([[1,0,0,0,2], [0,0,3,0,0], [0,0,0,0,0], [0,2,0,0,0]])\nm4\n</code></pre> Output <p>array([[1, 0, 0, 0, 2],        [0, 0, 3, 0, 0],        [0, 0, 0, 0, 0],        [0, 2, 0, 0, 0]])</p> <pre><code>U, S_diag, V = linalg.svd(m4)\nU\n</code></pre> Output <p>array([[ 0.,  1.,  0.,  0.],        [ 1.,  0.,  0.,  0.],        [ 0.,  0.,  0., -1.],        [ 0.,  0.,  1.,  0.]])</p> <pre><code>S_diag\n</code></pre> Output <p>array([ 3.        ,  2.23606798,  2.        ,  0.        ])</p> <p>The <code>svd</code> function just returns the values in the diagonal of \u03a3, but we want the full \u03a3 matrix, so let\u2019s create it:</p> <pre><code>S = np.zeros((4, 5))\nS[np.diag_indices(4)] = S_diag\nS  # \u03a3\n</code></pre> Output <p>array([[ 3.        ,  0.        ,  0.        ,  0.        ,  0.        ],        [ 0.        ,  2.23606798,  0.        ,  0.        ,  0.        ],        [ 0.        ,  0.        ,  2.        ,  0.        ,  0.        ],        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ]])</p> <pre><code>V\n</code></pre> Output <p>array([[-0.        ,  0.        ,  1.        , -0.        ,  0.        ],        [ 0.4472136 ,  0.        ,  0.        ,  0.        ,  0.89442719],        [-0.        ,  1.        ,  0.        , -0.        ,  0.        ],        [ 0.        ,  0.        ,  0.        ,  1.        ,  0.        ],        [-0.89442719,  0.        ,  0.        ,  0.        ,  0.4472136 ]])</p> <pre><code>U.dot(S).dot(V) # U.\u03a3.V == m4\n</code></pre> Output <p>array([[ 1.,  0.,  0.,  0.,  2.],        [ 0.,  0.,  3.,  0.,  0.],        [ 0.,  0.,  0.,  0.,  0.],        [ 0.,  2.,  0.,  0.,  0.]])</p>"},{"location":"courses/Tools/numpy/#diagonal-and-trace","title":"Diagonal and trace","text":"<pre><code>np.diag(m3)  # the values in the diagonal of m3 (top left to bottom right)\n</code></pre> Output <p>array([ 1,  7, 31])</p> <pre><code>np.trace(m3)  # equivalent to np.diag(m3).sum()\n</code></pre> Output <p>39</p>"},{"location":"courses/Tools/numpy/#solving-a-system-of-linear-scalar-equations","title":"Solving a system of linear scalar equations","text":"<p>The <code>solve</code> function solves a system of linear scalar equations, such as:</p> <ul> <li>\\(2x + 6y = 6\\)</li> <li>\\(5x + 3y = -9\\)</li> </ul> <pre><code>coeffs  = np.array([[2, 6], [5, 3]])\ndepvars = np.array([6, -9])\nsolution = linalg.solve(coeffs, depvars)\nsolution\n</code></pre> Output <p>array([-3.,  2.])</p> <p>Let\u2019s check the solution:</p> <pre><code>coeffs.dot(solution), depvars  # yep, it's the same\n</code></pre> Output <p>(array([ 6., -9.]), array([ 6, -9]))</p> <p>Looks good! Another way to check the solution:</p> <pre><code>np.allclose(coeffs.dot(solution), depvars)\n</code></pre> Output <p>True</p>"},{"location":"courses/Tools/numpy/#vectorization","title":"Vectorization","text":"<p>Instead of executing operations on individual array items, one at a time, your code is much more efficient if you try to stick to array operations. This is called vectorization. This way, you can benefit from NumPy\u2019s many optimizations.</p> <p>For example, let\u2019s say we want to generate a 768x1024 array based on the formula \\(sin(xy/40.5)\\). A bad option would be to do the math in python using nested loops:</p> <pre><code>import math\ndata = np.empty((768, 1024))\nfor y in range(768):\nfor x in range(1024):\ndata[y, x] = math.sin(x*y/40.5)  # BAD! Very inefficient.\n</code></pre> <p>Sure, this works, but it\u2019s terribly inefficient since the loops are taking place in pure python. Let\u2019s vectorize this algorithm. First, we will use NumPy\u2019s <code>meshgrid</code> function which generates coordinate matrices from coordinate vectors.</p> <pre><code>x_coords = np.arange(0, 1024)  # [0, 1, 2, ..., 1023]\ny_coords = np.arange(0, 768)   # [0, 1, 2, ..., 767]\nX, Y = np.meshgrid(x_coords, y_coords)\nX\n</code></pre> Output <p>array([[   0,    1,    2, \u2026, 1021, 1022, 1023],        [   0,    1,    2, \u2026, 1021, 1022, 1023],        [   0,    1,    2, \u2026, 1021, 1022, 1023],        \u2026,         [   0,    1,    2, \u2026, 1021, 1022, 1023],        [   0,    1,    2, \u2026, 1021, 1022, 1023],        [   0,    1,    2, \u2026, 1021, 1022, 1023]])</p> <pre><code>Y\n</code></pre> Output <p>array([[  0,   0,   0, \u2026,   0,   0,   0],        [  1,   1,   1, \u2026,   1,   1,   1],        [  2,   2,   2, \u2026,   2,   2,   2],        \u2026,         [765, 765, 765, \u2026, 765, 765, 765],        [766, 766, 766, \u2026, 766, 766, 766],        [767, 767, 767, \u2026, 767, 767, 767]])</p> <p>As you can see, both <code>X</code> and <code>Y</code> are 768x1024 arrays, and all values in <code>X</code> correspond to the horizontal coordinate, while all values in <code>Y</code> correspond to the the vertical coordinate.</p> <p>Now we can simply compute the result using array operations:</p> <pre><code>data = np.sin(X*Y/40.5)\n</code></pre> <p>Now we can plot this data using matplotlib\u2019s <code>imshow</code> function</p> <pre><code>import matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nfig = plt.figure(1, figsize=(7, 6))\nplt.imshow(data, cmap=cm.hot, interpolation=\"bicubic\")\nplt.show()\n</code></pre>"},{"location":"courses/Tools/numpy/#saving-and-loading","title":"Saving and loading","text":"<p>NumPy makes it easy to save and load <code>ndarray</code>s in binary or text format.</p>"},{"location":"courses/Tools/numpy/#binary-npy-format","title":"Binary <code>.npy</code> format","text":"<p>Let\u2019s create a random array and save it.</p> <pre><code>a = np.random.rand(2,3)\na\n</code></pre> Output <p>array([[ 0.41307972,  0.20933385,  0.32025581],        [ 0.19853514,  0.408001  ,  0.6038287 ]])</p> <pre><code>np.save(\"my_array\", a)\n</code></pre> <p>Done! Since the file name contains no file extension was provided, NumPy automatically added <code>.npy</code>. Let\u2019s take a peek at the file content:</p> <pre><code>with open(\"my_array.npy\", \"rb\") as f:\ncontent = f.read()\ncontent\n</code></pre> Output <p>\u201c\\x93NUMPY\\x01\\x00F\\x00{\u2018descr\u2019: \u2018\\x12\\x7f\\xd4?x&lt;h\\x81\\x99i\\xc9?@\\xa4\\x027\\xb0\\x1c\\xda?&lt;P\\x05\\x8f\\x90R\\xe3?\u201d <p>To load this file into a NumPy array, simply call <code>load</code>:</p> <pre><code>a_loaded = np.load(\"my_array.npy\")\na_loaded\n</code></pre> Output <p>array([[ 0.41307972,  0.20933385,  0.32025581],        [ 0.19853514,  0.408001  ,  0.6038287 ]])</p>"},{"location":"courses/Tools/numpy/#text-format","title":"Text format","text":"<p>Let\u2019s try saving the array in text format:</p> <pre><code>np.savetxt(\"my_array.csv\", a)\n</code></pre> <p>Now let\u2019s look at the file content:</p> <pre><code>with open(\"my_array.csv\", \"rt\") as f:\nprint(f.read())\n</code></pre> Output <p>4.130797191668116319e-01 2.093338525574361952e-01 3.202558143634371968e-01 1.985351449843368865e-01 4.080009972772735694e-01 6.038286965726977762e-01</p> <p>This is a CSV file with tabs as delimiters. You can set a different delimiter:</p> <pre><code>np.savetxt(\"my_array.csv\", a, delimiter=\",\")\n</code></pre> <p>To load this file, just use <code>loadtxt</code>:</p> <pre><code>a_loaded = np.loadtxt(\"my_array.csv\", delimiter=\",\")\na_loaded\n</code></pre> Output <p>array([[ 0.41307972,  0.20933385,  0.32025581],        [ 0.19853514,  0.408001  ,  0.6038287 ]])</p>"},{"location":"courses/Tools/numpy/#zipped-npz-format","title":"Zipped <code>.npz</code> format","text":"<p>It is also possible to save multiple arrays in one zipped file:</p> <pre><code>b = np.arange(24, dtype=np.uint8).reshape(2, 3, 4)\nb\n</code></pre> Output <p>array([[[ 0,  1,  2,  3],         [ 4,  5,  6,  7],         [ 8,  9, 10, 11]],</p> <pre><code>   [[12, 13, 14, 15],\n    [16, 17, 18, 19],\n    [20, 21, 22, 23]]], dtype=uint8)\n</code></pre> <pre><code>np.savez(\"my_arrays\", my_a=a, my_b=b)\n</code></pre> <p>Again, let\u2019s take a peek at the file content. Note that the <code>.npz</code> file extension was automatically added.</p> <pre><code>with open(\"my_arrays.npz\", \"rb\") as f:\ncontent = f.read()\nrepr(content)[:180] + \"[...]\"\n</code></pre> Output <p>u\u2018\u201cPK\\x03\\x04\\x14\\x00\\x00\\x00\\x00\\x00x\\x94cH\\xb6\\x96\\xe4{h\\x00\\x00\\x00h\\x00\\x00\\x00\\x08\\x00\\x00\\x00my_b.npy\\x93NUMPY\\x01\\x00F\\x00{'descr': '|u1', 'fortran_order': False, 'shape': (2,[\u2026]\u2019</p> <p>You then load this file like so:</p> <pre><code>my_arrays = np.load(\"my_arrays.npz\")\nmy_arrays\n</code></pre> Output <p> <p>This is a dict-like object which loads the arrays lazily:</p> <pre><code>my_arrays.keys()\n</code></pre> Output <p>[\u2018my_b\u2019, \u2018my_a\u2019]</p> <pre><code>my_arrays[\"my_a\"]\n</code></pre> Output <p>array([[ 0.41307972,  0.20933385,  0.32025581],        [ 0.19853514,  0.408001  ,  0.6038287 ]])</p>"},{"location":"courses/Tools/numpy/#what-next","title":"What next?","text":"<p>Now you know all the fundamentals of NumPy, but there are many more options available. The best way to learn more is to experiment with NumPy, and go through the excellent reference documentation to find more functions and features you may be interested in.</p>"},{"location":"projects/Reciprocal-n-body-Collision-Avoidance/","title":"Reciprocal n-body Collision Avoidance","text":""},{"location":"projects/Reciprocal-n-body-Collision-Avoidance/#importer-les-packages","title":"Importer les Packages","text":"<p>Packages</p> <ul> <li> <p>NumPy : NumPy est une biblioth\u00e8que Python populaire pour le calcul scientifique qui fournit des structures de donn\u00e9es pour la repr\u00e9sentation de tableaux multidimensionnels et des fonctions pour manipuler ces tableaux.</p> </li> <li> <p>Matplotlib : Matplotlib est une biblioth\u00e8que en Python utilis\u00e9e pour tracer des graphiques et des visualisations.</p> </li> <li> <p>heapq : heapq est un module Python qui impl\u00e9mente les algorithmes d\u2019heaps ou de tas pour des structures de donn\u00e9es.</p> </li> <li> <p>math : Le module math en Python fournit des fonctions math\u00e9matiques courantes, telles que les fonctions trigonom\u00e9triques, exponentielles, logarithmiques, etc.</p> </li> <li> <p>CVXOPT : CVXOPT est une biblioth\u00e8que open source Python pour l\u2019optimisation convexe. Elle est utilis\u00e9e pour r\u00e9soudre des probl\u00e8mes d\u2019optimisation convexe tels que la programmation lin\u00e9aire, la programmation quadratique, la programmation semi-d\u00e9finie, la programmation convexe et autres. Elle fournit des solveurs rapides et pr\u00e9cis pour les probl\u00e8mes d\u2019optimisation convexe, y compris des interfaces pour les solvers externes.</p> </li> <li> <p>random : The random module in Python provides a suite of functions for generating random numbers.</p> </li> <li> <p>time : Le module time est un module Python qui fournit diverses fonctions permettant de manipuler le temps.</p> </li> <li> <p>cv2 : cv2 is a library for computer vision and image processing. It is a Python wrapper for OpenCV (Open Source Computer Vision), which is a C++ library that includes numerous computer vision algorithms.</p> </li> <li> <p>IPython : La biblioth\u00e8que IPython fournit un certain nombre d\u2019outils pour faciliter le d\u00e9veloppement et l\u2019analyse de donn\u00e9es en Python.</p> </li> <li> <p>tqdm : tqdm is a Python package that provides a progress bar visualization for iterative tasks, making it easy to see how far along a task is and how much longer it is expected to take.</p> </li> </ul> <pre><code>import numpy\nfrom numpy.linalg import norm\nfrom numpy import dot,array\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Rectangle, Circle\nimport matplotlib.patches as patches\nfrom pylab import show,imshow\nimport heapq\nfrom math import *\nimport cvxopt\nfrom cvxopt import matrix,solvers\nimport random\nimport time\nimport os\nimport matplotlib.animation as animation\nimport cv2\nfrom IPython import display\nfrom tqdm import tqdm\n</code></pre>"},{"location":"projects/Reciprocal-n-body-Collision-Avoidance/#initialiser-la-geometrie","title":"Initialiser la g\u00e9om\u00e9trie","text":"<p>draw</p> <p>On commence par d\u00e9finir la fonction <code>draw</code> qui prend plusieurs arguments en entr\u00e9e et qui trace une sc\u00e8ne avec des agents et des obstacles.</p> <p>Les arguments en entr\u00e9e sont:</p> <p>Ex : une liste des sorties de la sc\u00e8ne</p> <p>Obs : une liste des obstacles rectangulaires</p> <p>Obs_cir : une liste des obstacles circulaires</p> <p>scene : une paire (L, l) qui repr\u00e9sente les dimensions de la sc\u00e8ne</p> <p>agents : une liste d\u2019agents, o\u00f9 chaque agent est repr\u00e9sent\u00e9 par sa position, sa taille et sa couleur</p> <p>t : temps de simulation</p> <p>savepath : le chemin pour enregistrer la figure g\u00e9n\u00e9r\u00e9e</p> <p>play : un bool\u00e9en qui sp\u00e9cifie si l\u2019animation doit \u00eatre affich\u00e9e ou non</p> <p>La fonction commence par cr\u00e9er une figure et un axe avec une taille d\u00e9termin\u00e9e par la dimension de la sc\u00e8ne. Ensuite, elle dessine les obstacles, les sorties et les agents sur la figure. Les obstacles rectangulaires sont repr\u00e9sent\u00e9s par des rectangles noirs, les obstacles circulaires par des cercles noirs, les sorties par des rectangles orange et les agents par des cercles de couleur.</p> <p>Enfin, la fonction sauvegarde la figure \u00e0 l\u2019emplacement sp\u00e9cifi\u00e9 par \u201csavepath\u201d. Si \u201cplay\u201d est faux, la figure est ferm\u00e9e.</p> <pre><code>def draw(Ex, Obs, Obs_cir, scene, agents, t, savepath, play = False):\nL , l = scene\nratio = l/L\nc = 10\nfig, ax = plt.subplots(figsize=(c/ratio,c))\ntitle = ax.text(0.5, 1.05, \"Temps de simulation : %s s \\n Nombre des agents : %s\" %(t,len(agents)), \ntransform=ax.transAxes, ha=\"center\", size=20)\n#Draw the environment\nplt.plot([0, L], [0, 0], 'white')\nplt.plot([L, L], [0, l], 'white')\nplt.plot([L, 0], [l,l], 'white')\nplt.plot([0,0], [l,0], 'white')\n#Draw Obstacle\nfor obs in Obs:\nrect = Rectangle(obs.position, obs.width, obs.height)\nrect.set_color('black')\nax.add_patch(rect)\n#Draw Obstacle Cir\nfor obs in Obs_cir:\ncircle = Circle(obs.position, obs.rayon)\ncircle.set_color('black')\nax.add_patch(circle)\n#Draw exits\nfor e in Ex:\nrect = Rectangle(e.position, e.width, e.height)\nrect.set_color('orange')\nax.add_patch(rect)\n#Draw agents\nfor agent in agents:\nx,y = agent.position\ncircle = Circle((x,y), agent.size)\ncircle.set_color(agent.color)\nax.add_patch(circle)\nplt.xticks(fontsize=20)\nplt.yticks(fontsize=20)\nfig.savefig(savepath)\nif not play:\nplt.close()\n</code></pre> <p>record_video</p> <p>La fonction appel\u00e9e <code>record_video</code> prend un argument optionnel speed (dont la valeur par d\u00e9faut est 25). Le but de cette fonction est de cr\u00e9er une vid\u00e9o \u00e0 partir d\u2019une s\u00e9quence d\u2019images sauvegard\u00e9es dans un r\u00e9pertoire, et de sauvegarder le fichier vid\u00e9o r\u00e9sultant dans le r\u00e9pertoire de travail actuel. Les arguments pass\u00e9s \u00e0 cette fonction sont les suivants :</p> <p>speed : une valeur enti\u00e8re repr\u00e9sentant le nombre d\u2019images par seconde de la vid\u00e9o r\u00e9sultante (c\u2019est-\u00e0-dire le taux de rafra\u00eechissement de la vid\u00e9o).</p> <p>La fonction commence par imprimer un message indiquant qu\u2019elle commence l\u2019enregistrement de la vid\u00e9o. Ensuite, elle lit la premi\u00e8re image de la s\u00e9quence d\u2019images pour d\u00e9terminer les dimensions de la vid\u00e9o.</p> <p>Elle cr\u00e9e ensuite un objet VideoWriter en utilisant la m\u00e9thode cv2.VideoWriter d\u2019OpenCV, en sp\u00e9cifiant le nom du fichier de sortie, le codec vid\u00e9o (dans ce cas XVID), le taux de rafra\u00eechissement et les dimensions de la vid\u00e9o (bas\u00e9es sur les dimensions de la premi\u00e8re image).</p> <p>Ensuite, elle boucle sur les images restantes de la s\u00e9quence et ajoute chacune \u00e0 la vid\u00e9o \u00e0 l\u2019aide de la m\u00e9thode video.write(). Les images sont lues en utilisant la m\u00e9thode cv2.imread() d\u2019OpenCV, qui lit une image \u00e0 partir d\u2019un chemin de fichier sp\u00e9cifi\u00e9.</p> <p>Enfin, la fonction nettoie toutes les fen\u00eatres qui ont pu \u00eatre cr\u00e9\u00e9es pendant le processus et lib\u00e8re l\u2019objet vid\u00e9o. Elle affiche un message indiquant que la vid\u00e9o a \u00e9t\u00e9 sauvegard\u00e9e.</p> <pre><code>def record_video(speed = 25):\nprint('Recording video ...')\nframe = cv2.imread('DossierImages/simulation' + str(10) + '.jpg')\nheight, width, layers = frame.shape\nfourcc = cv2.VideoWriter_fourcc(*'XVID')\nvideo = cv2.VideoWriter('video.avi', fourcc, speed, (width,height))\nfor k in range(N_iter):\nvideo.write(cv2.imread('DossierImages/simulation' + str(k+1) + '.jpg'))\ncv2.destroyAllWindows()\nvideo.release()\nprint('Video saved.')\n</code></pre> <p>generate_indiv</p> <p>La fonction <code>generate_indiv(N)</code> cr\u00e9e une liste de N agents en v\u00e9rifiant qu\u2019ils ne se chevauchent pas et ne traversent pas les obstacles. Voici les \u00e9tapes principales :</p> <ul> <li> <p> La fonction d\u00e9finit la taille de la sc\u00e8ne, ainsi que des variables pour la distance minimale entre les agents et pour le rayon de chaque agent.</p> </li> <li> <p> La fonction cr\u00e9e une liste vide L qui contiendra les agents, puis elle commence une boucle qui s\u2019arr\u00eatera quand il y aura N agents dans la liste L.</p> </li> <li> <p> \u00c0 chaque it\u00e9ration de la boucle, la fonction g\u00e9n\u00e8re une position al\u00e9atoire pour un nouvel agent en utilisant des fonctions al\u00e9atoires et l\u2019ajoute \u00e0 une liste temporaire q, qui contient les positions de tous les agents d\u00e9j\u00e0 cr\u00e9\u00e9s, ainsi que les rayons de ces agents, qui sont stock\u00e9s dans la liste R.</p> </li> <li> <p> Ensuite, la fonction v\u00e9rifie s\u2019il y a une collision entre le nouvel agent et les agents d\u00e9j\u00e0 cr\u00e9\u00e9s. Si c\u2019est le cas, la variable choc est d\u00e9finie sur True, ce qui signifie qu\u2019il y a eu une collision et que le nouvel agent ne sera pas ajout\u00e9 \u00e0 la liste L.</p> </li> <li> <p> Ensuite, la fonction v\u00e9rifie si le nouvel agent entre en collision avec un obstacle. Si c\u2019est le cas, la variable choc est d\u00e9finie sur True.</p> </li> <li> <p> Si le nouvel agent ne provoque pas de collision, il est ajout\u00e9 \u00e0 la liste L.</p> </li> <li> <p> Lorsque N agents ont \u00e9t\u00e9 cr\u00e9\u00e9s et ajout\u00e9s \u00e0 la liste L, la fonction retourne cette liste.</p> </li> </ul> <pre><code>def generate_indiv(N):\ndef rand_float_range(start, end):\nreturn random.random() * (end - start) + start\na , b = size_scene\ndst = 0.2\nr = 0.2\nL = list()\nwhile len(L) &lt; N:\nchoc = False\nq = [agent.position for agent in L]\nR = [agent.size for agent in L]\nx = rand_float_range(int(0),int(a))\ny = rand_float_range(int(0),int(b))\nq.append([x,y])\nR.append(r)\nfor j in range(len(q)-1):\nif dist(q[-1], q[j]) - (R[-1]+R[j]) &lt;= dst:\nchoc = True\nbreak\n#chocs obstacle\nfor obstacle in obstacles_cir:\n[a0, b0], rayon = obstacle.position, obstacle.rayon\nif (x-a0)**2 + (y-b0)**2 &lt; (rayon+3)**2 : choc = True\nfor obstacle in obstacles:\n[a0, b0], w, l = obstacle.position, obstacle.width, obstacle.height\na1, b1 = a0 + w , b0 + l\nif (a0&lt;=x&lt;=a1 and b0-r-0.5&lt;=y&lt;=b1+r+0.5) or (b0&lt;=y&lt;=b1 and a0-r-0.5&lt;=x&lt;=a1+r+0.5): choc = True\nelif distance_vecteur_obs([x,y] , r, obstacle)[0] &lt; 0.5: choc = True\nif not choc:\nagent = myAgent((x,y))\nagent.size = r\nL.append(agent)\nreturn L\n</code></pre> <p>maxiMini &amp; plot_directions</p> <p>La premi\u00e8re fonction, nomm\u00e9e <code>maxiMini(FX,FY)</code>, prend en entr\u00e9e deux listes FX et FY, contenant des valeurs de directions. Cette fonction parcourt les deux listes et recherche la valeur maximale et la valeur minimale des directions dans chaque liste. Elle retourne ensuite ces deux valeurs.</p> <p>La deuxi\u00e8me fonction, nomm\u00e9e <code>plot_directions(FX,FY)</code>, prend \u00e9galement en entr\u00e9e deux listes FX et FY. Cette fonction affiche deux graphiques c\u00f4te \u00e0 c\u00f4te : un pour les directions selon X et un pour les directions selon Y. Les directions sont repr\u00e9sent\u00e9es par des couleurs sur chaque graphique, et les couleurs correspondent \u00e0 des valeurs. Les valeurs minimales et maximales sont obtenues en appelant la fonction <code>maxiMini(FX,FY)</code>. Les graphiques sont affich\u00e9s \u00e0 l\u2019aide de la biblioth\u00e8que Matplotlib. Enfin, cette fonction retourne les graphiques affich\u00e9s.</p> <p>En r\u00e9sum\u00e9, ces deux fonctions permettent de visualiser les directions de mouvement \u00e0 partir de listes de directions selon X et Y.</p> <pre><code>def maxiMini(FX,FY):\nmaxi = 0\nMini = 0\nfor i in range(n):\nfor j in range(len(FX[0])):\nfx , fy = FX[i][j] , FY[i][j]\nif fx != float('inf') and fx != -float('inf') and fy != float('inf') and fy != -float('inf') and not isnan(fx) and not isnan(fy):\nif fx&gt;maxi :\nmaxi = fx\nif fy&gt;maxi :\nmaxi = fy\nif fx&lt;Mini : \nMini = fx\nif fy&lt;Mini :\nMini = fy\nreturn maxi , Mini\ndef plot_directions(FX,FY):\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,15))\nZ = [FX, FY]\ntext = ['Directions selon X', 'Directions selon Y']\nmaxi , Mini = maxiMini(FX,FY)\nfor ax, i in zip(axes.flat, range(2)):\nim = ax.imshow(Z[i], interpolation=\"bicubic\", origin=\"upper\", vmin=Mini, vmax=maxi)\nax.title.set_text(text[i])\nfig.subplots_adjust(right=0.8)\ncbar_ax = fig.add_axes([0.85, 0.35, 0.05, 0.3])\nfig.colorbar(im, cax=cbar_ax)\nplt.show()\n</code></pre> <p>Exit</p> <p>Ce code d\u00e9finit une classe <code>Exit</code> qui repr\u00e9sente une sortie. La classe poss\u00e8de un constructeur (init) qui prend en argument une position, une largeur et une hauteur de la sortie. La position est un tuple de deux \u00e9l\u00e9ments repr\u00e9sentant les coordonn\u00e9es (x, y) du coin sup\u00e9rieur gauche de la sortie.</p> <p>Le constructeur initialise les attributs position, width et height de la classe avec les valeurs pass\u00e9es en argument.</p> <pre><code>class Exit:\ndef __init__(self,position,width,height):\nself.position = position\nself.width = width\nself.height = height\n</code></pre> <p>Obstacle</p> <p>La classe <code>Obstacle</code> a pour but de repr\u00e9senter un obstacle dans une simulation. Elle poss\u00e8de trois attributs : position, width et height, qui correspondent respectivement \u00e0 la position de l\u2019obstacle et \u00e0 sa largeur et hauteur.</p> <p>La m\u00e9thode repr de la classe est une m\u00e9thode sp\u00e9ciale qui renvoie une cha\u00eene de caract\u00e8res repr\u00e9sentant l\u2019objet. Dans ce cas pr\u00e9cis, elle renvoie une cha\u00eene de caract\u00e8res contenant la position de l\u2019obstacle ainsi que les coordonn\u00e9es de ses coins (en supposant que la position correspond au coin en bas \u00e0 gauche).</p> <pre><code>class Obstacle():\ndef __init__(self, position,width,height):\nself.position=position\nself.width=width\nself.height=height\ndef __repr__(self):\nreturn 'Obstacle'+'\\n'+'DL:'+str(self.position)+'DR:'+str((self.position[0]+self.width,self.position[1]))+'UR:'+str((self.position[0]+self.width,self.position[1]+self.height))+'UL:'+str((self.position[0]+self.width,self.position[1]))\n</code></pre> <p>Obstacle_Cir</p> <p>Ce code d\u00e9finit une classe <code>Obstacle_Cir</code> qui repr\u00e9sente un obstacle circulaire.</p> <p>La classe a un constructeur `init qui prend deux param\u00e8tres, position et rayon, qui sont utilis\u00e9s pour initialiser les attributs de l\u2019objet. L\u2019attribut position est un tuple qui repr\u00e9sente la position du centre de l\u2019obstacle sur l\u2019espace de simulation et l\u2019attribut rayon est un nombre flottant qui repr\u00e9sente le rayon de l\u2019obstacle.</p> <pre><code>class Obstacle_Cir():\ndef __init__(self, position,rayon):\nself.position=position\nself.rayon=rayon\n</code></pre>"},{"location":"projects/Reciprocal-n-body-Collision-Avoidance/#fast-marching","title":"Fast Marching","text":"<p>PriorityQueue</p> <p>Cette classe est une impl\u00e9mentation d\u2019une file de priorit\u00e9 (ou heap) en utilisant la biblioth\u00e8que heapq.</p> <p>init(self) : Constructeur de la classe qui initialise la file de priorit\u00e9 et un index pour suivre l\u2019\u00e9l\u00e9ment courant.</p> <p>pop(self) : Cette m\u00e9thode supprime et renvoie l\u2019\u00e9l\u00e9ment le plus petit de la file de priorit\u00e9.</p> <p>remove(self, nodeId) : Cette m\u00e9thode prend un noeud (identifi\u00e9 par nodeId) en entr\u00e9e et supprime cet \u00e9l\u00e9ment de la file de priorit\u00e9.</p> <p>iter(self) : Cette m\u00e9thode renvoie l\u2019it\u00e9rateur sur l\u2019instance de la file de priorit\u00e9.</p> <p>str(self) : Cette m\u00e9thode renvoie une repr\u00e9sentation sous forme de cha\u00eene de la file de priorit\u00e9.</p> <p>append(self, node) : Cette m\u00e9thode ajoute un \u00e9l\u00e9ment dans la file de priorit\u00e9.</p> <p>contains(self, key) : Cette m\u00e9thode renvoie True si la cl\u00e9 est pr\u00e9sente dans la file de priorit\u00e9, False sinon.</p> <p>eq(self, other) : Cette m\u00e9thode v\u00e9rifie si deux files de priorit\u00e9 sont \u00e9gales.</p> <p>getitem(self, nodeId) : Cette m\u00e9thode renvoie l\u2019\u00e9l\u00e9ment correspondant \u00e0 l\u2019ID du n\u0153ud donn\u00e9.</p> <p>clear(self) : Cette m\u00e9thode supprime tous les \u00e9l\u00e9ments de la file de priorit\u00e9.</p> <p>len(self) : Cette m\u00e9thode renvoie la longueur de la file de priorit\u00e9.</p> <p>next = next : Cette m\u00e9thode est utilis\u00e9e pour rendre la file de priorit\u00e9 iterable.</p> <pre><code>class PriorityQueue():\ndef __init__(self):\nself.queue = []\nself.current = 0\ndef pop(self):\nreturn heapq.heappop(self.queue)\ndef remove(self, nodeId):\nfor i in range(len(self.queue)):\nif self.queue[i][1]==nodeId:\nself.queue.pop(i)\nbreak;\ndef __iter__(self):\nreturn self\ndef __str__(self):\nreturn 'PQ:[%s]'%(', '.join([str(i) for i in self.queue]))\ndef append(self, node):\nheapq.heappush(self.queue,node)\ndef __contains__(self, key):\nself.current = 0\nreturn key in [n for _,n in self.queue]\ndef __eq__(self, other):\nself.curent = 0\nreturn self == other\ndef __getitem__(self, nodeId):\nfor element in self.queue:\nif element[1]==nodeId:\nreturn element\nreturn None\ndef clear(self):\nself.queue = []\ndef __len__(self):\nreturn len(self.queue)\n__next__ = next\n</code></pre> <p>GridGraph</p> <p>Ce code d\u00e9finit une classe <code>GridGraph</code> qui repr\u00e9sente une grille. Cette grille est utilis\u00e9e pour simuler un environnement dans lequel une ou plusieurs entit\u00e9s se d\u00e9placent, en utilisant un algorithme de calcul de chemin pour d\u00e9terminer le chemin optimal entre deux points.</p> <p>La classe est initialis\u00e9e avec deux param\u00e8tres, size_scene qui est un tuple repr\u00e9sentant la taille de la sc\u00e8ne (la grille) en unit\u00e9s arbitraires, et precision qui d\u00e9termine le nombre de subdivisions dans la grille. La pr\u00e9cision est utilis\u00e9e pour d\u00e9finir la taille de chaque case dans la grille.</p> <p>La grille est mod\u00e9lis\u00e9e par deux matrices, indicator_map et distances. indicator_map est initialis\u00e9e avec des valeurs de 1 pour chaque case de la grille, et sera modifi\u00e9e plus tard pour inclure des obstacles et des sorties. distances est initialis\u00e9e avec des valeurs inf pour chaque case de la grille.</p> <p>La m\u00e9thode get_neighbours est utilis\u00e9e pour renvoyer les voisins d\u2019un n\u0153ud donn\u00e9, repr\u00e9sent\u00e9 par un tuple d\u2019entiers (x, y) indiquant les coordonn\u00e9es du n\u0153ud sur la grille.</p> <p>La m\u00e9thode to_node est utilis\u00e9e pour convertir des coordonn\u00e9es r\u00e9elles en coordonn\u00e9es de n\u0153uds sur la grille.</p> <p>La m\u00e9thode prepare_graph_for_fast_marching est utilis\u00e9e pour modifier indicator_map en y ajoutant des obstacles et des sorties, afin de pr\u00e9parer la grille pour l\u2019algorithme de calcul de chemin. Les obstacles sont d\u00e9finis comme des rectangles ou des cercles, repr\u00e9sent\u00e9s par des objets Obstacle ou ObstacleCir, et les sorties sont repr\u00e9sent\u00e9es par des objets Exit.</p> <pre><code>class GridGraph:\nglobal OBSTACLE\nglobal EXIT\nOBSTACLE = 0\nEXIT = 2\ndef __init__(self,size_scene,precision):\nself.precision = precision\nself.horizontal_size = int(size_scene[0]*precision)+1\nself.vertical_size = int(size_scene[1]*precision)+1\nself.indicator_map = numpy.ones((self.vertical_size,self.horizontal_size))\nself.distances = numpy.ones((self.vertical_size,self.horizontal_size))*float('inf')\ndef get_neighbours(self,node):\nresult = {};\nif node[1]&lt;self.horizontal_size-1:\nresult['x+1']=(node[0],node[1]+1);\nif node[1]&gt;0:\nresult['x-1']=(node[0],node[1]-1);\nif node[0]&lt;self.vertical_size-1:\nresult['y+1']=(node[0]+1,node[1]);\nif node[0]&gt;0:\nresult['y-1']=(node[0]-1,node[1]);\nreturn result;\ndef to_node(self,coordinates):\nreturn (int(coordinates[1]*self.precision),int(coordinates[0]*self.precision))\ndef prepare_graph_for_fast_marching(self,obstacles, obstacles_cir, exits):\nfor obstacle in obstacles:\ndl = (obstacle.position[0],obstacle.position[1])\nur = (obstacle.position[0]+obstacle.width,obstacle.position[1]+obstacle.height)\nfor x in range(self.to_node(dl)[0]+1,self.to_node(ur)[0]):\nfor y in range(self.to_node(dl)[1]+1,self.to_node(ur)[1]):\nif x&gt;=0 and x&lt;self.indicator_map.shape[0] and y&gt;=0 and y&lt;self.indicator_map.shape[1]:\nself.indicator_map[x,y]=OBSTACLE\nfor obstacle_cir in obstacles_cir:\ndl = (obstacle_cir.position[0] - obstacle_cir.rayon , obstacle_cir.position[1] - obstacle_cir.rayon)\nur = (obstacle_cir.position[0] + obstacle_cir.rayon , obstacle_cir.position[1] + obstacle_cir.rayon)\nfor x in range(self.to_node(dl)[0]+1,self.to_node(ur)[0]):\nfor y in range(self.to_node(dl)[1]+1,self.to_node(ur)[1]):\nif x&gt;=0 and x&lt;self.indicator_map.shape[0] and y&gt;=0 and y&lt;self.indicator_map.shape[1]:\nif (x/self.precision - obstacle_cir.position[1])**2 + (y/self.precision - obstacle_cir.position[0])**2 &lt;= obstacle_cir.rayon**2:\nself.indicator_map[x,y]=OBSTACLE\nfor exit_ in exits:\ndl = (exit_.position[0],exit_.position[1])\nur = (exit_.position[0]+exit_.width,exit_.position[1]+exit_.height)\nfor x in range(self.to_node(dl)[0],self.to_node(ur)[0]+1):\nfor y in range(self.to_node(dl)[1],self.to_node(ur)[1]+1):\nif x&gt;=0 and x&lt;self.indicator_map.shape[0] and y&gt;=0 and y&lt;self.indicator_map.shape[1]:\nself.indicator_map[x,y]=EXIT\n</code></pre> <p>fast_marching_method</p> <p>Le code prend en entr\u00e9e un graphe et un point de d\u00e9part et retourne une carte de distance de tous les n\u0153uds du graphe au point de d\u00e9part.</p> <p>Le code commence par d\u00e9finir une fonction calculus_distance qui prend en entr\u00e9e un n\u0153ud, un graphe et des poids et renvoie la distance de ce n\u0153ud au point de d\u00e9part en utilisant la m\u00e9thode de marche rapide. Cette m\u00e9thode calcule la distance en utilisant la distance aux n\u0153uds voisins pond\u00e9r\u00e9e par des poids qui d\u00e9pendent de la g\u00e9om\u00e9trie du probl\u00e8me.</p> <p>Ensuite, le code initialise une file de priorit\u00e9 frontier, qui contiendra les n\u0153uds \u00e0 explorer, et une liste explored qui contiendra les n\u0153uds d\u00e9j\u00e0 explor\u00e9s. Les poids initiaux des n\u0153uds sont stock\u00e9s dans weights. Les points d\u2019arriv\u00e9e sont trouv\u00e9s dans la carte indicator_map et ajout\u00e9s \u00e0 la file de priorit\u00e9 avec une distance initiale de 0. Les poids des points d\u2019arriv\u00e9e sont \u00e9galement initialis\u00e9s \u00e0 0.</p> <p>La boucle principale commence avec l\u2019extraction d\u2019un n\u0153ud de la file de priorit\u00e9 frontier. La distance \u00e0 ce n\u0153ud est stock\u00e9e dans weights. Les voisins du n\u0153ud sont explor\u00e9s, et si un voisin n\u2019a pas d\u00e9j\u00e0 \u00e9t\u00e9 explor\u00e9 et appartient \u00e0 la grille (indiqu\u00e9 par la carte indicator_map), sa distance au point de d\u00e9part est calcul\u00e9e en utilisant la m\u00e9thode calculus_distance. Si le voisin n\u2019est pas d\u00e9j\u00e0 dans la file de priorit\u00e9, il est ajout\u00e9 avec sa nouvelle distance, sinon, si sa distance calcul\u00e9e est inf\u00e9rieure \u00e0 sa distance actuelle, sa distance et sa priorit\u00e9 dans la file de priorit\u00e9 sont mises \u00e0 jour. Les n\u0153uds explor\u00e9s sont ajout\u00e9s \u00e0 la liste explored.</p> <p>Une fois la file de priorit\u00e9 vid\u00e9e, la carte de distance est stock\u00e9e dans la variable distances de l\u2019objet graphe et renvoy\u00e9e.</p> <pre><code>def fast_marching_method(graph,start):\ndef calculus_distance(node,graph,weights):\nneighbours = graph.get_neighbours(node);\nif 'y-1' in neighbours :\nif 'y+1' in neighbours:\nx1 = min(weights[neighbours['y-1']],weights[neighbours['y+1']]);\nelse :\nx1 = weights[neighbours['y-1']];\nelse :\nif 'y+1' in neighbours:\nx1 = weights[neighbours['y+1']];\nif 'x-1' in neighbours:\nif 'x+1' in neighbours:\nx2 = min(weights[neighbours['x-1']],weights[neighbours['x+1']]);\nelse :\nx2 = weights[neighbours['x-1']];\nelse :\nif 'x+1' in neighbours:\nx2 = weights[neighbours['x+1']];\nif 2*h**2-(x1-x2)**2&gt;=0:\nreturn (x1+x2+(2*h**2-(x1-x2)**2)**0.5)/2\nelse:\nreturn min(x1,x2)+h\nfrontier = PriorityQueue();\nweights = graph.distances;\nexplored = []\ngoals = numpy.where(graph.indicator_map==2)\ngoals_x = goals[0]\ngoals_y = goals[1]\nfor i in range(goals_x.size):\nfrontier.append([0,(goals_x[i],goals_y[i])])\nweights[(goals_x[i],goals_y[i])] = 0\nwhile frontier:\nnode = frontier.pop();\nexplored.append(node[1])\n#if node[1]==start:\n#   return weights\nneighbours = graph.get_neighbours(node[1]);\nfor neighbour in neighbours.values():\nif neighbour not in explored and graph.indicator_map[neighbour]:\nif not neighbour in frontier:\nfrontier.append([calculus_distance(neighbour,graph,weights),neighbour])\nweights[neighbour]=calculus_distance(neighbour,graph,weights)\nelif weights[neighbour] &gt; calculus_distance(neighbour,graph,weights):\nfrontier[neighbour][0]=calculus_distance(neighbour,graph,weights)\nweights[neighbour]=calculus_distance(neighbour,graph,weights)\ngraph.distances = weights\n</code></pre> <p>adjust_FM</p> <p>Ce code permet d\u2019ajuster les fronts d\u2019onde g\u00e9n\u00e9r\u00e9s par la m\u00e9thode de Fast Marching.</p> <p>Le code commence par initialiser deux listes vides, Lx_gauche et Lx_droite. Ces listes vont contenir les coordonn\u00e9es des points du front d\u2019onde qui sont \u00e0 gauche ou \u00e0 droite d\u2019un point infini ou ind\u00e9fini.</p> <p>Ensuite, le code parcourt les fronts d\u2019onde et ajoute les coordonn\u00e9es des points \u00e0 la liste Lx_gauche ou Lx_droite si ces points sont \u00e0 gauche ou \u00e0 droite d\u2019un point infini ou ind\u00e9fini. Il en fait de m\u00eame pour les coordonn\u00e9es des points du front d\u2019onde qui sont en haut ou en bas d\u2019un point infini ou ind\u00e9fini, qu\u2019il ajoute aux listes Ly_haut et Ly_bas.</p> <p>Enfin, le code remplace les valeurs des points des fronts d\u2019onde contenus dans les listes Lx_gauche, Lx_droite, Ly_haut et Ly_bas par les valeurs de leurs voisins les plus proches, en parcourant les listes et en acc\u00e9dant aux valeurs des tableaux FX et FY correspondant aux fronts d\u2019onde en question.</p> <pre><code>def adjust_FM():\nLx_gauche = []\nLx_droite = []\nfor i in range(1,n):\nfor j in range(1,len(FX[0])-1):\nu , v = FX[i][j] , FX[i][j+1]\nif u == float('inf') or u == -float('inf'):\nif v != float('inf') and v != -float('inf') and not isnan(v):\nLx_gauche.append((i,j))\nif v == float('inf') or v == -float('inf'):\nif u != float('inf') and u != -float('inf') and not isnan(u):\nLx_droite.append((i,j+1))\nfor cellule in Lx_gauche:\ni, j = cellule\nFX[i][j] = FX[i][j+1]\nfor cellule in Lx_droite:\ni, j = cellule\nFX[i][j] = FX[i][j-1]\nLy_haut = []\nLy_bas = []\nfor i in range(1,n-1):\nfor j in range(1,len(FY[0])):\nu , v = FY[i][j] , FY[i+1][j]\nif u == float('inf') or u == -float('inf'):\nif v != float('inf') and v != -float('inf') and not isnan(v):\nLy_haut.append((i,j))\nif v == float('inf') or v == -float('inf'):\nif u != float('inf') and u != -float('inf') and not isnan(u):\nLy_bas.append((i+1,j))\nfor cellule in Ly_haut:\ni, j = cellule\nFY[i][j] = FY[i+1][j]\nfor cellule in Ly_bas:\ni, j = cellule\nFY[i][j] = FY[i-1][j]\n</code></pre>"},{"location":"projects/Reciprocal-n-body-Collision-Avoidance/#myagent","title":"MyAgent","text":"<p>myAgent</p> <p>Ce code d\u00e9finit la classe <code>myAgent</code>, qui repr\u00e9sente un agent dans notre environnement de simulation. Chaque instance de cette classe contient les attributs suivants :</p> <p>position: un vecteur 2D repr\u00e9sentant la position de l\u2019agent dans l\u2019environnement.</p> <p>speed: un vecteur 2D repr\u00e9sentant la vitesse actuelle de l\u2019agent.</p> <p>D_S: un vecteur 2D repr\u00e9sentant la direction d\u00e9sir\u00e9e de l\u2019agent (c\u2019est-\u00e0-dire la direction vers laquelle il souhaite se d\u00e9placer).</p> <p>size: la taille de l\u2019agent.</p> <p>has_reached_exit: un bool\u00e9en qui indique si l\u2019agent a atteint la sortie ou non.</p> <p>near_to_exit: un bool\u00e9en qui indique si l\u2019agent est proche de la sortie ou non.</p> <p>masse: la masse de l\u2019agent.</p> <p>color: la couleur de l\u2019agent.</p> <p>La classe myAgent contient \u00e9galement plusieurs m\u00e9thodes :</p> <p>desired_direction: Cette m\u00e9thode calcule la direction d\u00e9sir\u00e9e de l\u2019agent en fonction de la position actuelle de l\u2019agent dans l\u2019environnement et de la carte de flux (contenue dans les matrices FX et FY).</p> <p>update_D_S: Cette m\u00e9thode met \u00e0 jour le vecteur D_S en appelant la m\u00e9thode desired_direction.</p> <p>update_Speed: Cette m\u00e9thode met \u00e0 jour la vitesse de l\u2019agent en fonction d\u2019un vecteur de vitesse donn\u00e9 en argument.</p> <p>reach_exit: Cette m\u00e9thode v\u00e9rifie si l\u2019agent a atteint l\u2019une des sorties de l\u2019environnement et met \u00e0 jour l\u2019attribut has_reached_exit en cons\u00e9quence.</p> <p>update_Position: Cette m\u00e9thode met \u00e0 jour la position de l\u2019agent en fonction d\u2019un vecteur de position donn\u00e9 en argument et appelle la m\u00e9thode reach_exit pour mettre \u00e0 jour l\u2019attribut has_reached_exit.</p> <pre><code>class myAgent():\ndef __init__(self, position):\nself.position = numpy.array(position)\nself.speed = (0,0)\nself.D_S = (0,0)\nself.size = 0.2\nself.has_reached_exit = False\nself.near_to_exit = False\nself.masse = 80\nself.color = 'red'\ndef desired_direction(self):\nx, y = self.position\na, b = size_scene\nn , m = int(x/h) , int((b-y)/h)\nif n &lt; 0 : n = 0\nif m &lt; 0 : m = 0\nif n &gt; len(FX[0])-1 : n = len(FX[0])-1\nif m &gt; len(FX)-1 : m = len(FX)-1\nv = numpy.array((FX[m][n], FY[m][n]))\nif norm(v)==0: return numpy.array((0,0))\nreturn v / norm(v)\ndef update_D_S(self):\nself.D_S = self.desired_direction()\ndef update_Speed(self, v):\nself.speed = (v[0],v[1])\ndef reach_exit(self):\nfor ex in exits:\nd , _ = distance_vecteur_obs(self.position , self.size, ex)\nif d &lt;= 0.2:\nself.has_reached_exit = True\nbreak\ndef update_Position(self, q):\nself.position = q\nself.reach_exit()\n</code></pre>"},{"location":"projects/Reciprocal-n-body-Collision-Avoidance/#fonctions","title":"Fonctions","text":"<p>f_motrice</p> <p>La fonction <code>f_motrice(agent)</code> calcule la force motrice qui sera appliqu\u00e9e \u00e0 l\u2019agent.</p> <p>Elle prend en entr\u00e9e l\u2019objet agent qui doit poss\u00e9der au moins un attribut D_S (vecteur unitaire repr\u00e9sentant la direction d\u00e9sir\u00e9e par l\u2019agent) et speed (vecteur vitesse de l\u2019agent).</p> <p>La force motrice est calcul\u00e9e comme suit :</p> <ul> <li> <p>Le coefficient de relaxation tau est d\u00e9fini \u00e0 0.5.</p> </li> <li> <p>La force motrice est donn\u00e9e par l\u2019expression : (2 x direction d\u00e9sir\u00e9e - vitesse courante) / tau</p> </li> <li> <p>Le r\u00e9sultat est un vecteur qui repr\u00e9sente la force motrice \u00e0 appliquer \u00e0 l\u2019agent.</p> </li> </ul> <p>La force motrice est la force qui pousse l\u2019agent \u00e0 suivre la direction d\u00e9sir\u00e9e, en prenant en compte sa vitesse courante pour \u00e9viter les changements brutaux de direction. Elle permet de mod\u00e9liser le comportement des agents qui avancent dans une direction donn\u00e9e tout en essayant de minimiser les changements de direction brusques.</p> <pre><code>#force motrice\ndef f_motrice(agent):\ntau = 0.5\nreturn (numpy.array(agent.D_S)*2 - numpy.array(agent.speed))/tau\n</code></pre> <p>dist &amp; distance_vecteur_obj &amp; distance_vecteur_obs_cir &amp; distance_vecteur_obs</p> <p>Ces fonctions sont toutes des fonctions de calcul de distance entre deux points ou un point et un obstacle.</p> <ul> <li> <p>La fonction <code>dist(p1, p2)</code> prend deux points p1 et p2 et retourne la norme de leur diff\u00e9rence. Cette norme est calcul\u00e9e en utilisant la fonction numpy.array() pour cr\u00e9er des tableaux numpy \u00e0 partir des points, puis en calculant la diff\u00e9rence entre ces tableaux \u00e0 l\u2019aide de l\u2019op\u00e9rateur - et en utilisant la fonction norm() pour calculer la norme.</p> </li> <li> <p>La fonction <code>distance_vecteur_obj(q1, q2, r1, r2)</code> prend deux points q1 et q2, ainsi que deux rayons r1 et r2 et calcule la distance entre ces deux objets. La distance est calcul\u00e9e comme la distance entre q1 et q2 moins la somme des rayons r1 et r2. La fonction renvoie \u00e9galement le vecteur normalis\u00e9 allant de q2 \u00e0 q1.</p> </li> <li> <p>La fonction <code>distance_vecteur_obs_cir(q, r, obstacle)</code> prend un point q, un rayon r et un objet circulaire obstacle (repr\u00e9sent\u00e9 par sa position et son rayon) et calcule la distance entre le point et l\u2019obstacle. La distance est calcul\u00e9e comme la distance entre le point et le centre de l\u2019obstacle, moins la somme des rayons. La fonction renvoie \u00e9galement le vecteur normalis\u00e9 allant du centre de l\u2019obstacle \u00e0 q.</p> </li> <li> <p>La fonction <code>distance_vecteur_obs(q, r, obstacle)</code> prend un point q, un rayon r et un obstacle rectangulaire obstacle (repr\u00e9sent\u00e9 par sa position, sa largeur et sa hauteur) et calcule la distance entre le point et l\u2019obstacle. La distance est calcul\u00e9e comme la distance entre q et le point de l\u2019obstacle le plus proche de q. Ce point est calcul\u00e9 en projetant q sur le rectangle et en s\u00e9lectionnant le point projet\u00e9 qui est le plus proche de q. La fonction renvoie \u00e9galement le vecteur normalis\u00e9 allant du point le plus proche de q sur l\u2019obstacle \u00e0 q.</p> </li> </ul> <pre><code>def dist(p1,p2):\nreturn norm(numpy.array(p1)-numpy.array(p2))\ndef distance_vecteur_obj(q1, q2, r1, r2):\nd = dist(q1, q2)\nn = -(numpy.array(q2) - numpy.array(q1))/d\nd = d - (r1 + r2)\nreturn d , n\ndef distance_vecteur_obs_cir(q , r, obstacle):\n[a0, b0], rayon = obstacle.position, obstacle.rayon\nx , y = q\nd = ((x-a0)**2 + (y-b0)**2)**0.5 \nn = -(numpy.array(obstacle.position) - numpy.array(q))/d\nd = d - (rayon + r)\nreturn d , n\ndef distance_vecteur_obs(q , r, obstacle):\n[a0, b0], L, l = obstacle.position, obstacle.width, obstacle.height\na1, b1 = a0 + L , b0 + l\nx , y = q\npoint = []\nif x&lt;=a0:\nif y&gt;=b1:\npoint = [a0, b1]\nelif b0&lt;y&lt;b1:\npoint = [a0, y]\nelse:\npoint = [a0, b0]\nelif a0&lt;x&lt;a1:\nif y&gt;=b1:\npoint = [x, b1]\nelif b0&lt;y&lt;b1:\npoint = [x, b1]\nelse:\npoint = [x, b0]\nelse:\nif y&gt;=b1:\npoint = [a1, b1]\nelif b0&lt;y&lt;b1:\npoint = [a1, y]\nelse:\npoint = [a1, b0]\nd = dist(point , q)\nn = (numpy.array(q) - numpy.array(point))/d\nreturn d - r , n\n</code></pre> <p>matrice_normals</p> <p>Cette fonction <code>matrice_normals(q, R)</code> calcule les vecteurs normaux pour chaque collision possible entre les agents et les obstacles dans un environnement donn\u00e9.</p> <p>La fonction prend en entr\u00e9e deux listes : q qui est la liste des positions des agents et R qui est la liste des rayons de chaque agent.</p> <p>La fonction retourne une matrice numpy, Normals, qui contient les vecteurs normaux de chaque collision, o\u00f9 chaque ligne repr\u00e9sente un vecteur normal pour un choc possible et chaque colonne repr\u00e9sente un agent (donc 2*m colonnes pour m agents). La fonction retourne \u00e9galement une liste, agents_en_chocs, qui contient les indices des agents impliqu\u00e9s dans au moins une collision.</p> <p>La fonction parcourt tous les agents et v\u00e9rifie s\u2019il y a une collision avec un autre agent ou un obstacle. Si une collision est d\u00e9tect\u00e9e, la fonction calcule le vecteur normal correspondant \u00e0 cette collision \u00e0 l\u2019aide de distance_vecteur_obj() pour une collision entre deux agents, distance_vecteur_obs() pour une collision entre un agent et un obstacle rectangulaire et distance_vecteur_obs_cir() pour une collision entre un agent et un obstacle circulaire.</p> <p>Les vecteurs normaux sont stock\u00e9s dans la matrice Normals et les indices des agents impliqu\u00e9s dans des collisions sont stock\u00e9s dans la liste agents_en_chocs.</p> <p>En fin de parcours, la fonction renvoie la matrice Normals et la liste agents_en_chocs.</p> <pre><code>def matrice_normals(q, R):\nNormals = []\nagents_en_chocs = []\nm = len(q)\n#chocs agents\nfor i in range(m):\nN = numpy.zeros(2*m)\nfor j in range(m):\nif j != i:\nd , n = distance_vecteur_obj(q[i], q[j], R[i], R[j])\nif d &lt;= 0.2:\nN[2*i], N[2*i+1], N[2*j], N[2*j+1] = n[0], n[1], -n[0], -n[1]\nif not all(v == 0 for v in N):\nNormals.append(N)\nagents_en_chocs.append(i)\n#chocs obstacle\nfor obstacle in obstacles:\nN = numpy.zeros(2*m)\nfor i in range(m):\nd , n = distance_vecteur_obs(q[i] , R[i], obstacle)\nif d &lt;= 0.2:\nN[2*i], N[2*i+1] = n[0], n[1]\nif N[2*i] != 0 or N[2*i+1] != 0:\nagents_en_chocs.append(i)\nif not all(v == 0 for v in N):\nNormals.append(N)\n#chocs obstacle circulaire\nfor obstacle in obstacles_cir:\nN = numpy.zeros(2*m)\nfor i in range(m):\nd , n = distance_vecteur_obs_cir(q[i] , R[i], obstacle)\nif d &lt;= .2:\nN[2*i], N[2*i+1] = n[0], n[1]\nif N[2*i] != 0 or N[2*i+1] != 0:\nagents_en_chocs.append(i)\nif not all(v == 0 for v in N):\nNormals.append(N)\nreturn numpy.array(Normals) , agents_en_chocs\n</code></pre> <p>detection_de_chocs</p> <p>La fonction <code>detection_de_chocs(Q, R)</code> qui prend en entr\u00e9e deux listes Q et R contenant respectivement les positions et les rayons de tous les agents et qui renvoie True si deux agents ou un agent et un obstacle se trouvent \u00e0 une distance inf\u00e9rieure \u00e0 une marge de collision marge, et False sinon.</p> <p>La fonction parcourt d\u2019abord tous les obstacles rectangulaires et circulaires stock\u00e9s dans les variables obstacles et obstacles_cir, respectivement, pour v\u00e9rifier s\u2019il y a une collision entre l\u2019agent et l\u2019un de ces obstacles en comparant les coordonn\u00e9es de l\u2019agent \u00e0 celles des coins de l\u2019obstacle et \u00e0 la distance de l\u2019agent au centre de l\u2019obstacle. Ensuite, la fonction compare la distance entre l\u2019agent courant et tous les autres agents pour v\u00e9rifier s\u2019il y a une collision entre eux.</p> <p>Si une collision est d\u00e9tect\u00e9e, la fonction retourne True, sinon elle retourne False.</p> <pre><code>def detection_de_chocs(Q, R):\nm = len(agents)\nfor i in range(m):\n[x , y], r = Q[i], R[i]\nmarge = .2\n#chocs obstacle\nfor obstacle in obstacles:\n[a0, b0], L, l = obstacle.position, obstacle.width, obstacle.height\na1, b1 = a0 + L , b0 + l\nif a0&lt;=x&lt;=a1 and b0-r-marge&lt;=y&lt;=b1+r+marge: return True\nif b0&lt;=y&lt;=b1 and a0-r-marge&lt;=x&lt;=a1+r+marge: return True\nfor obst in obstacles_cir:\n[a0, b0], rayon = obst.position, obst.rayon\nd = ((x - a0)**2 + (y - b0)**2)**0.5\nif d - (rayon+r) &lt; 2 : return True\n#chocs agents\nfor j in range(m):\nif j != i:\nif dist(Q[i], Q[j]) - (R[i]+R[j]) &lt;= marge: return True\nreturn False\n</code></pre> <p>predict_position2</p> <p>La fonction <code>predict_position2(V)</code> permet de pr\u00e9dire la position des agents \u00e0 l\u2019instant suivant en fonction de leur vitesse actuelle et leur vitesse future, ainsi que de leur position actuelle. Elle prend en entr\u00e9e une liste V de la vitesse de chaque agent (vecteur de dimension 2 pour chaque agent) \u00e0 l\u2019instant actuel.</p> <p>Le premier \u00e9l\u00e9ment de la fonction convertit la liste V en un tableau V_future de dimension p x 2 o\u00f9 p est le nombre d\u2019agents dans la simulation. Chaque ligne de V_future contient la vitesse future d\u2019un agent sous la forme d\u2019un vecteur de dimension 2.</p> <p>Le deuxi\u00e8me \u00e9l\u00e9ment de la fonction cr\u00e9e un tableau V_passe de dimension m x 2, o\u00f9 m est le nombre total d\u2019agents dans la simulation. Chaque ligne de V_passe contient la vitesse actuelle de chaque agent sous la forme d\u2019un vecteur de dimension 2.</p> <pre><code>def predict_position2(V):\np = int(len(V)/2)\nV_future =  numpy.array([ numpy.array([V[2*j], V[2*j+1]]) for j in range(p) ])\nV_passe =   numpy.array([ numpy.array(agent.speed) for agent in agents ])\nreturn [numpy.array(agent.position) + dt*(V_future[agents.index(agent)] + V_passe[agents.index(agent)])/2 for agent in agents]\n</code></pre> <p>correction_vitesses</p> <p>Cette fonction prend en entr\u00e9e la vitesse actuelle de chaque agent, la force ext\u00e9rieure appliqu\u00e9e \u00e0 chaque agent et le coefficient de restitution entre les agents. Elle calcule ensuite la nouvelle vitesse pour chaque agent en fonction des chocs d\u00e9tect\u00e9s en appelant la fonction matrice_normals qui retourne la matrice des normales pour chaque agent en collision avec un autre agent ou un obstacle.</p> <p>Dans la premi\u00e8re partie de la fonction, la fonction predict_position2 est appel\u00e9e pour pr\u00e9dire la position future des agents. Ensuite, la fonction detection_de_chocs est appel\u00e9e pour v\u00e9rifier s\u2019il y a collision entre les agents et les obstacles.</p> <p>Si une collision est d\u00e9tect\u00e9e, la fonction calcule la matrice de masse M pour chaque agent et la matrice de normales C_N pour chaque collision. Ensuite, elle calcule la matrice U en multipliant la transpos\u00e9e de C_N avec C_N. Cette matrice est utilis\u00e9e pour calculer la matrice de contrainte P.</p> <pre><code>def correction_vitesses(V, Pext, K_n):\nV, Pext = numpy.array(V), numpy.array(Pext)\np = len(agents)\nagents_en_chocs = []\nq = predict_position2(V)\nR = [agent.size for agent in agents]\nif detection_de_chocs(q, R):\n# Matrice Masse\nM = numpy.zeros((2*p, 2*p))\nfor i in range(p):\nM[2*i][2*i] = agents[i].masse\nM[2*i+1][2*i+1] = agents[i].masse\n# Matrice Normales\nC_N , agents_en_chocs = matrice_normals(q, R)\nU = dot(C_N.transpose(), C_N)\nP = matrix(numpy.array(M) + 0.5 * K_n * U , tc='d')\nq = matrix(numpy.array(dot(M - 0.5 * K_n * U , V) + dt * Pext), tc='d')\nG = matrix(numpy.array(C_N), tc='d')\nh = matrix(numpy.array(numpy.zeros(len(C_N))), tc='d')\nsolvers.options['show_progress'] = False\nreturn list(solvers.qp(P,-q,-G,h)['x']) , agents_en_chocs\nelse:\nreturn V , agents_en_chocs\n</code></pre> <p>matrice_DistancesEtNormaux &amp; matrice_DistancesEtNormaux_danger</p> <p>Ces deux fonctions g\u00e9n\u00e8rent une matrice de distances et une matrice de normales entre les agents (ou les dangers) du sc\u00e9nario.</p> <p>La fonction <code>matrice_DistancesEtNormaux(agents)</code> prend en entr\u00e9e une liste d\u2019objets agents et renvoie une matrice de distance matrice_distance et une matrice de normales matrice_normaux. Les matrices sont carr\u00e9es et de taille \u00e9gale au nombre d\u2019agents dans la liste agents. La matrice de distance matrice_distance contient les distances entre chaque paire d\u2019agents, et la matrice de normales matrice_normaux contient les normales correspondantes.</p> <p>La fonction <code>matrice_DistancesEtNormaux_danger(agents)</code> prend en entr\u00e9e une liste d\u2019objets agents et renvoie une matrice de distance matrice_distance et une matrice de normales matrice_normaux entre chaque agent de la liste et le danger Dangers[0]. La matrice de distance matrice_distance contient les distances entre chaque agent et le danger, et la matrice de normales matrice_normaux contient les normales correspondantes.</p> <pre><code>def matrice_DistancesEtNormaux(agents):\nN_ind = len(agents)\nmatrice_distance = numpy.zeros((N_ind, N_ind))\nmatrice_normaux = numpy.zeros((N_ind, N_ind,2))\nfor i in range(N_ind):\nfor j in range(N_ind):\nif i &gt; j:\nd, n = distance_vecteur_obj(agents[i].position, agents[j].position, agents[i].size, agents[j].size)\nmatrice_distance[i][j] = d\nmatrice_distance[j][i] = d\nmatrice_normaux[i][j] = n\nmatrice_normaux[j][i] = -n\nreturn matrice_distance , matrice_normaux\ndef matrice_DistancesEtNormaux_danger(agents):\nN_ind = len(agents)\nmatrice_distance = numpy.zeros(N_ind)\nmatrice_normaux = numpy.zeros((N_ind, 2))\nfor i in range(N_ind):\nd = dist(Dangers[0], agents[i].position)\nn = norm(numpy.array(Dangers[0]) - numpy.array(agents[i].position))\nmatrice_distance[i] = d\nmatrice_normaux[i] = n\nreturn matrice_distance , matrice_normaux\n</code></pre>"},{"location":"projects/Reciprocal-n-body-Collision-Avoidance/#configuration","title":"Configuration","text":"<pre><code>a , b , eps = 10 , 10 , 0.2\nsize_scene = (a,b)\nobstacles = [Obstacle((0,0),a,eps), Obstacle((0,eps),eps,b-eps), Obstacle((eps,b-eps),a-eps,eps), Obstacle((a-eps, eps),eps, b-2*eps)]\nexits = [Exit((4,a-eps), 1, eps)]\nobstacles_cir = []\ndraw(exits, obstacles, obstacles_cir, size_scene, [], 0, 'gemoetrie.png', play=True)\n</code></pre> Output"},{"location":"projects/Reciprocal-n-body-Collision-Avoidance/#champs-de-directions","title":"Champs de directions","text":"<pre><code>h = .5 #pas de discritisation du FAst Marching\ngraph = GridGraph(size_scene,1/h)\ngraph.prepare_graph_for_fast_marching(obstacles, obstacles_cir, exits)\nfast_marching_method(graph, (0,0))\n</code></pre> <pre><code>d = graph.distances\nd_tr = []\nn = len(d)\nfor i in range(n):\nd_tr.append(d[n-i-1])\nFY, FX = numpy.gradient(numpy.array(d_tr))\nFX = -FX\nadjust_FM()\n</code></pre> Output"},{"location":"projects/Reciprocal-n-body-Collision-Avoidance/#simulation","title":"Simulation","text":"<pre><code>N_pop = 10\ntemps_de_sim = 1*60 #secondes\ndt = 5e-2\nN_iter = int(temps_de_sim / dt)\nagents = generate_indiv(N_pop)\ndraw(exits, obstacles, obstacles_cir, size_scene, agents, 0, 'config_init.png', play=True)\n</code></pre> Output <pre><code>K_n = 0\nR = [agent.size for agent in agents]\n!mkdir DossierImages\nfor image in os.listdir('DossierImages'):\nos.remove('DossierImages/' + image)\nfor n in tqdm(range(N_iter)):\nif len(agents)==0:break\nV_avant_correction = []\nP = []\nmatrice_distance , matrice_normaux = matrice_DistancesEtNormaux(agents)\nfor agent in agents:\nagent.update_D_S()\np_ext = f_motrice(agent)\nvi = agent.speed + dt*p_ext/agent.masse\nV_avant_correction.extend(vi)\nP.extend(p_ext)\nV_new , agents_en_chocs = correction_vitesses(V_avant_correction, P, K_n)\nq = predict_position2(V_new)\nfor agent in agents:\nk = agents.index(agent)\nagent.update_Speed([V_new[2*k] , V_new[2*k+1]])\nagent.update_Position(q[k])\nfor agent in agents:\nif agent.has_reached_exit: agents.remove(agent)\npath = 'DossierImages/simulation' + str(n) + '.jpg'\ndraw(exits, obstacles, obstacles_cir, size_scene, agents,round(n*dt, 2), savepath=path, play = False)\nprint('Simulation finished.')\nrecord_video(speed = 25)\n</code></pre> Output"},{"location":"projects/abstractive%20summarization/","title":"Abstractive Summarization","text":""},{"location":"projects/abstractive%20summarization/#introduction","title":"Introduction","text":"<p>Introduction</p> <p>Abstractive Summarization est une t\u00e2che du Natural Language Processing (NLP) qui vise \u00e0 g\u00e9n\u00e9rer un r\u00e9sum\u00e9 concis d\u2019un texte source. Contrairement au extractive summarization, Abstractive Summarization ne se contente pas de copier les phrases importantes du texte source, mais peut \u00e9galement en cr\u00e9er de nouvelles qui sont pertinentes, ce qui peut \u00eatre consid\u00e9r\u00e9 comme une paraphrase. Abstractive Summarization donne lieu \u00e0 un certain nombre d\u2019applications dans diff\u00e9rents domaines, des livres et de la litt\u00e9rature, \u00e0 la science et \u00e0 la R&amp;D, \u00e0 la recherche financi\u00e8re et \u00e0 l\u2019analyse de documents juridiques.</p> <p>Jusqu\u2019\u00e0 pr\u00e9sent, l\u2019approche la plus r\u00e9cente et la plus efficace en mati\u00e8re de Abstractive Summarization consiste \u00e0 utiliser des mod\u00e8les de transformation sp\u00e9cifiquement adapt\u00e9s \u00e0 un ensemble de donn\u00e9es de r\u00e9sum\u00e9. Dans cette \u00e9tude, nous d\u00e9montrons comment vous pouvez facilement r\u00e9sumer un texte \u00e0 l\u2019aide d\u2019un mod\u00e8le puissant en quelques \u00e9tapes simples. Tout d\u2019abord, nous utiliserons deux mod\u00e8les qui sont d\u00e9j\u00e0 pr\u00e9-entra\u00een\u00e9s, de sorte qu\u2019aucun entrainnement suppl\u00e9mentaire n\u2019est n\u00e9cessaire, puis nous affinerons l\u2019un de ces deux mod\u00e8les sur notre base de donn\u00e9es.</p> <p>Sans plus attendre, commen\u00e7ons !</p>"},{"location":"projects/abstractive%20summarization/#importer-les-donnees","title":"Importer les donn\u00e9es","text":"<pre><code>import pandas as pd\ndata = pd.read_json(\"/content/sample_data/AgrSmall.json\")\ndata.head()\n</code></pre>"},{"location":"projects/abstractive%20summarization/#utilisation-de-transformer-bart-large-cnn-t5-base","title":"Utilisation de transformer <code>bart-large-cnn</code> &amp; <code>t5-base</code>","text":""},{"location":"projects/abstractive%20summarization/#installer-la-bibliotheque-transformers","title":"Installer la biblioth\u00e8que Transformers","text":"<p>La biblioth\u00e8que que nous allons utiliser est Transformers par Huggingface.</p> <p>Pour installer des transformateurs, il suffit d\u2019ex\u00e9cuter cette cellule :</p> <pre><code>pip install transformers\n</code></pre> <p>Note</p> <p>Transformers n\u00e9cessite l\u2019installation pr\u00e9alable de Pytorch. Si vous n\u2019avez pas encore install\u00e9 Pytorch, rendez-vous sur le site officiel de Pytorch et suivez les instructions pour l\u2019installer.</p>"},{"location":"projects/abstractive%20summarization/#importer-les-bibliotheques","title":"Importer les biblioth\u00e8ques","text":"<p>Apr\u00e8s avoir install\u00e9 transformers avec succ\u00e8s, nous pouvons maintenant commencer \u00e0 l\u2019importer dans votre script Python. Nous pouvons \u00e9galement importer <code>os</code> afin de d\u00e9finir la variable d\u2019environnement \u00e0 utiliser par le GPU \u00e0 l\u2019\u00e9tape suivante.</p> <pre><code>from transformers import pipeline\nimport os\n</code></pre> <p>Maintenant, nous sommes pr\u00eats \u00e0 s\u00e9lectionner the summarization model \u00e0 utiliser. Huggingface fournit deux summarization models puissants \u00e0 utiliser : BART (bart-large-cnn) et t5 (t5-small, t5-base, t5-large, t5-3b, t5-11b). Pour en savoir plus sur ces mod\u00e8les veuillez consulter leurs documents officiels (document BART, document t5).</p> <p>Pour utiliser le mod\u00e8le BART, qui est form\u00e9 sur le CNN/Daily Mail News Dataset, nous avons utilis\u00e9s directement les param\u00e8tres par d\u00e9faut via le module int\u00e9gr\u00e9 Huggingface pipeline :</p> <pre><code>summarizer = pipeline(\"summarization\")\n</code></pre> <p>Pour utiliser le mod\u00e8le t5 (par exemple t5-base), qui est entra\u00een\u00e9 sur c4 Common Crawl web corpus, nous avons proc\u00e9d\u00e9 comme suit :</p> <pre><code>summarizer = pipeline(\"summarization\", model=\"t5-base\", tokenizer=\"t5-base\", framework=\"tf\")\n</code></pre> <p>Pour plus d\u2019informations, veuillez vous r\u00e9f\u00e9rer \u00e0 la Huggingface documentation.</p>"},{"location":"projects/abstractive%20summarization/#entrer-le-texte-a-resumer","title":"Entrer le texte \u00e0 r\u00e9sumer","text":"<p>Maintenant que notre mod\u00e8le est pr\u00eat, nous pouvons commencer \u00e0 choisir les textes que nous voulons r\u00e9sumer. Nous proposons de choisir les 4 premiers abstracts dans notre base de donn\u00e9es :</p> <p>Nous d\u00e9finissons nos variables :</p> <pre><code>text_1 = data[\"abstracts\"][0]\nprint(text_1)\n</code></pre> Output text_1 <p>Most people in rural areas in South Africa (SA) rely on untreated drinking groundwater sources and pit latrine sanitations. A minimum basic sanitation facility should enable safe and appropriate removal of human waste, and although pit latrines provide this, they are still contamination concerns. Pit latrine sludge in SA is mostly emptied and disposed off-site as waste or buried in-situ. Despite having knowledge of potential sludge benefits, most communities in SA are reluctant to use it. This research captured social perceptions regarding latrine sludge management in Monontsha village in the Free State Province of SA through key informant interviews and questionnaires. A key informant interview and questionnaire was done in Monontsha, SA. Eighty participants, representing 5% of all households, were selected. Water samples from four boreholes and four rivers were analyzed for faecal coliforms and E.coli bacteria. On average, five people in a household were sharing a pit latrine. Eighty-three percent disposed filled pit latrines while 17% resorted to closing the filled latrines. Outbreaks of diarrhoea (69%) and cholera (14%) were common. Sixty percent were willing to use treated faecal sludge in agriculture. The binary logistic regression model indicated that predictor variables significantly (p \u02c2 0.05) described water quality, faecal sludge management, sludge application in agriculture and biochar adaption. Most drinking water sources in the study had detections \u02c2 1 CFU/100 mL. It is therefore imperative to use both qualitative surveys and analytical data. Awareness can go a long way to motivate individuals to adopt to a new change. View Full-Text</p> <pre><code>text_2 = data[\"abstracts\"][1]\nprint(text_2)\n</code></pre> Output text_2 <p>The aim of this study was to highlight the importance of socioeconomic and psychosocial factors in the adoption of sustainable agricultural practices (SAPs) in banana farm production. To this end, data from 300 randomly selected farm households from Pakistan were collected through a structured self-report questionnaire. Using logistic regression (LR) and structural equation modeling (SEM), socioeconomic and psychosocial effects were evaluated. The results show that economic status, watching agricultural training programs, newspaper and radio awareness campaigns, participation in extension programs, perceptions of sustainable agriculture and the feasibility of SAPs were significant factors in farmers\u2019 adoption of sustainable agriculture practices. Also, consistent with the theory of planned behavior (TPB), all its dimensions (attitude, subjective norms and perceived behavioral control) affected the adoption of SAPs. This finding highlights the importance of socioeconomic and psychosocial factors in promoting sustainable agricultural practice among banana production farmers. This is the first study which attempts to provide empirical evidence using a robust procedure (two models\u2014LR and SEM). The practical implication is that, when socioeconomic and psychosocial factors are well supported by satisfactory policy measures, SAP adoption is more than likely, which eventually increases farmers\u2019 adaptive capacity to the changing environment. Ultimately, this leads to sustainable banana production, which has great potential to contribute towards poverty eradication. View Full-Text</p> <pre><code>text_3 = data[\"abstracts\"][2]\nprint(text_3)\n</code></pre> Output text_3 <p>Urban agriculture and gardening provide many health benefits, but the soil is sometimes at risk of heavy metal and metalloid (HMM) contamination. HMM, such as lead and arsenic, can result in adverse health effects for humans. Gardeners may face exposure to these contaminants because of their regular contact with soil and consumption of produce grown in urban areas. However, there is a lack of research regarding whether differential exposure to HMM may be attributed to differential knowledge of exposure sources. In 2018, industrial slag and hazardous levels of soil contamination were detected in West Atlanta. We conducted community-engaged research through surveys and follow-up interviews to understand awareness of slag, HMM in soil, and potential remediation options. Home gardeners were more likely to recognize HMM health effects and to cite health as a significant benefit of gardening than community gardeners. In terms of knowledge, participants were concerned about the potential health effects of contaminants in soil yet unconcerned with produce in their gardens. Gardeners\u2019 knowledge on sources of HMM exposure and methods for remediation were low and varied based on racial group. View Full-Text</p> <pre><code>text_4 = data[\"abstracts\"][3]\nprint(text_4)\n</code></pre> Output text_4 <p>Waste management has become pertinent in urban regions, along with rapid population growth. The current ways of managing waste, such as refuse collection and recycling, are failing to minimise waste in cities. With urban populations growing worldwide, there is the challenge of increased pressure to import food from rural areas. Urban agriculture not only presents an opportunity to explore other means of sustainable food production, but for managing organic waste in cities. However, this opportunity is not taken advantage of. Besides, there is a challenge of mixed reactions from urban planners and policymakers concerning the challenges and benefits presented by using organic waste in urban agriculture. The current paper explores the perceived challenges and opportunities for organic waste utilisation and management through urban agriculture in the Durban South Basin in eThekwini Municipality in KwaZulu-Natal (KZN) Province of South Africa. It is anticipated that this information will be of use to the eThekwini Municipality, policymakers, researchers, urban agriculture initiatives, households and relevant stakeholders in the study areas and similar contexts globally. Two hundred (200) households involved in any urban farming activity and ten (10) key informants (six (6) staff from the Cleaning and Solid Waste Unit of the eThekwini Municipality and four (4) from the urban agricultural initiative) were selected using convenient sampling. Descriptive statistics and inductive thematic analysis were used to analyse data. The significant perceived challenges and risks associated with the utilisation of organic waste through urban agriculture included lack of a supporting policy, climatic variation, lack of land tenure rights, soil contamination and food safety concerns. Qualitative data further showed that the difficulty in segregating waste, water scarcity, difficulty in accessing inputs, limited transportation of organic waste, inadequate handling and treatment of organic waste, and being a health hazard were some important challenges. On the other hand, the significant perceived benefits associated with the utilisation of organic waste through urban agriculture were enhanced food and nutrition security, and opportunities for business incubation. Other important benefits established through qualitative data were an improved market expansion for farmers and improved productivity. Overall, despite the perceived challenges and risks, there is an opportunity to manage organic waste through urban agriculture. It is imperative for an integrated policy encompassing the food, climate and waste management to be developed to support this strategy. All stakeholders\u2014the government, municipal authorities and urban agricultural initiatives should also, guided by the policy, support urban farmers, for example, through pieces of training on how to properly manage and recycle organic waste, land distribution, inputs availability and water usage rights among other things. View Full-Text</p>"},{"location":"projects/abstractive%20summarization/#generation-de-resume","title":"G\u00e9n\u00e9ration de r\u00e9sum\u00e9","text":"<p>Enfin, nous pouvons commencer \u00e0 r\u00e9sumer les textes entr\u00e9s. Ici, nous d\u00e9clarons la longueur minimale et la longueur maximale que nous souhaitons pour la sortie des r\u00e9sum\u00e9s, et nous d\u00e9sactivons \u00e9galement l\u2019\u00e9chantillonnage pour g\u00e9n\u00e9rer des r\u00e9sum\u00e9s fixes. Nous pouvons le faire en ex\u00e9cutant les commandes suivantes :</p> <pre><code>summary_text_1 = summarizer(text, max_length=100, min_length=5, do_sample=False)[0]['summary_text']\nprint(summary_text_1)\n</code></pre> <p>Voil\u00e0 ! Nous obtenons le r\u00e9sum\u00e9 de premier texte :</p> Output <p>Most people in rural areas in South Africa rely on untreated drinking groundwater sources and pit latrine sanitations . Outbreaks of diarrhoea (69%) and cholera (14%) were common. Sixty percent were willing to use treated faecal sludge in agriculture .</p> <pre><code>summary_text_2 = summarizer(text_2, max_length=100, min_length=5, do_sample=False)[0]['summary_text']\nprint(summary_text_2)\n</code></pre> <p>Voil\u00e0 ! Nous obtenons le r\u00e9sum\u00e9 de deuxi\u00e8me texte :</p> Output <p>The aim of this study was to highlight the importance of socioeconomic and psychosocial factors in the adoption of sustainable agricultural practices (SAPs) in banana farm production . Economic status, watching agricultural training programs, newspaper and radio awareness campaigns, perceptions of sustainable agriculture and the feasibility of SAPs were significant factors .</p> <pre><code>summary_text_3 = summarizer(text_3, max_length=100, min_length=5, do_sample=False)[0]['summary_text']\nprint(summary_text_3)\n</code></pre> <p>Voil\u00e0 ! Nous obtenons le r\u00e9sum\u00e9 de troisi\u00e8me texte :</p> Output <p>Heavy metal and metalloid (HMM) contamination can result in adverse health effects for humans . In 2018, industrial slag and hazardous levels of soil contamination were detected in West Atlanta . Home gardeners were more likely to recognize HMM health effects than community gardeners .</p> <pre><code>summary_text_4 = summarizer(text_4, max_length=100, min_length=5, do_sample=False)[0]['summary_text']\nprint(summary_text_4)\n</code></pre> <p>Voil\u00e0 ! Nous obtenons le r\u00e9sum\u00e9 de quatri\u00e8me texte :</p> Output <p>Waste management has become pertinent in urban regions, along with rapid population growth . The current ways of managing waste, such as refuse collection and recycling, are failing to minimise waste in cities . With urban populations growing worldwide, there is the challenge of increased pressure to import food from rural areas .</p>"},{"location":"projects/abstractive%20summarization/#fine-tuning-simplet5","title":"Fine-tuning SimpleT5","text":"<pre><code>!pip install simplet5\n</code></pre> <pre><code>import pandas as pd\nfrom sklearn.model_selection import train_test_split\npath = \"/content/sample_data/AgrSmall.json\"\ndf = pd.read_json(path)\ndf.head()\n</code></pre> <pre><code># simpleT5 expects dataframe to have 2 columns: \"source_text\" and \"target_text\"\ndf = df.rename(columns={\"titles\":\"target_text\", \"abstracts\":\"source_text\"})\ndf = df[['source_text', 'target_text']]\n# T5 model expects a task related prefix: since it is a summarization task, we will add a prefix \"summarize: \"\ndf['source_text'] = \"summarize: \" + df['source_text']\ndf\n</code></pre> <pre><code>train_df, test_df = train_test_split(df, test_size=0.2)\ntrain_df.shape, test_df.shape\n</code></pre> <pre><code>from simplet5 import SimpleT5\nmodel = SimpleT5()\nmodel.from_pretrained(model_type=\"t5\", model_name=\"t5-base\")\nmodel.train(train_df=train_df[:3000],\neval_df=test_df[:100], \nsource_max_token_len=128, \ntarget_max_token_len=50, \nbatch_size=8, max_epochs=3, use_gpu=True)\n</code></pre> <pre><code># let's load the trained model for inferencing:\nmodel.load_model(\"t5\",\"/content/outputs/simplet5-epoch-0-train-loss-2.806-val-loss-2.5596\", use_gpu=True)\ntext_1 = data[\"abstracts\"][0]\ntext_2 = data[\"abstracts\"][1]\ntext_3 = data[\"abstracts\"][2]\ntext_4 = data[\"abstracts\"][3]\n</code></pre> <pre><code>model.predict(text_1)\n</code></pre> Output <p>[\u2018latrine sludge management in Monontsha, Free State Province of South Africa. Key informant interviews and questionnaires\u2019]</p> <pre><code>model.predict(text_2)\n</code></pre> Output <p>[\u2018sustainable agriculture practices among banana production farmers in Pakistan: Evidence from LR and SEM\u2019]</p> <pre><code>model.predict(text_3)\n</code></pre> Output <p>[\u2018soil contamination from industrial slag and hazardous levels of metalloid (HMM) contamination in West Atlanta, Georgia. Community-engaged research\u2019]</p> <pre><code>model.predict(text_4)\n</code></pre> Output <p>[\u2018challenges and opportunities for organic waste utilisation and management through urban agriculture in the Durban South Basin, KwaZulu-Natal Province of South Africa\u2019]</p>"},{"location":"projects/big%20data%20for%20iot/","title":"Big-Data For IOT","text":""},{"location":"projects/big%20data%20for%20iot/#membres-du-groupe","title":"Membres du groupe","text":"<p>Membres du groupe</p> <ul> <li>Hermann Agossou</li> <li>Abdellatif BELMADY</li> <li>Fatine BOUSSATTINE</li> <li>Hamza HAJJINI</li> <li>Salma KHMASSI</li> <li>Mohamed Lamine BAMBA</li> <li>Hamza Dribine</li> </ul>"},{"location":"projects/big%20data%20for%20iot/#introduction","title":"Introduction","text":"<p>Introduction</p> <p>Ce projet a pour but de pr\u00e9senter les concepts cl\u00e9s du Big Data et de l\u2019IoT, ainsi que leur importance dans le monde actuel. Il a \u00e9galement explor\u00e9 les diff\u00e9rentes approches et outils utilis\u00e9s pour g\u00e9rer ces donn\u00e9es massives, les enjeux et les d\u00e9fis li\u00e9s \u00e0 leur utilisation, les applications de l\u2019IA dans le Big Data et l\u2019IoT, et les perspectives futures de ces technologies.</p>"},{"location":"projects/big%20data%20for%20iot/#definition-du-big-data-et-de-liot","title":"D\u00e9finition du Big Data et de l\u2019IoT","text":"<p>Info</p> <p>Pr\u00e9sentation de ces deux concepts cl\u00e9s et de leur importance dans le monde actuel.</p> <p>L\u2019internet des objets (IoT) a gagn\u00e9 en utilisation et en popularit\u00e9 au cours de la derni\u00e8re d\u00e9cennie, indiquant de nouvelles orientations productives et passionnantes pour toute une g\u00e9n\u00e9ration de dispositifs d\u2019information. Les concepts fondamentaux de l\u2019IoT ont \u00e9t\u00e9 invent\u00e9s par Kevin Ashton en 1999, lorsqu\u2019il a introduit la communication entre appareils \u00e0 une \u00e9chelle plus large que celle qui \u00e9tait possible auparavant. Atzori et al. ont depuis d\u00e9clar\u00e9 que \u201cl\u2019IoT est le r\u00e9sultat de la convergence de trois visions : orient\u00e9e vers les objets, orient\u00e9e vers l\u2019internet et orient\u00e9e vers la s\u00e9mantique\u201d. En termes de s\u00e9mantique sp\u00e9cifiquement, l\u2019IoT est un \u201cr\u00e9seau mondial d\u2019objets interconnect\u00e9s\u201d. L\u2019IoT peut \u00eatre d\u00e9fini comme \u201cune infrastructure de r\u00e9seau mondial dynamique, en tant que telle, elle peut identifier, contr\u00f4ler et surveiller chaque objet sur terre via l\u2019internet selon un protocole d\u2019accord sp\u00e9cifique, et par l\u2019interconnexion de choses physiques et virtuelles bas\u00e9e sur l\u2019interop\u00e9rabilit\u00e9 des technologies de l\u2019information et de la communication\u201d. L\u2019objectif principal de l\u2019IoT est d\u2019aider \u00e0 partager des informations en temps r\u00e9el par le biais d\u2019acteurs autonomes en r\u00e9seau. La figure 1 explique le concept de l\u2019IoT. Un capteur dot\u00e9 de capacit\u00e9s de calcul intelligentes est plac\u00e9 \u00e0 un endroit o\u00f9 se trouve une connexion Internet. Ce capteur sera capable de communiquer avec n\u2019importe quoi, \u00e0 tout moment et de n\u2019importe quel endroit du r\u00e9seau. Les syst\u00e8mes de collecte de donn\u00e9es localisent et transf\u00e8rent les donn\u00e9es par le biais d\u2019un grand nombre de ces dispositifs de communication au sein de l\u2019infrastructure IoT, ce qui facilite le processus de collecte des donn\u00e9es. Plusieurs solutions de communication, telles que WIFI, ZigBee, Bluetooth et GSM, permettent l\u2019interconnexion de dispositifs utilisant divers r\u00e9seaux d\u2019acc\u00e8s, notamment l\u2019identification par radiofr\u00e9quence (RFID), les dispositifs dot\u00e9s de capteurs sans fil et tout objet intelligent connect\u00e9 \u00e0 l\u2019internet par IP physique.</p> <p>De nos jours, d\u2019\u00e9normes volumes de donn\u00e9es sont g\u00e9n\u00e9r\u00e9s par l\u2019IoT. Ces donn\u00e9es, souvent appel\u00e9es \u201cbig data\u201d, font r\u00e9f\u00e9rence \u00e0 \u201cune grande \u00e9chelle de donn\u00e9es qui exige de nouvelles architectures et technologies pour la gestion des donn\u00e9es (capture et traitement) afin de permettre l\u2019extraction de valeur pour une meilleure compr\u00e9hension et prise de d\u00e9cision\u201d. Le big data se caract\u00e9rise par diverses propri\u00e9t\u00e9s de haut volume, de haute v\u00e9locit\u00e9, de haute vari\u00e9t\u00e9 et de haute v\u00e9racit\u00e9. D\u2019ici 2020, l\u2019IoT devrait connecter 50 milliards de dispositifs ou plus, en raison de l\u2019afflux consid\u00e9rable de nouveaux objets intelligents et de l\u2019augmentation exponentielle de la demande de leurs services.</p> <p> <p></p> <p>Fig. 1. Internet of things concept.</p> <p></p> <p>R\u00e9cemment, l\u2019IoT a \u00e9t\u00e9 appliqu\u00e9 dans les environnements intelligents, qui permettent aux utilisateurs de mieux comprendre et contr\u00f4ler leur environnement gr\u00e2ce \u00e0 une gamme de dispositifs interconnect\u00e9s. Dans les applications d\u2019environnement intelligent, l\u2019IoT est employ\u00e9 pour construire un r\u00e9seau de surveillance \u00e9cologique complet, \u00e0 plusieurs niveaux et enti\u00e8rement couvert, qui peut \u00eatre r\u00e9alis\u00e9 en utilisant l\u2019int\u00e9gration de capteurs \u00e0 tous les niveaux en tirant parti de l\u2019IoT avec des informations spatiales et temporelles, et en construisant une plate-forme massive avec un centre de donn\u00e9es et un support de service unifi\u00e9. La technologie IoT et son int\u00e9gration avec le big data ont \u00e9t\u00e9 largement appliqu\u00e9es dans divers domaines tels que les villes intelligentes, les soins de sant\u00e9 intelligents, les syst\u00e8mes d\u2019alerte intelligents et la gestion des catastrophes. Par cons\u00e9quent, la construction et l\u2019application de l\u2019IoT et du big data dans les domaines environnementaux sont devenues une mesure cruciale, notamment pour le d\u00e9veloppement, la promotion et la gestion d\u2019un nouvel environnement strat\u00e9gique dans l\u2019industrie.</p>"},{"location":"projects/big%20data%20for%20iot/#exemples-concrets-dutilisation-du-big-data-et-de-liot","title":"Exemples concrets d\u2019utilisation du Big Data et de l\u2019IoT","text":"<p>Les voitures intelligentes</p> <p>Les voitures intelligentes utilisent l\u2019IoT pour \u00e9changer des informations li\u00e9es au fonctionnement et l\u2019environnement de la voitures, tel que l\u2019emplacement, la vitesse, la dynamique\u2026. Grace \u00e0 l\u2019IoT, on peut d\u00e9terminer l\u2019itin\u00e9raire le plus optimale, aussi, on peut localiser une place libre dans un parking. De plus, Il peut aider dans la r\u00e9paration et l\u2019entretien des v\u00e9hicules, en fait, il informe l\u2019utilisateur de la date de maintenance pr\u00e9vue, et il aide dans la r\u00e9paration avec une direction ad\u00e9quate. Ainsi, il permet aux voitures de faire des taches lourdes comme \u00e9viter les collisions et arr\u00eater le trafic inutile.</p> <p>Ces voitures intelligentes sont \u00e9quip\u00e9es de cam\u00e9ras et de capteurs qui peuvent collecter des donn\u00e9es sur l\u2019environnement de la voiture. Cela peut inclure des \u00e9l\u00e9ments tels que les sch\u00e9mas de circulation, les conditions m\u00e9t\u00e9orologiques et m\u00eame l\u2019emplacement et la vitesse des autres v\u00e9hicules dans la r\u00e9gion. Ce qui conduit \u00e0 la collecte d\u2019un volume important de donn\u00e9es. </p> <p>Les villes intelligentes</p> <p>Les villes intelligentes utilisent l\u2019IoT sur plusieurs aspects tel que : les transports automatiques, les syst\u00e8mes intelligents de gestion de l\u2019\u00e9nergie et de distribution de l\u2019eau, la s\u00e9curit\u00e9 urbaine et la surveillance de l\u2019environnement. Ces villes utilisent l\u2019IoT et le Big Data pour collecter et analyser des donn\u00e9es provenant de diverses sources, telles que des capteurs et des cam\u00e9ras installer partout dans la ville, afin de r\u00e9soudre les probl\u00e8mes rencontr\u00e9s par les citoyens, nous citons comme exemples :  </p> <p>\u2022   Les syst\u00e8mes intelligents de gestion du trafic qui utilisent les donn\u00e9es des capteurs de trafic pour optimiser la circulation et r\u00e9duire les embouteillages.</p> <p>\u2022   Les syst\u00e8mes d\u2019\u00e9clairage intelligents qui utilisent des donn\u00e9es provenant de capteurs pour ajuster la luminosit\u00e9 et la synchronisation des lampadaires.</p> <p>\u2022   Les syst\u00e8mes intelligents de gestion des d\u00e9chets qui utilisent les donn\u00e9es de capteurs de niveau de d\u00e9chets pour optimiser les itin\u00e9raires de collecte des ordures.</p> <p>\u2022   Les syst\u00e8mes de stationnement intelligents qui utilisent les donn\u00e9es fournies par des capteurs pour guider les conducteurs vers les places de stationnement disponibles et r\u00e9duire les embouteillages.</p> <p>\u2022   Les syst\u00e8mes de surveillance de la qualit\u00e9 de l\u2019air et de l\u2019eau qui utilisent des capteurs IoT pour d\u00e9tecter et alerter les responsables de la ville des dangers potentiels. </p> <p>Certains rapports estiment que les villes intelligentes peuvent g\u00e9n\u00e9rer jusqu\u2019\u00e0 t\u00e9rabytes de donn\u00e9es par jour, ce volume de donn\u00e9es est en constante augmentation en raison de la croissance de l\u2019Internet des objets (IoT) et de la 5G.</p> <p>La domotique</p> <p>Les syst\u00e8mes domotiques ou les maisons intelligentes contient des appareilles qui fonctionnent \u00e0 base de l\u2019IoT, comme les climatiseurs, les lumi\u00e8res et les ventilateurs. Cela donne la possibilit\u00e9 \u00e0 l\u2019utilisateur de contr\u00f4ler sa maison \u00e0 une distance \u00e9tendue, en fait, il peut contr\u00f4ler la temp\u00e9rature, l\u2019\u00e9clairage, la gestion de l\u2019\u00e9nergie, l\u2019expansion, le syst\u00e8me de s\u00e9curit\u00e9, et l\u2019acc\u00e8s \u00e0 distance.</p> <p>La domotique utilise des capteurs, des actionneurs, des r\u00e9seaux de communication et des syst\u00e8mes de contr\u00f4le pour automatiser les t\u00e2ches m\u00e9nag\u00e8res et am\u00e9liorer le confort et la s\u00e9curit\u00e9 des r\u00e9sidents. La domotique utilise les technologies du Big Data, et des algorithmes d\u2019analyse des donn\u00e9es pour pr\u00e9voir les besoins futurs et anticiper les probl\u00e8mes. Par exemple, en utilisant des donn\u00e9es sur les tendances de consommation d\u2019\u00e9nergie, les syst\u00e8mes de domotique peuvent ajuster automatiquement les param\u00e8tres de chauffage et de climatisation pour r\u00e9duire la consommation d\u2019\u00e9nergie.</p> <p>En conclusion, la domotique et le BIG Data sont \u00e9troitement li\u00e9s car ces derniers permettent de collecter, stocker et utiliser des donn\u00e9es pour am\u00e9liorer les performances des syst\u00e8mes de domotique en termes de confort, s\u00e9curit\u00e9 et \u00e9conomie d\u2019\u00e9nergie.</p> <p>Les appareils portables</p> <p>De nos jours, l\u2019IoT a \u00e9t\u00e9 int\u00e9gr\u00e9 dans la plupart des appareils portable, ces derni\u00e8res contient des cam\u00e9ras, des capteurs de son, les r\u00e9seaux et la connexion \u00e0 internet, qui utilisent pour collecter certaines informations sur l\u2019utilisateurs, notamment : </p> <p>\u2022   Les donn\u00e9es de localisation : les smartphones utilisent des technologies comme GPS, Wi-Fi et les r\u00e9seaux cellulaires pour d\u00e9terminer la position de l\u2019utilisateur.</p> <p>\u2022   Les donn\u00e9es de navigation : les smartphones enregistrent les sites web et les applications que l\u2019utilisateur a visit\u00e9s.</p> <p>\u2022   Les donn\u00e9es de contacts : les smartphones stockent les informations de contact de l\u2019utilisateur, comme les num\u00e9ros de t\u00e9l\u00e9phone et les adresses e-mail.</p> <p>\u2022   Les donn\u00e9es de messages : les smartphones peuvent stocker les messages texte et les conversations de messagerie instantan\u00e9e de l\u2019utilisateur.</p> <p>\u2022   Les donn\u00e9es de m\u00e9dias : les smartphones peuvent stocker les photos, les vid\u00e9os et les fichiers audio pris ou enregistr\u00e9s par l\u2019utilisateur.</p> <p>Les rapports informent que aujourd\u2019hui les serveurs de Facebook doivent analyser tous les demi-heure l\u2019\u00e9quivalent de 105 To de donn\u00e9es (Botton \u2018\u2019j\u2019aime\u2019\u2019, photos, requ\u00eate \u2026 ).</p>"},{"location":"projects/big%20data%20for%20iot/#approches-et-outils-pour-gerer-le-big-data-et-liot","title":"Approches et outils pour g\u00e9rer le Big Data et l\u2019IoT","text":"<p>Info</p> <p>Pr\u00e9sentation des diff\u00e9rents approches et outils utilis\u00e9s pour g\u00e9rer et analyser le Big Data et l\u2019IoT, tels que les plateformes de gestion de donn\u00e9es, les outils d\u2019analyse de donn\u00e9es en temps r\u00e9el, etc.</p> <p>Le Big Data et l\u2019IoT (Internet des objets) sont deux domaines qui ont connu une croissance explosive ces derni\u00e8res ann\u00e9es et qui continuent de se d\u00e9velopper rapidement. Le Big Data fait r\u00e9f\u00e9rence \u00e0 l\u2019ensemble des donn\u00e9es g\u00e9n\u00e9r\u00e9es par les entreprises, les organisations et les individus, tandis que l\u2019IoT d\u00e9signe l\u2019ensemble des objets connect\u00e9s \u00e0 Internet qui sont capables de collecter et de transmettre des donn\u00e9es. La gestion de ces deux domaines peut \u00eatre complexe, mais il existe plusieurs approches et outils qui peuvent aider les entreprises \u00e0 y parvenir.</p> <p>Une approche courante pour g\u00e9rer le Big Data consiste \u00e0 utiliser des technologies de gestion de donn\u00e9es distribu\u00e9es, telles que Hadoop ou Spark. Ces technologies permettent de traiter de grandes quantit\u00e9s de donn\u00e9es de mani\u00e8re efficace et \u00e0 bas co\u00fbt en r\u00e9partissant le travail sur plusieurs n\u0153uds de calcul.</p> <p>Il est \u00e9galement possible de g\u00e9rer le Big Data en utilisant des bases de donn\u00e9es en m\u00e9moire, comme Redis ou Memcached, qui permettent de traiter les donn\u00e9es de mani\u00e8re plus rapide que les bases de donn\u00e9es traditionnelles. Cependant, ces bases de donn\u00e9es sont g\u00e9n\u00e9ralement moins adapt\u00e9es aux grands volumes de donn\u00e9es et ne conviennent pas toujours \u00e0 tous les types de donn\u00e9es.</p> <p>Pour g\u00e9rer l\u2019IoT, il est courant d\u2019utiliser des plateformes de gestion de l\u2019IoT, telles que AWS IoT ou Azure IoT, qui permettent de collecter, de stocker et de traiter les donn\u00e9es provenant d\u2019objets connect\u00e9s. Ces plateformes offrent \u00e9galement des outils pour la gestion de l\u2019IoT, tels que la gestion des appareils, la s\u00e9curit\u00e9 et la conformit\u00e9.</p> <p>On note \u00e9galement l\u2019utilisation de capteurs (par exemple, capteurs de temp\u00e9rature, de mouvement, de pression) ainsi que des protocoles de communication sans fil (par exemple, Bluetooth, Wi-Fi, LTE).Ces appareils permettent de collecter des donn\u00e9es environnementales ou de contr\u00f4ler des objets physiques \u00e0 distance. Pour cela, ils utilisent des protocoles qui permettent \u00e0 diff\u00e9rents appareils de communiquer entre eux et de se connecter \u00e0 Internet. Ils sont souvent utilis\u00e9s pour la communication entre appareils IoT.</p> <p>En conclusion, il existe de nombreux approches et outils pour g\u00e9rer le Big Data et l\u2019IoT. Le choix de la solution d\u00e9pend de l\u2019environnement de l\u2019entreprise et de ses besoins en mati\u00e8re de traitement de donn\u00e9es. Il est important de prendre le temps de bien comprendre les options disponibles et de choisir la solution qui convient le mieux \u00e0 l\u2019entreprise afin de maximiser l\u2019efficacit\u00e9 et l\u2019efficience de la gestion des donn\u00e9es.</p>"},{"location":"projects/big%20data%20for%20iot/#enjeux-et-defis-lies-au-big-data-et-a-liot","title":"Enjeux et d\u00e9fis li\u00e9s au Big Data et \u00e0 l\u2019IoT","text":"<p>Le recours au big data s\u2019av\u00e8re ainsi substantiel pour l\u2019exploitation et le traitement des vastes quantit\u00e9s de donn\u00e9es collect\u00e9es par les dispositifs connect\u00e9s (iot), dont les enjeux sont list\u00e9s ci-dessous :</p> <p>1. Confidentialit\u00e9 et s\u00e9curit\u00e9</p> <p>Les donn\u00e9es collect\u00e9es par les objets connect\u00e9s peuvent \u00eatre utilis\u00e9es pour suivre les activit\u00e9s des personnes, \u00e0 savoir des comptes utilisateurs, de consommateurs. Pourtant, elles peuvent \u00eatre utilis\u00e9es \u00e0 des fins malveillantes ou sans le consentement des personnes concern\u00e9es. De plus, lesdits objets  peuvent \u00eatre la cible de diff\u00e9rentes formes d\u2019attaques, comme les attaques de d\u00e9ni de service, les attaques de fuites de donn\u00e9es ou les attaques de piratage, et par cons\u00e9quent, la gestion de la s\u00e9curit\u00e9 des donn\u00e9es massives et confidentielles demeure un d\u00e9fi en raison de la quantit\u00e9 de donn\u00e9es \u00e0 prot\u00e9ger et des risques potentiels pouvant affecter les donn\u00e9es.</p> <p>2. Vari\u00e9t\u00e9s de donn\u00e9es</p> <p>Les donn\u00e9es massives collect\u00e9es via les appareils connect\u00e9s peuvent \u00eatre de diff\u00e9rents types (structur\u00e9es, non structur\u00e9es, semi-structur\u00e9es) et provenir de diff\u00e9rentes sources. Par exemple, la plupart des donn\u00e9es collect\u00e9es peuvent \u00eatre sous format d\u2019images, de fichiers audio, de documents, de fichiers texte, etc. qui ne sont pas structur\u00e9es et ne se trouvent pas dans des bases de donn\u00e9es. Il sera donc difficile d\u2019extraire et d\u2019analyser par la suite toutes ces donn\u00e9es non structur\u00e9es.</p> <p>3. La vitesse de gestion des m\u00e9gadonn\u00e9es</p> <p>Ceci est consid\u00e9r\u00e9 comme un enjeu crucial vu que les donn\u00e9es massives collect\u00e9es sur Internet peuvent \u00eatre g\u00e9n\u00e9r\u00e9es et mises \u00e0 jour tr\u00e8s rapidement. Cela peut rendre difficile le traitement en temps r\u00e9el des donn\u00e9es et l\u2019obtention de r\u00e9sultats rapides. Par exemple, si les donn\u00e9es sont utilis\u00e9es pour prendre des d\u00e9cisions commerciales importantes, il est crucial d\u2019avoir acc\u00e8s \u00e0 des donn\u00e9es \u00e0 jour et de pouvoir traiter rapidement ces donn\u00e9es pour obtenir des r\u00e9sultats en temps opportun.</p> <p>4. Stockage et infrastructure des donn\u00e9es</p> <p>Le stockage et l\u2019infrastructure des donn\u00e9es sont des enjeux importants pour l\u2019usage du big data au service de l\u2019IoT car celui-ci implique la collecte et le traitement de grandes quantit\u00e9s de donn\u00e9es en temps r\u00e9el, qui peuvent provenir de diff\u00e9rents types de capteurs et de dispositifs connect\u00e9s. Ces donn\u00e9es peuvent \u00eatre utilis\u00e9es pour diverses fins, telles que l\u2019optimisation de la production, l\u2019am\u00e9lioration de la maintenance pr\u00e9ventive ou l\u2019analyse de la performance des syst\u00e8mes. Par cons\u00e9quent, la gestion efficace de ces donn\u00e9es repose sur une infrastructure de stockage et de traitement de donn\u00e9es ad\u00e9quates ( bases de donn\u00e9es distribu\u00e9es, syst\u00e8mes de fichiers distribu\u00e9s, \u2026).</p>"},{"location":"projects/big%20data%20for%20iot/#applications-de-lia-dans-le-big-data-et-liot","title":"Applications de l\u2019IA dans le Big Data et l\u2019IoT","text":"<p>Info</p> <p>Pr\u00e9sentation des diff\u00e9rentes applications de l\u2019intelligence artificielle dans le Big Data et l\u2019IoT, ainsi que leur impact sur l\u2019analyse et la prise de d\u00e9cision.</p> <p>L\u2019intelligence artificielle (IA) est de plus en plus utilis\u00e9e pour traiter les donn\u00e9es massives g\u00e9n\u00e9r\u00e9es par les objets connect\u00e9s dans l\u2019Internet des objets (IoT). La combinaison de l\u2019IA et du Big Data permet d\u2019optimiser les processus d\u2019analyse et de pr\u00e9diction, offrant ainsi de nouvelles possibilit\u00e9s pour les entreprises et les organisations.</p> <p>Une des principales applications de l\u2019IA dans le Big Data et l\u2019IoT est l\u2019analyse pr\u00e9dictive. Les mod\u00e8les de pr\u00e9diction bas\u00e9s sur l\u2019IA peuvent \u00eatre utilis\u00e9s pour pr\u00e9voir la maintenance des \u00e9quipements, la consommation d\u2019\u00e9nergie ou encore les tendances de vente. Cela permet aux entreprises de planifier efficacement leur maintenance et de maximiser leur rendement. En outre, cela permet d\u2019anticiper les besoins en consommation d\u2019\u00e9nergie et de planifier la production d\u2019\u00e9nergie en cons\u00e9quence. Les tendances de vente peuvent \u00e9galement \u00eatre pr\u00e9vues pour adapter les strat\u00e9gies de marketing et de production.</p> <p>La maintenance pr\u00e9ventive est une autre application importante de l\u2019IA dans le Big Data et l\u2019IoT. Les capteurs int\u00e9gr\u00e9s dans les \u00e9quipements industriels peuvent collecter des donn\u00e9es en temps r\u00e9el sur leur performance. L\u2019IA peut ensuite \u00eatre utilis\u00e9e pour d\u00e9tecter les anomalies et les signes de d\u00e9t\u00e9rioration, permettant ainsi une maintenance pr\u00e9ventive pour \u00e9viter les pannes. Cela permet aux entreprises de r\u00e9duire les co\u00fbts li\u00e9s aux pannes inattendues et de maximiser la disponibilit\u00e9 de leurs \u00e9quipements. Cela contribue \u00e9galement \u00e0 la s\u00e9curit\u00e9 des employ\u00e9s en r\u00e9duisant les risques d\u2019accidents li\u00e9s \u00e0 des \u00e9quipements d\u00e9fectueux.</p> <p>L\u2019IA peut \u00e9galement \u00eatre utilis\u00e9e pour optimiser les r\u00e9seaux de transport et de distribution d\u2019\u00e9nergie. Les donn\u00e9es recueillies par les objets connect\u00e9s peuvent \u00eatre utilis\u00e9es pour planifier les itin\u00e9raires de transport les plus efficaces, ou encore pour r\u00e9guler la production d\u2019\u00e9nergie \u00e9olienne et solaire. Cela permet d\u2019optimiser les itin\u00e9raires de transport, de r\u00e9duire les co\u00fbts de transport et d\u2019am\u00e9liorer la qualit\u00e9 des services de transport. L\u2019IA peut \u00e9galement \u00eatre utilis\u00e9e pour r\u00e9guler la production d\u2019\u00e9nergie renouvelable en fonction des besoins en \u00e9nergie pour maximiser l\u2019utilisation des ressources.</p> <p>Enfin, l\u2019IA peut \u00eatre utilis\u00e9e pour am\u00e9liorer la qualit\u00e9 de vie des individus. Les objets connect\u00e9s peuvent collecter des donn\u00e9es sur les habitudes de vie des individus, permettant ainsi une meilleure compr\u00e9hension de leurs besoins. L\u2019IA peut \u00eatre utilis\u00e9e pour d\u00e9velopper des solutions personnalis\u00e9es en mati\u00e8re de sant\u00e9, de logement ou encore de consommation d\u2019\u00e9nergie. Cela permet de cr\u00e9er des environnements de vie plus confortables et plus sains pour les individus.</p>"},{"location":"projects/big%20data%20for%20iot/#perspectives-futures-du-big-data-et-de-liot","title":"Perspectives futures du Big Data et de l\u2019IoT","text":"<p>Info</p> <p>Pr\u00e9sentation des tendances et perspectives futures du Big Data et de l\u2019IoT, ainsi que leur impact sur les entreprises et la soci\u00e9t\u00e9 en g\u00e9n\u00e9ral.</p> <p>L\u2019internet des objets est l\u2019une des innovations qui fa\u00e7onneront fortement notre avenir. Grace \u00e0 son fort progr\u00e8s au cours du temps, il serait possible de connecter la majorit\u00e9 des appareils qui nous entourent et ainsi exploiter le Big Data partag\u00e9 dans tous les aspects de notre vie. Voici les principales fa\u00e7ons dont l\u2019IOT et le Big Data impacteront les entreprises en particulier et la soci\u00e9t\u00e9 en g\u00e9n\u00e9ral :</p> <p>Marketing personnalis\u00e9</p> <p>Gr\u00e2ce aux donn\u00e9es g\u00e9n\u00e9r\u00e9es par les appareils interconnect\u00e9s, il serait possible de cibler le bon public et de lui transmettre le bon message au moment le plus id\u00e9al. Ainsi, les gens recevront toute sorte de publicit\u00e9 ou promotion qui correspond parfaitement \u00e0 leurs comportements d\u2019achat et \u00e0 leurs int\u00e9r\u00eats, ce qui rend les chances de se rapprocher d\u2019un client plus probables, certaines et m\u00eame inimaginables.  D\u2019ailleurs, les entreprises d\u2019aujourd\u2019hui essaient de tirer profit au maximum de l\u2019ensemble des technologies \u00e9mergentes afin d\u2019augmenter les r\u00e9sultats et d\u00e9velopper des campagnes marketing tr\u00e8s efficace capables de bien g\u00e9rer le budget qui leur est d\u00e9di\u00e9.</p> <p>Villes intelligentes</p> <p>L\u2019IOT et le Big Data participeront fortement \u00e0 la modernisation de nos villes via l\u2019adoption de certaines appareils interconnect\u00e9s capables de collecter un maximum de donn\u00e9es en temps r\u00e9el et l\u2019application majeure de l\u2019intelligence artificielle dans le but de rendre les technologies existantes plus intelligentes et ad\u00e9quates. Ainsi, la ville de demain sera \u00e9quip\u00e9e par des contr\u00f4leurs du trafic servant \u00e0 la pr\u00e9diction du danger sur la route, des routes solaires contenant des panneaux photovolta\u00efques pour avertir les conducteurs en cas d\u2019obstacle ou animal, des arr\u00eats de bus intelligents qui activent et d\u00e9sactivent le chauffage et la climatisation de fa\u00e7on automatique\u2026</p> <p>Prise de d\u00e9cision am\u00e9lior\u00e9e</p> <p>L\u2019acc\u00e8s en temps r\u00e9el \u00e0 un maximum d\u2019informations tangibles permettra aux entreprises et aux d\u00e9tenteurs de magasin de prendre la bonne d\u00e9cision, d\u2019anticiper les risques les plus mena\u00e7ants et d\u2019\u00e9conomiser les d\u00e9penses. Ils sauront interpr\u00e9ter et surveiller l\u2019ensemble des donn\u00e9es r\u00e9colt\u00e9es par les capteurs IOT pour d\u00e9duire le bon volume \u00e0 produire, les types de produits les plus vendus, la saisonnalit\u00e9 des ventes\u2026, ce qui conduira \u00e0 une efficacit\u00e9 accrue, \u00e0 des couts op\u00e9rationnels r\u00e9duits et \u00e0 un retour sur investissement plus \u00e9lev\u00e9.</p> <p>Chaine d\u2019approvisionnement optimis\u00e9e</p> <p>La mise en \u0153uvre de l\u2019IOT et du Big Data permettra de bien contr\u00f4ler le flux du produit : de l\u2019approvisionnement en mati\u00e8res premi\u00e8res jusqu\u2019\u00e0 la distribution du produit final. En connectant les processus et les personnes, il serait possible de mesurer les informations collect\u00e9es, de les \u00e9changer et de les analyser par des tableaux de bord afin de prendre des d\u00e9cisions proactives bas\u00e9es sur les donn\u00e9es et superviser la chaine d\u2019approvisionnement dans sa totalit\u00e9.</p> <p>Organisations et syst\u00e8mes de sant\u00e9 d\u00e9velopp\u00e9s</p> <p>Les soins pour les patients peuvent \u00eatre, gr\u00e2ce \u00e0 la m\u00e9decine de pr\u00e9cision favoris\u00e9e par l\u2019IOT et le Big Data, consid\u00e9rablement am\u00e9lior\u00e9s comme leurs qualit\u00e9s de vie. Il serait possible de collecter un maximum de donn\u00e9es sur leurs programmes de m\u00e9dicament via des capteurs ou montres intelligents sans n\u00e9cessit\u00e9 de recourir constamment aux analyses et aux m\u00e9decins. De plus, il serait possible de localiser avec un simple clic les h\u00f4pitaux et les ambulances qui sont les plus proches, de pr\u00e9dire avec pr\u00e9cision les maladies et de d\u00e9velopper de nouveaux m\u00e9dicaments en se basant sur l\u2019analyse des donn\u00e9es cliniques.</p> <p>Agriculture connect\u00e9e</p> <p>Le Big Data collect\u00e9 via les tracteurs, animaux, drones et machines de r\u00e9colte connect\u00e9s permettra aux agriculteurs dans le futur proche d\u2019am\u00e9liorer le rendement de leurs terres et fermes. Ils seront capables d\u2019acc\u00e9der en temps r\u00e9el aux informations qui lui sont assez importantes, d\u2019anticiper les maladies des cultures pour faire les pr\u00e9cautions n\u00e9cessaires et d\u2019optimiser l\u2019irrigation et l\u2019emploi des fertilisants. D\u2019o\u00f9 une agriculture future \u00e9cologique, \u00e9conome et de haute pr\u00e9cision.</p> <p>Gestion de transport am\u00e9lior\u00e9e</p> <p>L\u2019IOT et le Big Data jouent un r\u00f4le important pour les diff\u00e9rents types de syst\u00e8mes de transport : maritime, a\u00e9rien, ferroviaire et routier. Ils permettront de garantir un transport de services et biens s\u00e9curis\u00e9, de coordonner efficacement l\u2019exp\u00e9dition et d\u2019assurer en permanence la connectivit\u00e9 r\u00e9seau sur les routes. De plus, ils serviront \u00e0 anticiper la maintenance et l\u2019entretien des \u00e9quipements, \u00e0 contr\u00f4ler toute pollution d\u00e9gag\u00e9e des moyens de transport et \u00e0 r\u00e9duire le recrutement des chauffeurs \u00e0 cause des v\u00e9hicules autonomes. Ainsi, la gestion du transport de demain serait plus simple, efficace et s\u00e9curis\u00e9e.</p> <p>Consommation \u00e9nerg\u00e9tique optimis\u00e9e</p> <p>Gr\u00e2ce \u00e0 la collecte instantan\u00e9e en temps r\u00e9el des donn\u00e9es li\u00e9es \u00e0 la consommation et aux pertes \u00e9nerg\u00e9tiques, il serait possible d\u2019identifier l\u2019ensemble des comportements \u00e0 optimiser et \u00e9viter le gaspillage des ressources. De plus, les consommateurs particuliers ou entreprises disposeront d\u2019algorithmes leur permettant de pr\u00e9dire leur consommation \u00e9nerg\u00e9tique d\u00e9pendamment d\u2019appareils ou machines utilis\u00e9es, de r\u00e9duire leurs d\u00e9penses et d\u2019am\u00e9liorer le confort logement. Ainsi, les comportements \u00e9nerg\u00e9tiques futurs seraient plus sobres et r\u00e9pondent \u00e0 la neutralit\u00e9 carbone et aux enjeux \u00e9nerg\u00e9tiques les plus complexes. </p> <p>M\u00e9tiers nouveaux</p> <p>Gr\u00e2ce \u00e0 l\u2019\u00e9volution remarquable de l\u2019impl\u00e9mentation de l\u2019IOT et de l\u2019exploitation du Big Data, les m\u00e9tiers d\u2019avenir seront focalis\u00e9s sur tout ce qui est digitalisation et intelligence artificielle. Voici quelques exemples des m\u00e9tiers les plus incontournables dans le futur proche : Data Engineer, ing\u00e9nieur DevOps/Cloud, architecte Big Data, Data Analyst, Data Scientist, Tech Lead Big Data\u2026</p>"},{"location":"projects/big%20data%20for%20iot/#conclusion","title":"Conclusion","text":"<p>Info</p> <p>Synth\u00e8se des principaux points abord\u00e9s dans l\u2019expos\u00e9 et \u00e9ventuelles r\u00e9flexions sur l\u2019avenir du Big Data et de l\u2019IoT.</p> <p>En conclusion, il est clair que le Big Data et l\u2019IoT ont un impact significatif sur les entreprises et la soci\u00e9t\u00e9 en g\u00e9n\u00e9ral. Les avanc\u00e9es technologiques en cours permettront de collecter et de traiter des volumes encore plus importants de donn\u00e9es, offrant ainsi de nouvelles opportunit\u00e9s pour optimiser les processus d\u2019analyse et de pr\u00e9diction. Cependant, il est important de noter que ces technologies posent \u00e9galement des d\u00e9fis en mati\u00e8re de s\u00e9curit\u00e9 et de confidentialit\u00e9 des donn\u00e9es. Il est donc crucial de continuer \u00e0 d\u00e9velopper des approches et des outils pour g\u00e9rer efficacement ces donn\u00e9es massives tout en prot\u00e9geant les int\u00e9r\u00eats des utilisateurs.</p>"},{"location":"projects/boston%20datasets/","title":"Boston Datasets","text":""},{"location":"projects/boston%20datasets/#bibliotheques","title":"Biblioth\u00e8ques","text":"<p>Biblioth\u00e8ques</p> <p>Tout d\u2019abord, ex\u00e9cutons la cellule ci-dessous pour importer tous les paquets dont vous aurez besoin au cours de cette \u00e9tude.</p> <ul> <li> <p>pandas est une biblioth\u00e8que \u00e9crite pour le langage de programmation Python permettant la manipulation et l\u2019analyse des donn\u00e9es.</p> </li> <li> <p>numpy est une biblioth\u00e8que pour langage de programmation Python, destin\u00e9e \u00e0 manipuler des matrices ou tableaux multidimensionnels ainsi que des fonctions math\u00e9matiques op\u00e9rant sur ces tableaux.</p> </li> <li> <p>matplotlib est une biblioth\u00e8que du langage de programmation Python destin\u00e9e \u00e0 tracer et visualiser des donn\u00e9es sous forme de graphiques.</p> </li> <li> <p>seaborn est une biblioth\u00e8que de visualisation Python bas\u00e9e sur matplotlib. Elle fournit une interface de haut niveau pour dessiner des graphiques statistiques attrayants.</p> </li> <li> <p>keras est l\u2019API de haut niveau de TensorFlow.</p> </li> <li> <p>sklearn est une biblioth\u00e8que libre Python destin\u00e9e \u00e0 l\u2019apprentissage automatique. </p> </li> <li>pickle est principalement utilis\u00e9 pour s\u00e9rialiser et d\u00e9s\u00e9rialiser une structure objet Python. En d\u2019autres termes, c\u2019est le processus de conversion d\u2019un objet Python en un flux d\u2019octets pour le stocker dans un fichier/base de donn\u00e9es, maintenir l\u2019\u00e9tat du programme entre les sessions ou transporter des donn\u00e9es sur le r\u00e9seau.</li> </ul> <pre><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tensorflow import keras\nfrom keras import layers\nimport seaborn as sns\nimport pickle\nfrom sklearn import svm\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\n</code></pre>"},{"location":"projects/boston%20datasets/#etude-exploratoire-des-donnees","title":"Etude exploratoire des donn\u00e9es","text":""},{"location":"projects/boston%20datasets/#definition-des-colonnes","title":"D\u00e9finition des colonnes","text":"<p>D\u00e9finition des colonnes</p> <p>Dans le domaine de la science des donn\u00e9es, la premi\u00e8re chose \u00e0 faire est de bien comprendre les donn\u00e9es, ainsi et dans ce m\u00eame sens, nous avons d\u00e9fini les colonnes comme suit :</p> <ul> <li> <p><code>CRIM</code>: per capita crime rate by town.</p> </li> <li> <p><code>ZN</code>: proportion of residential land zoned for lots over 25,000 sq.ft.</p> </li> <li> <p><code>INDUS</code>: proportion of non-retail business acres per town.</p> </li> <li> <p><code>CHAS</code>: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).</p> </li> <li> <p><code>NOX</code>: nitric oxides concentration (parts per 10 million).</p> </li> <li> <p><code>RM</code>: average number of rooms per dwelling.</p> </li> <li> <p><code>AGE</code>: proportion of owner-occupied units built prior to 1940.</p> </li> <li> <p><code>DIS</code>: weighted distances to five Boston employment centres.</p> </li> <li> <p><code>RAD</code>: index of accessibility to radial highways.</p> </li> <li> <p><code>TAX</code>: full-value property-tax rate per $10,000.</p> </li> <li> <p><code>PTRATIO</code>: pupil-teacher ratio by town.</p> </li> <li> <p><code>B</code>: 1000(Bk - 0.63)^2 where Bk is the proportion of black people by town.</p> </li> <li> <p><code>LSTAT</code>: % lower status of the population.</p> </li> <li> <p><code>MEDV</code>: our Target, Median value of owner-occupied homes in $1000\u2019s</p> </li> </ul>"},{"location":"projects/boston%20datasets/#feature-engineering","title":"Feature engineering","text":"<p><pre><code># Importer le dataset\nfrom sklearn.datasets import load_boston\nboston = load_boston()\n</code></pre> <pre><code># Afficher les \u00e9\u00e9ments cl\u00e9s du dataset\nboston.keys()\n</code></pre></p> Output <p>dict_keys([\u2018data\u2019, \u2018target\u2019, \u2018feature_names\u2019, \u2018DESCR\u2019, \u2018filename\u2019, \u2018data_module\u2019])</p> <pre><code>## Afficher la description du dataset\nprint(boston.DESCR)\n</code></pre> Output <p>.. _boston_dataset:</p> <p>Boston house prices dataset</p> <p>Data Set Characteristics: </p> <pre><code>:Number of Instances: 506\n\n:Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n\n:Attribute Information (in order):\n    - CRIM     per capita crime rate by town\n    - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n    - INDUS    proportion of non-retail business acres per town\n    - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n    - NOX      nitric oxides concentration (parts per 10 million)\n    - RM       average number of rooms per dwelling\n    - AGE      proportion of owner-occupied units built prior to 1940\n    - DIS      weighted distances to five Boston employment centres\n    - RAD      index of accessibility to radial highways\n    - TAX      full-value property-tax rate per $10,000\n    - PTRATIO  pupil-teacher ratio by town\n    - B        1000(Bk - 0.63)^2 where Bk is the proportion of black people by town\n    - LSTAT    % lower status of the population\n    - MEDV     Median value of owner-occupied homes in $1000's\n\n:Missing Attribute Values: None\n\n:Creator: Harrison, D. and Rubinfeld, D.L.\n</code></pre> <p>This is a copy of UCI ML housing dataset. https://archive.ics.uci.edu/ml/machine-learning-databases/housing/</p> <p>This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.</p> <p>The Boston house-price data of Harrison, D. and Rubinfeld, D.L. \u2018Hedonic prices and the demand for clean air\u2019, J. Environ. Economics &amp; Management, vol.5, 81-102, 1978.   Used in Belsley, Kuh &amp; Welsch, \u2018Regression diagnostics \u2026\u2019, Wiley, 1980.   N.B. Various transformations are used in the table on pages 244-261 of the latter.</p> <p>The Boston house-price data has been used in many machine learning papers that address regression problems.   </p> <p>.. topic:: References</p> <ul> <li>Belsley, Kuh &amp; Welsch, \u2018Regression diagnostics: Identifying Influential Data and Sources of Collinearity\u2019, Wiley, 1980. 244-261.</li> <li>Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.</li> </ul> <pre><code># Afficher le contenu des features \nprint(boston.data)\n</code></pre> Output <p>[[6.3200e-03 1.8000e+01 2.3100e+00 \u2026 1.5300e+01 3.9690e+02 4.9800e+00]</p> <p>[2.7310e-02 0.e+00 7.0700e+00 \u2026 1.7800e+01 3.9690e+02 9.1400e+00]</p> <p>[2.7290e-02 0.e+00 7.0700e+00 \u2026 1.7800e+01 3.9283e+02 4.0300e+00]</p> <p>\u2026</p> <p>[6.0760e-02 0.e+00 1.1930e+01 \u2026 2.1000e+01 3.9690e+02 5.6400e+00]</p> <p>[1.0959e-01 0.e+00 1.1930e+01 \u2026 2.1000e+01 3.9345e+02 6.4800e+00]</p> <p>[4.7410e-02 0.e+00 1.1930e+01 \u2026 2.1000e+01 3.9690e+02 7.8800e+00]]</p> <pre><code># Afficher le contenu du label\nprint(boston.target)\n</code></pre> Output <p>[24.  21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 15.  18.9 21.7 20.4 18.2 19.9 23.1 17.5 20.2 18.2 13.6 19.6 15.2 14.5 15.6 13.9 16.6 14.8 18.4 21.  12.7 14.5 13.2 13.1 13.5 18.9 20.  21.  24.7 30.8 34.9 26.6 25.3 24.7 21.2 19.3 20.  16.6 14.4 19.4 19.7 20.5 25.  23.4 18.9 35.4 24.7 31.6 23.3 19.6 18.7 16.  22.2 25.  33.  23.5 19.4 22.  17.4 20.9 24.2 21.7 22.8 23.4 24.1 21.4 20.  20.8 21.2 20.3 28.  23.9 24.8 22.9 23.9 26.6 22.5 22.2 23.6 28.7 22.6 22.  22.9 25.  20.6 28.4 21.4 38.7 43.8 33.2 27.5 26.5 18.6 19.3 20.1 19.5 19.5 20.4 19.8 19.4 21.7 22.8 18.8 18.7 18.5 18.3 21.2 19.2 20.4 19.3 22.  20.3 20.5 17.3 18.8 21.4 15.7 16.2 18.  14.3 19.2 19.6 23.  18.4 15.6 18.1 17.4 17.1 13.3 17.8 14.  14.4 13.4 15.6 11.8 13.8 15.6 14.6 17.8 15.4 21.5 19.6 15.3 19.4 17.  15.6 13.1 41.3 24.3 23.3 27.  50.  50.  50.  22.7 25.  50.  23.8 23.8 22.3 17.4 19.1 23.1 23.6 22.6 29.4 23.2 24.6 29.9 37.2 39.8 36.2 37.9 32.5 26.4 29.6 50.  32.  29.8 34.9 37.  30.5 36.4 31.1 29.1 50. 33.3 30.3 34.6 34.9 32.9 24.1 42.3 48.5 50.  22.6 24.4 22.5 24.4 20. 21.7 19.3 22.4 28.1 23.7 25.  23.3 28.7 21.5 23.  26.7 21.7 27.5 30.1 44.8 50.  37.6 31.6 46.7 31.5 24.3 31.7 41.7 48.3 29.  24.  25.1 31.5 23.7 23.3 22.  20.1 22.2 23.7 17.6 18.5 24.3 20.5 24.5 26.2 24.4 24.8 29.6 42.8 21.9 20.9 44.  50.  36.  30.1 33.8 43.1 48.8 31.  36.5 22.8 30.7 50.  43.5 20.7 21.1 25.2 24.4 35.2 32.4 32.  33.2 33.1 29.1 35.1 45.4 35.4 46.  50.  32.2 22.  20.1 23.2 22.3 24.8 28.5 37.3 27.9 23.9 21.7 28.6 27.1 20.3 22.5 29.  24.8 22.  26.4 33.1 36.1 28.4 33.4 28.2 22.8 20.3 16.1 22.1 19.4 21.6 23.8 16.2 17.8 19.8 23.1 21.  23.8 23.1 20.4 18.5 25.  24.6 23.  22.2 19.3 22.6 19.8 17.1 19.4 22.2 20.7 21.1 19.5 18.5 20.6 19.  18.7 32.7 16.5 23.9 31.2 17.5 17.2 23.1 24.5 26.6 22.9 24.1 18.6 30.1 18.2 20.6 17.8 21.7 22.7 22.6 25.  19.9 20.8 16.8 21.9 27.5 21.9 23.1 50.  50.  50.  50.  50.  13.8 13.8 15.  13.9 13.3 13.1 10.2 10.4 10.9 11.3 12.3  8.8  7.2 10.5  7.4 10.2 11.5 15.1 23.2 9.7 13.8 12.7 13.1 12.5  8.5  5.   6.3  5.6  7.2 12.1  8.3  8.5  5. 11.9 27.9 17.2 27.5 15.  17.2 17.9 16.3  7.   7.2  7.5 10.4  8.8  8.4 16.7 14.2 20.8 13.4 11.7  8.3 10.2 10.9 11.   9.5 14.5 14.1 16.1 14.3 11.7 13.4  9.6  8.7  8.4 12.8 10.5 17.1 18.4 15.4 10.8 11.8 14.9 12.6 14.1 13.  13.4 15.2 16.1 17.8 14.9 14.1 12.7 13.5 14.9 20.  16.4 17.7 19.5 20.2 21.4 19.9 19.  19.1 19.1 20.1 19.9 19.6 23.2 29.8 13.8 13.3 16.7 12.  14.6 21.4 23.  23.7 25.  21.8 20.6 21.2 19.1 20.6 15.2  7. 8.1 13.6 20.1 21.8 24.5 23.1 19.7 18.3 21.2 17.5 16.8 22.4 20.6 23.9 22.  11.9]</p> <pre><code># Afficher les noms des features\nprint(boston.feature_names)\n</code></pre> Output <p>[\u2018CRIM\u2019 \u2018ZN\u2019 \u2018INDUS\u2019 \u2018CHAS\u2019 \u2018NOX\u2019 \u2018RM\u2019 \u2018AGE\u2019 \u2018DIS\u2019 \u2018RAD\u2019 \u2018TAX\u2019 \u2018PTRATIO\u2019 \u2018B\u2019 \u2018LSTAT\u2019]</p> <p><pre><code># Transformer le boston dataset en Data Frame\ndataset = pd.DataFrame(boston.data,columns=boston.feature_names)\n</code></pre> <pre><code># Afficher les 5 premi\u00e8res lignes du dataset\ndataset.head(5)\n</code></pre></p> Output CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT 0 0.00632 18.0 2.31 0.0 0.538 6.575 65.2 4.0900 1.0 296.0 15.3 396.90 4.98 1 0.02731 0.0 7.07 0.0 0.469 6.421 78.9 4.9671 2.0 242.0 17.8 396.90 9.14 2 0.02729 0.0 7.07 0.0 0.469 7.185 61.1 4.9671 2.0 242.0 17.8 392.83 4.03 3 0.03237 0.0 2.18 0.0 0.458 6.998 45.8 6.0622 3.0 222.0 18.7 394.63 2.94 4 0.06905 0.0 2.18 0.0 0.458 7.147 54.2 6.0622 3.0 222.0 18.7 396.90 5.33 <p><pre><code># Ajouter le label au dataset et lui nommer \"Price\"\ndataset['MEDV'] = boston.target\n</code></pre> <pre><code># Afficher quelques informations de la data\ndataset.info()\n</code></pre></p> Output <p><code>&lt;class 'pandas.core.frame.DataFrame'&gt;</code></p> <p>RangeIndex: 506 entries, 0 to 505</p> <p>Data columns (total 14 columns):</p> # Column Non-Null Count Dtype 0 CRIM 506 non-null float64 1 ZN 506 non-null float64 2 INDUS 506 non-null float64 3 CHAS 506 non-null float64 4 NOX 506 non-null float64 5 RM 506 non-null float64 6 AGE 506 non-null float64 7 DIS 506 non-null float64 8 RAD 506 non-null float64 9 TAX 506 non-null float64 10 PTRATIO 506 non-null float64 11 B 506 non-null float64 12 LSTAT 506 non-null float64 13 MEDV 506 non-null float64 <p>dtypes: float64(14)</p> <p>memory usage: 55.5 KB</p> <ul> <li> <p>Le Dataset contient 506 lignes et 14 colonnes.</p> </li> <li> <p>toutes les colonnes sont de type float64.</p> </li> </ul> <pre><code># Afficher une description statistique de la dataset\ndataset.describe()\n</code></pre> Output CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT MEDV count 506.00 506.00 506.00 506.00 506.00 506.00 506.00 506.00 506.00 506.00 506.00 506.00 506.00 506.00 mean 3.61 11.36 11.13 0.06 0.55 6.28 68.57 3.79 9.54 408.23 18.45 356.67 12.65 22.53 std 8.60 23.32 6.86 0.25 0.11 0.70 28.14 2.10 8.70 168.53 2.16 91.29 7.14 9.19 min 0.006 0.00 0.46 0.00 0.38 3.56 2.90 1.12 1.00 187.00 12.60 0.32 1.73 5.00 25% 0.08 0.00 5.19 0.00 0.44 5.88 45.02 2.10 4.00 279.00 17.40 375.37 6.95 17.02 50% 0.25 0.00 9.69 0.00 0.53 6.20 77.50 3.20 5.00 330.00 19.05 391.44 11.36 21.20 75% 3.67 12.50 18.10 0.00 0.62 6.62 94.07 5.18 24.00 666.00 20.20 396.22 16.95 25.00 max 88.97 100.00 27.74 1.00 0.87 8.78 100.00 12.12 24.00 711.00 22.00 396.90 37.97 50.00 <pre><code># Afficher les valeurs NaN\ndataset.isnull().sum()\n</code></pre> Output Column Number of NaN CRIM 0 ZN 0 INDUS 0 CHAS 0 NOX 0 RM 0 AGE 0 DIS 0 RAD 0 TAX 0 PTRATIO 0 B 0 LSTAT 0 MEDV 0 <p>dtype: int64</p> <p>Nous notons que le dataset ne contient pas de valeurs NaN.</p>"},{"location":"projects/boston%20datasets/#vizualisation-des-donnees","title":"Vizualisation des donn\u00e9es","text":""},{"location":"projects/boston%20datasets/#matrice-de-correlation","title":"Matrice de corr\u00e9lation","text":"<p>La matrice de corr\u00e9lation indique les valeurs de corr\u00e9lation, qui mesurent le degr\u00e9 de relation lin\u00e9aire entre chaque paire de variables. Les valeurs de corr\u00e9lation peuvent \u00eatre comprises entre -1 et +1. Si les deux variables ont tendance \u00e0 augmenter et \u00e0 diminuer en m\u00eame temps, la valeur de corr\u00e9lation est positive. Lorsqu\u2019une variable augmente alors que l\u2019autre diminue, la valeur de corr\u00e9lation est n\u00e9gative.</p> <pre><code># Afficher la matrice de corr\u00e9lation\nmatriceCorr = data.corr().round(1)\nsns.heatmap(data=matriceCorr, annot = True)\n</code></pre> Output <p></p> <p>Nous notons qu\u2019il y a plusieurs correlations entre les colonnes, mais nous n\u2019allons pas prendre en consid\u00e9ration ces corr\u00e9lations pour l\u2019instant parce que les r\u00e9seaux de neuronnes peuvent d\u00e9tecter les corr\u00e9lations ainsi les traiter. </p>"},{"location":"projects/boston%20datasets/#representations-des-colonnes-deux-a-deux","title":"Repr\u00e9sentations des colonnes deux \u00e0 deux","text":"<pre><code># Afficher les repr\u00e9sentations des colonnes deux \u00e0 deux\nsns.pairplot(dataset)\n</code></pre> Output <pre><code># Afficher \"MEDV\" en fonction de \"CRIM\"\nplt.scatter(dataset['CRIM'],dataset['MEDV'])\nplt.xlabel(\"Crime Rate\")\nplt.ylabel(\"Medv\")\n</code></pre> Output <pre><code># Afficher \"RM\" en fonction de \"MEDV\"\nplt.scatter(dataset['RM'],dataset['MEDV'])\nplt.xlabel(\"RM\")\nplt.ylabel(\"Medv\")\n</code></pre> Output <pre><code># Tracer les donn\u00e9es et l'ajustement d'un mod\u00e8le de r\u00e9gression lin\u00e9aire MEDV=f(RM)\nsns.regplot(x=\"RM\",y=\"MEDV\",data=dataset)\n</code></pre> Output <pre><code># Tracer les donn\u00e9es et l'ajustement d'un mod\u00e8le de r\u00e9gression lin\u00e9aire MEDV=f(LSTAT)\nsns.regplot(x=\"LSTAT\",y=\"MEDV\",data=dataset)\n</code></pre> Output <pre><code># Tracer les donn\u00e9es et l'ajustement d'un mod\u00e8le de r\u00e9gression lin\u00e9aire MEDV=f(CHAS)\nsns.regplot(x=\"CHAS\",y=\"MEDV\",data=dataset)\n</code></pre> Output <pre><code># Tracer les donn\u00e9es et l'ajustement d'un mod\u00e8le de r\u00e9gression lin\u00e9aire MEDV=f(PTRATIO)\nsns.regplot(x=\"PTRATIO\",y=\"MEDV\",data=dataset)\n</code></pre> Output"},{"location":"projects/boston%20datasets/#implementation-des-modeles","title":"Impl\u00e9mentation des mod\u00e8les","text":""},{"location":"projects/boston%20datasets/#preparation-des-des-vecteurs-dentrainement","title":"Pr\u00e9paration des des vecteurs d\u2019entrainement","text":"<p>Maintenant nous allons impl\u00e9menter et entrainer plusieurs mod\u00e8les de machine learning afin de choisir le meilleur, mais avant nous devons d\u00e9finir les features, le target et d\u00e9composer le dataset en data d\u2019entrainement et data du test.  </p> <p><pre><code># D\u00e9finir les features\nX = dataset.drop('MEDV', axis=1)\n# D\u00e9finir le target\ny = dataset['MEDV']\n</code></pre> <pre><code># D\u00e9composer la data en 80% pour l'entrainement et 20% pour le test\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n</code></pre> <pre><code># Afficher la taille de X_train, X_test, y_train, y_test\nprint(\"la taille de X_train est :\", X_train.shape)\nprint(\"la taille de X_test est :\", X_test.shape)\nprint(\"la taille de y_train est :\", y_train.shape)\nprint(\"la taille de y_test est :\", y_test.shape)\n</code></pre></p> Output <p>la taille de X_train est : (404, 13)</p> <p>la taille de X_test est : (102, 13)</p> <p>la taille de y_train est : (404,)</p> <p>la taille de y_test est : (102,)</p> <pre><code># Norrmalisation des donn\u00e9es en utilisant le StandardScaler (x-mean)/(std)\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n</code></pre>"},{"location":"projects/boston%20datasets/#reseaux-de-neurones-denses-dnn","title":"R\u00e9seaux de neurones denses DNN","text":"<p><pre><code>num_layer1 = 50\nnum_layer2 = 50\nmodel = keras.models.Sequential(name='DNN')\nmodel.add(layers.Input((13,), name=\"Couche_in\"))\nmodel.add(layers.Dense(num_layer1, activation='relu', name='Couche_cachee1'))\nmodel.add(layers.Dense(num_layer2, activation='relu', name='Couche_cachee2'))\nmodel.add(layers.Dense(1, name='Couche_out'))\n</code></pre> <pre><code>model.compile(optimizer='adam',\nloss='mse',\nmetrics=['mae'])\n</code></pre> <pre><code>model.summary()\n</code></pre></p> Output <p>Model: \u201cDNN\u201d</p> Layer (type) Output Shape Param # Couche_cachee1 (Dense) (None, 50) 700 Couche_cachee2 (Dense) (None, 50) 2550 Couche_out (Dense) (None, 1) 51 <p>Total params: 3,301</p> <p>Trainable params: 3,301</p> <p>Non-trainable params: 0</p> <pre><code># Lancer l'entrainement du mod\u00e8le\nhist = model.fit(X_train,\ny_train,\nepochs=400,\nbatch_size=50)\n</code></pre> Output <p>Epoch 1/400 9/9 [==============================] - 1s 4ms/step - loss: 557.3136 - mae: 21.6968</p> <p>Epoch 2/400 9/9 [==============================] - 0s 3ms/step - loss: 520.2143 - mae: 20.8262</p> <p>Epoch 3/400 9/9 [==============================] - 0s 3ms/step - loss: 475.9985 - mae: 19.7651</p> <p>Epoch 4/400 9/9 [==============================] - 0s 3ms/step - loss: 423.2747 - mae: 18.4109</p> <p>Epoch 5/400 9/9 [==============================] - 0s 3ms/step - loss: 361.1457 - mae: 16.7136</p> <p>Epoch 6/400 9/9 [==============================] - 0s 3ms/step - loss: 289.6600 - mae: 14.6173</p> <p>Epoch 7/400 9/9 [==============================] - 0s 3ms/step - loss: 219.4651 - mae: 12.2325</p> <p>Epoch 8/400 9/9 [==============================] - 0s 3ms/step - loss: 158.8683 - mae: 10.0692</p> <p>Epoch 9/400 9/9 [==============================] - 0s 3ms/step - loss: 116.7818 - mae: 8.3857</p> <p>Epoch 10/400 9/9 [==============================] - 0s 3ms/step - loss: 91.9504 - mae: 7.3596</p> <p>Epoch 11/400 9/9 [==============================] - 0s 3ms/step - loss: 76.5844 - mae: 6.6405</p> <p>Epoch 12/400 9/9 [==============================] - 0s 8ms/step - loss: 62.4096 - mae: 5.9445</p> <p>Epoch 13/400 9/9 [==============================] - 0s 3ms/step - loss: 49.9997 - mae: 5.3151</p> <p>Epoch 14/400 9/9 [==============================] - 0s 3ms/step - loss: 40.8705 - mae: 4.8252</p> <p>Epoch 15/400 9/9 [==============================] - 0s 3ms/step - loss: 34.1865 - mae: 4.4059</p> <p>Epoch 16/400 9/9 [==============================] - 0s 3ms/step - loss: 29.6209 - mae: 4.0728</p> <p>Epoch 17/400 9/9 [==============================] - 0s 3ms/step - loss: 26.3418 - mae: 3.8037</p> <p>Epoch 18/400 9/9 [==============================] - 0s 3ms/step - loss: 24.0514 - mae: 3.6174</p> <p>Epoch 19/400 9/9 [==============================] - 0s 3ms/step - loss: 22.3640 - mae: 3.4849</p> <p>Epoch 20/400 9/9 [==============================] - 0s 3ms/step - loss: 21.0404 - mae: 3.3751</p> <p>Epoch 21/400 9/9 [==============================] - 0s 3ms/step - loss: 20.0787 - mae: 3.2945</p> <p>Epoch 22/400 9/9 [==============================] - 0s 4ms/step - loss: 19.1893 - mae: 3.2271</p> <p>Epoch 23/400 9/9 [==============================] - 0s 3ms/step - loss: 18.4744 - mae: 3.1858</p> <p>Epoch 24/400 9/9 [==============================] - 0s 3ms/step - loss: 17.9731 - mae: 3.1562</p> <p>Epoch 25/400 9/9 [==============================] - 0s 3ms/step - loss: 17.4404 - mae: 3.0923</p> <p>Epoch 26/400 9/9 [==============================] - 0s 3ms/step - loss: 16.9731 - mae: 3.0298</p> <p>Epoch 27/400 9/9 [==============================] - 0s 3ms/step - loss: 16.6027 - mae: 2.9926</p> <p>Epoch 28/400 9/9 [==============================] - 0s 3ms/step - loss: 16.2943 - mae: 2.9884</p> <p>Epoch 29/400 9/9 [==============================] - 0s 3ms/step - loss: 16.1183 - mae: 2.9904</p> <p>Epoch 30/400 9/9 [==============================] - 0s 3ms/step - loss: 15.8298 - mae: 2.9535</p> <p>Epoch 31/400 9/9 [==============================] - 0s 3ms/step - loss: 15.4369 - mae: 2.8914</p> <p>Epoch 32/400 9/9 [==============================] - 0s 3ms/step - loss: 15.2457 - mae: 2.8531</p> <p>Epoch 33/400 9/9 [==============================] - 0s 3ms/step - loss: 15.0859 - mae: 2.8292</p> <p>Epoch 34/400 9/9 [==============================] - 0s 3ms/step - loss: 14.8123 - mae: 2.8021</p> <p>Epoch 35/400 9/9 [==============================] - 0s 2ms/step - loss: 14.7016 - mae: 2.8349</p> <p>Epoch 36/400 9/9 [==============================] - 0s 3ms/step - loss: 14.7392 - mae: 2.8583</p> <p>Epoch 37/400 9/9 [==============================] - 0s 3ms/step - loss: 14.4040 - mae: 2.7936</p> <p>Epoch 38/400 9/9 [==============================] - 0s 3ms/step - loss: 14.1673 - mae: 2.7549</p> <p>Epoch 39/400 9/9 [==============================] - 0s 3ms/step - loss: 14.0135 - mae: 2.7394</p> <p>Epoch 40/400 9/9 [==============================] - 0s 3ms/step - loss: 13.7766 - mae: 2.7193</p> <p>Epoch 41/400 9/9 [==============================] - 0s 3ms/step - loss: 13.6497 - mae: 2.7049</p> <p>Epoch 42/400 9/9 [==============================] - 0s 3ms/step - loss: 13.8148 - mae: 2.7279</p> <p>Epoch 43/400 9/9 [==============================] - 0s 3ms/step - loss: 13.5806 - mae: 2.7368</p> <p>Epoch 44/400 9/9 [==============================] - 0s 4ms/step - loss: 13.3692 - mae: 2.6903</p> <p>Epoch 45/400 9/9 [==============================] - 0s 3ms/step - loss: 13.1967 - mae: 2.6587</p> <p>Epoch 46/400 9/9 [==============================] - 0s 3ms/step - loss: 13.0199 - mae: 2.6454</p> <p>Epoch 47/400 9/9 [==============================] - 0s 3ms/step - loss: 13.0109 - mae: 2.6521</p> <p>Epoch 48/400 9/9 [==============================] - 0s 3ms/step - loss: 12.9398 - mae: 2.6408</p> <p>Epoch 49/400 9/9 [==============================] - 0s 3ms/step - loss: 12.8580 - mae: 2.6236</p> <p>Epoch 50/400 9/9 [==============================] - 0s 3ms/step - loss: 12.8581 - mae: 2.6218</p> <p>Epoch 51/400 9/9 [==============================] - 0s 3ms/step - loss: 12.7277 - mae: 2.6095</p> <p>Epoch 52/400 9/9 [==============================] - 0s 3ms/step - loss: 12.5262 - mae: 2.5825</p> <p>Epoch 53/400 9/9 [==============================] - 0s 3ms/step - loss: 12.5404 - mae: 2.5921</p> <p>Epoch 54/400 9/9 [==============================] - 0s 3ms/step - loss: 12.3580 - mae: 2.5644</p> <p>Epoch 55/400 9/9 [==============================] - 0s 3ms/step - loss: 12.2630 - mae: 2.5534</p> <p>Epoch 56/400 9/9 [==============================] - 0s 3ms/step - loss: 12.1893 - mae: 2.5394</p> <p>Epoch 57/400 9/9 [==============================] - 0s 4ms/step - loss: 12.0945 - mae: 2.5230</p> <p>Epoch 58/400 9/9 [==============================] - 0s 3ms/step - loss: 12.1561 - mae: 2.5299</p> <p>Epoch 59/400 9/9 [==============================] - 0s 3ms/step - loss: 12.0405 - mae: 2.5175</p> <p>Epoch 60/400 9/9 [==============================] - 0s 3ms/step - loss: 12.0079 - mae: 2.4976</p> <p>Epoch 61/400 9/9 [==============================] - 0s 3ms/step - loss: 11.8621 - mae: 2.4903</p> <p>Epoch 62/400 9/9 [==============================] - 0s 3ms/step - loss: 11.7536 - mae: 2.4790</p> <p>Epoch 63/400 9/9 [==============================] - 0s 3ms/step - loss: 11.8308 - mae: 2.4806</p> <p>Epoch 64/400 9/9 [==============================] - 0s 3ms/step - loss: 11.8091 - mae: 2.4820</p> <p>Epoch 65/400 9/9 [==============================] - 0s 3ms/step - loss: 11.6384 - mae: 2.4957</p> <p>Epoch 66/400 9/9 [==============================] - 0s 3ms/step - loss: 11.8385 - mae: 2.5424</p> <p>Epoch 67/400 9/9 [==============================] - 0s 4ms/step - loss: 11.7600 - mae: 2.5212</p> <p>Epoch 68/400 9/9 [==============================] - 0s 3ms/step - loss: 11.4665 - mae: 2.4539</p> <p>Epoch 69/400 9/9 [==============================] - 0s 3ms/step - loss: 11.4085 - mae: 2.4327</p> <p>Epoch 70/400 9/9 [==============================] - 0s 3ms/step - loss: 11.3790 - mae: 2.4286</p> <p>Epoch 71/400 9/9 [==============================] - 0s 4ms/step - loss: 11.2816 - mae: 2.4209</p> <p>Epoch 72/400 9/9 [==============================] - 0s 4ms/step - loss: 11.2071 - mae: 2.4173</p> <p>Epoch 73/400 9/9 [==============================] - 0s 3ms/step - loss: 11.1422 - mae: 2.4088</p> <p>Epoch 74/400 9/9 [==============================] - 0s 3ms/step - loss: 11.0773 - mae: 2.4023</p> <p>Epoch 75/400 9/9 [==============================] - 0s 3ms/step - loss: 11.0161 - mae: 2.3964</p> <p>Epoch 76/400 9/9 [==============================] - 0s 4ms/step - loss: 11.0054 - mae: 2.3888</p> <p>Epoch 77/400 9/9 [==============================] - 0s 3ms/step - loss: 10.8978 - mae: 2.3807</p> <p>Epoch 78/400 9/9 [==============================] - 0s 3ms/step - loss: 10.8926 - mae: 2.3930</p> <p>Epoch 79/400 9/9 [==============================] - 0s 3ms/step - loss: 10.9182 - mae: 2.3996</p> <p>Epoch 80/400 9/9 [==============================] - 0s 3ms/step - loss: 10.9850 - mae: 2.4115</p> <p>Epoch 81/400 9/9 [==============================] - 0s 3ms/step - loss: 11.0064 - mae: 2.3867</p> <p>Epoch 82/400 9/9 [==============================] - 0s 3ms/step - loss: 11.1898 - mae: 2.3889</p> <p>Epoch 83/400 9/9 [==============================] - 0s 3ms/step - loss: 10.7470 - mae: 2.3746</p> <p>Epoch 84/400 9/9 [==============================] - 0s 3ms/step - loss: 10.8092 - mae: 2.4083</p> <p>Epoch 85/400 9/9 [==============================] - 0s 3ms/step - loss: 10.5877 - mae: 2.3942</p> <p>Epoch 86/400 9/9 [==============================] - 0s 4ms/step - loss: 10.5039 - mae: 2.3632</p> <p>Epoch 87/400 9/9 [==============================] - 0s 3ms/step - loss: 10.5263 - mae: 2.3636</p> <p>Epoch 88/400 9/9 [==============================] - 0s 3ms/step - loss: 10.4007 - mae: 2.3452</p> <p>Epoch 89/400 9/9 [==============================] - 0s 3ms/step - loss: 10.3052 - mae: 2.3390</p> <p>Epoch 90/400 9/9 [==============================] - 0s 3ms/step - loss: 10.2830 - mae: 2.3430</p> <p>Epoch 91/400 9/9 [==============================] - 0s 3ms/step - loss: 10.2626 - mae: 2.3305</p> <p>Epoch 92/400 9/9 [==============================] - 0s 3ms/step - loss: 10.2998 - mae: 2.3301</p> <p>Epoch 93/400 9/9 [==============================] - 0s 3ms/step - loss: 10.3857 - mae: 2.3660</p> <p>Epoch 94/400 9/9 [==============================] - 0s 3ms/step - loss: 10.2242 - mae: 2.3430</p> <p>Epoch 95/400 9/9 [==============================] - 0s 3ms/step - loss: 10.0685 - mae: 2.3185</p> <p>Epoch 96/400 9/9 [==============================] - 0s 3ms/step - loss: 10.0650 - mae: 2.3192</p> <p>Epoch 97/400 9/9 [==============================] - 0s 3ms/step - loss: 10.0117 - mae: 2.3269</p> <p>Epoch 98/400 9/9 [==============================] - 0s 3ms/step - loss: 10.0123 - mae: 2.3178</p> <p>Epoch 99/400 9/9 [==============================] - 0s 3ms/step - loss: 9.9383 - mae: 2.3025</p> <p>Epoch 100/400 9/9 [==============================] - 0s 4ms/step - loss: 9.8653 - mae: 2.2933</p> <p>Epoch 101/400 9/9 [==============================] - 0s 3ms/step - loss: 9.9191 - mae: 2.3033</p> <p>Epoch 102/400 9/9 [==============================] - 0s 3ms/step - loss: 9.8622 - mae: 2.2823</p> <p>Epoch 103/400 9/9 [==============================] - 0s 3ms/step - loss: 9.7497 - mae: 2.2569</p> <p>Epoch 104/400 9/9 [==============================] - 0s 3ms/step - loss: 9.6942 - mae: 2.2639</p> <p>Epoch 105/400 9/9 [==============================] - 0s 4ms/step - loss: 9.6776 - mae: 2.2588</p> <p>Epoch 106/400 9/9 [==============================] - 0s 3ms/step - loss: 9.7455 - mae: 2.2674</p> <p>Epoch 107/400 9/9 [==============================] - 0s 3ms/step - loss: 9.5815 - mae: 2.2458</p> <p>Epoch 108/400 9/9 [==============================] - 0s 3ms/step - loss: 9.5837 - mae: 2.2518</p> <p>Epoch 109/400 9/9 [==============================] - 0s 3ms/step - loss: 9.4691 - mae: 2.2334</p> <p>Epoch 110/400 9/9 [==============================] - 0s 3ms/step - loss: 9.4230 - mae: 2.2271</p> <p>Epoch 111/400 9/9 [==============================] - 0s 3ms/step - loss: 9.4083 - mae: 2.2276</p> <p>Epoch 112/400 9/9 [==============================] - 0s 3ms/step - loss: 9.3655 - mae: 2.2257</p> <p>Epoch 113/400 9/9 [==============================] - 0s 3ms/step - loss: 9.3588 - mae: 2.2105</p> <p>Epoch 114/400 9/9 [==============================] - 0s 3ms/step - loss: 9.6419 - mae: 2.2598</p> <p>Epoch 115/400 9/9 [==============================] - 0s 3ms/step - loss: 9.5963 - mae: 2.2624</p> <p>Epoch 116/400 9/9 [==============================] - 0s 3ms/step - loss: 9.4118 - mae: 2.2251</p> <p>Epoch 117/400 9/9 [==============================] - 0s 3ms/step - loss: 9.2462 - mae: 2.2159</p> <p>Epoch 118/400 9/9 [==============================] - 0s 3ms/step - loss: 9.2559 - mae: 2.2230</p> <p>Epoch 119/400 9/9 [==============================] - 0s 3ms/step - loss: 9.1834 - mae: 2.2073</p> <p>Epoch 120/400 9/9 [==============================] - 0s 3ms/step - loss: 9.1216 - mae: 2.1961</p> <p>Epoch 121/400 9/9 [==============================] - 0s 4ms/step - loss: 9.1227 - mae: 2.1902</p> <p>Epoch 122/400 9/9 [==============================] - 0s 3ms/step - loss: 9.1087 - mae: 2.1876</p> <p>Epoch 123/400 9/9 [==============================] - 0s 4ms/step - loss: 9.1089 - mae: 2.1849</p> <p>Epoch 124/400 9/9 [==============================] - 0s 3ms/step - loss: 9.0926 - mae: 2.1861</p> <p>Epoch 125/400 9/9 [==============================] - 0s 3ms/step - loss: 9.2096 - mae: 2.2124</p> <p>Epoch 126/400 9/9 [==============================] - 0s 4ms/step - loss: 9.0495 - mae: 2.1710</p> <p>Epoch 127/400 9/9 [==============================] - 0s 3ms/step - loss: 8.9340 - mae: 2.1624</p> <p>Epoch 128/400 9/9 [==============================] - 0s 4ms/step - loss: 8.8782 - mae: 2.1619</p> <p>Epoch 129/400 9/9 [==============================] - 0s 3ms/step - loss: 8.8453 - mae: 2.1571</p> <p>Epoch 130/400 9/9 [==============================] - 0s 4ms/step - loss: 8.9253 - mae: 2.1674</p> <p>Epoch 131/400 9/9 [==============================] - 0s 5ms/step - loss: 8.8694 - mae: 2.1647</p> <p>Epoch 132/400 9/9 [==============================] - 0s 4ms/step - loss: 8.7110 - mae: 2.1455</p> <p>Epoch 133/400 9/9 [==============================] - 0s 4ms/step - loss: 8.7117 - mae: 2.1463</p> <p>Epoch 134/400 9/9 [==============================] - 0s 3ms/step - loss: 8.7079 - mae: 2.1490</p> <p>Epoch 135/400 9/9 [==============================] - 0s 4ms/step - loss: 8.6802 - mae: 2.1438</p> <p>Epoch 136/400 9/9 [==============================] - 0s 3ms/step - loss: 8.6549 - mae: 2.1312</p> <p>Epoch 137/400 9/9 [==============================] - 0s 3ms/step - loss: 8.5795 - mae: 2.1202</p> <p>Epoch 138/400 9/9 [==============================] - 0s 3ms/step - loss: 8.5459 - mae: 2.1143</p> <p>Epoch 139/400 9/9 [==============================] - 0s 3ms/step - loss: 8.5602 - mae: 2.1233</p> <p>Epoch 140/400 9/9 [==============================] - 0s 3ms/step - loss: 8.4806 - mae: 2.1126</p> <p>Epoch 141/400 9/9 [==============================] - 0s 3ms/step - loss: 8.4711 - mae: 2.1127</p> <p>Epoch 142/400 9/9 [==============================] - 0s 3ms/step - loss: 8.4310 - mae: 2.1130</p> <p>Epoch 143/400 9/9 [==============================] - 0s 3ms/step - loss: 8.3803 - mae: 2.1100</p> <p>Epoch 144/400 9/9 [==============================] - 0s 3ms/step - loss: 8.4019 - mae: 2.1182</p> <p>Epoch 145/400 9/9 [==============================] - 0s 3ms/step - loss: 8.5072 - mae: 2.1415</p> <p>Epoch 146/400 9/9 [==============================] - 0s 3ms/step - loss: 8.4077 - mae: 2.1234</p> <p>Epoch 147/400 9/9 [==============================] - 0s 3ms/step - loss: 8.3219 - mae: 2.1120</p> <p>Epoch 148/400 9/9 [==============================] - 0s 3ms/step - loss: 8.2850 - mae: 2.1045</p> <p>Epoch 149/400 9/9 [==============================] - 0s 3ms/step - loss: 8.2003 - mae: 2.0864</p> <p>Epoch 150/400 9/9 [==============================] - 0s 3ms/step - loss: 8.3044 - mae: 2.1012</p> <p>Epoch 151/400 9/9 [==============================] - 0s 3ms/step - loss: 8.1278 - mae: 2.0764</p> <p>Epoch 152/400 9/9 [==============================] - 0s 3ms/step - loss: 8.1840 - mae: 2.0984</p> <p>Epoch 153/400 9/9 [==============================] - 0s 3ms/step - loss: 8.0466 - mae: 2.0698</p> <p>Epoch 154/400 9/9 [==============================] - 0s 3ms/step - loss: 8.0476 - mae: 2.0702</p> <p>Epoch 155/400 9/9 [==============================] - 0s 3ms/step - loss: 8.0402 - mae: 2.0748</p> <p>Epoch 156/400 9/9 [==============================] - 0s 3ms/step - loss: 7.9566 - mae: 2.0641</p> <p>Epoch 157/400 9/9 [==============================] - 0s 3ms/step - loss: 7.9516 - mae: 2.0667</p> <p>Epoch 158/400 9/9 [==============================] - 0s 3ms/step - loss: 7.9795 - mae: 2.0733</p> <p>Epoch 159/400 9/9 [==============================] - 0s 4ms/step - loss: 7.8663 - mae: 2.0591</p> <p>Epoch 160/400 9/9 [==============================] - 0s 3ms/step - loss: 7.8300 - mae: 2.0529</p> <p>Epoch 161/400 9/9 [==============================] - 0s 3ms/step - loss: 7.8782 - mae: 2.0532</p> <p>Epoch 162/400 9/9 [==============================] - 0s 3ms/step - loss: 7.7560 - mae: 2.0371</p> <p>Epoch 163/400 9/9 [==============================] - 0s 3ms/step - loss: 7.9327 - mae: 2.0501</p> <p>Epoch 164/400 9/9 [==============================] - 0s 3ms/step - loss: 8.0039 - mae: 2.0472</p> <p>Epoch 165/400 9/9 [==============================] - 0s 4ms/step - loss: 7.8326 - mae: 2.0383</p> <p>Epoch 166/400 9/9 [==============================] - 0s 3ms/step - loss: 7.7433 - mae: 2.0366</p> <p>Epoch 167/400 9/9 [==============================] - 0s 3ms/step - loss: 7.7063 - mae: 2.0403</p> <p>Epoch 168/400 9/9 [==============================] - 0s 4ms/step - loss: 7.6165 - mae: 2.0247</p> <p>Epoch 169/400 9/9 [==============================] - 0s 3ms/step - loss: 7.6203 - mae: 2.0237</p> <p>Epoch 170/400 9/9 [==============================] - 0s 4ms/step - loss: 7.7583 - mae: 2.0332</p> <p>Epoch 171/400 9/9 [==============================] - 0s 4ms/step - loss: 7.7060 - mae: 2.0474</p> <p>Epoch 172/400 9/9 [==============================] - 0s 4ms/step - loss: 7.7214 - mae: 2.0453</p> <p>Epoch 173/400 9/9 [==============================] - 0s 4ms/step - loss: 7.5782 - mae: 2.0151</p> <p>Epoch 174/400 9/9 [==============================] - 0s 3ms/step - loss: 7.4870 - mae: 1.9941</p> <p>Epoch 175/400 9/9 [==============================] - 0s 3ms/step - loss: 7.4292 - mae: 1.9942</p> <p>Epoch 176/400 9/9 [==============================] - 0s 3ms/step - loss: 7.4034 - mae: 1.9908</p> <p>Epoch 177/400 9/9 [==============================] - 0s 3ms/step - loss: 7.3374 - mae: 1.9794</p> <p>Epoch 178/400 9/9 [==============================] - 0s 3ms/step - loss: 7.3651 - mae: 1.9837</p> <p>Epoch 179/400 9/9 [==============================] - 0s 3ms/step - loss: 7.3334 - mae: 1.9801</p> <p>Epoch 180/400 9/9 [==============================] - 0s 3ms/step - loss: 7.2986 - mae: 1.9715</p> <p>Epoch 181/400 9/9 [==============================] - 0s 3ms/step - loss: 7.3080 - mae: 1.9842</p> <p>Epoch 182/400 9/9 [==============================] - 0s 3ms/step - loss: 7.2384 - mae: 1.9710</p> <p>Epoch 183/400 9/9 [==============================] - 0s 3ms/step - loss: 7.2382 - mae: 1.9695</p> <p>Epoch 184/400 9/9 [==============================] - 0s 4ms/step - loss: 7.1499 - mae: 1.9672</p> <p>Epoch 185/400 9/9 [==============================] - 0s 4ms/step - loss: 7.2522 - mae: 1.9746</p> <p>Epoch 186/400 9/9 [==============================] - 0s 3ms/step - loss: 7.1246 - mae: 1.9721</p> <p>Epoch 187/400 9/9 [==============================] - 0s 3ms/step - loss: 7.0991 - mae: 1.9624</p> <p>Epoch 188/400 9/9 [==============================] - 0s 4ms/step - loss: 7.0756 - mae: 1.9483</p> <p>Epoch 189/400 9/9 [==============================] - 0s 3ms/step - loss: 7.1697 - mae: 1.9584</p> <p>Epoch 190/400 9/9 [==============================] - 0s 4ms/step - loss: 6.9426 - mae: 1.9408</p> <p>Epoch 191/400 9/9 [==============================] - 0s 3ms/step - loss: 7.0492 - mae: 1.9498</p> <p>Epoch 192/400 9/9 [==============================] - 0s 3ms/step - loss: 6.9617 - mae: 1.9392</p> <p>Epoch 193/400 9/9 [==============================] - 0s 3ms/step - loss: 6.9713 - mae: 1.9391</p> <p>Epoch 194/400 9/9 [==============================] - 0s 3ms/step - loss: 6.9681 - mae: 1.9466</p> <p>Epoch 195/400 9/9 [==============================] - 0s 3ms/step - loss: 7.0815 - mae: 1.9378</p> <p>Epoch 196/400 9/9 [==============================] - 0s 3ms/step - loss: 6.9769 - mae: 1.9339</p> <p>Epoch 197/400 9/9 [==============================] - 0s 4ms/step - loss: 6.8727 - mae: 1.9210</p> <p>Epoch 198/400 9/9 [==============================] - 0s 3ms/step - loss: 6.8014 - mae: 1.9227</p> <p>Epoch 199/400 9/9 [==============================] - 0s 3ms/step - loss: 6.7703 - mae: 1.9244</p> <p>Epoch 200/400 9/9 [==============================] - 0s 3ms/step - loss: 6.8127 - mae: 1.9195</p> <p>Epoch 201/400 9/9 [==============================] - 0s 3ms/step - loss: 6.7469 - mae: 1.9105</p> <p>Epoch 202/400 9/9 [==============================] - 0s 3ms/step - loss: 6.7515 - mae: 1.9144</p> <p>Epoch 203/400 9/9 [==============================] - 0s 3ms/step - loss: 6.6946 - mae: 1.9044</p> <p>Epoch 204/400 9/9 [==============================] - 0s 4ms/step - loss: 6.6362 - mae: 1.8985</p> <p>Epoch 205/400 9/9 [==============================] - 0s 4ms/step - loss: 6.6175 - mae: 1.8955</p> <p>Epoch 206/400 9/9 [==============================] - 0s 3ms/step - loss: 6.5702 - mae: 1.8874</p> <p>Epoch 207/400 9/9 [==============================] - 0s 3ms/step - loss: 6.5716 - mae: 1.8900</p> <p>Epoch 208/400 9/9 [==============================] - 0s 4ms/step - loss: 6.5384 - mae: 1.8846</p> <p>Epoch 209/400 9/9 [==============================] - 0s 3ms/step - loss: 6.5449 - mae: 1.8830</p> <p>Epoch 210/400 9/9 [==============================] - 0s 3ms/step - loss: 6.5513 - mae: 1.8749</p> <p>Epoch 211/400 9/9 [==============================] - 0s 4ms/step - loss: 6.4929 - mae: 1.8735</p> <p>Epoch 212/400 9/9 [==============================] - 0s 3ms/step - loss: 6.5068 - mae: 1.8747</p> <p>Epoch 213/400 9/9 [==============================] - 0s 3ms/step - loss: 6.5305 - mae: 1.8740</p> <p>Epoch 214/400 9/9 [==============================] - 0s 6ms/step - loss: 6.5346 - mae: 1.8997</p> <p>Epoch 215/400 9/9 [==============================] - 0s 5ms/step - loss: 6.4906 - mae: 1.8849</p> <p>Epoch 216/400 9/9 [==============================] - 0s 4ms/step - loss: 6.4162 - mae: 1.8608</p> <p>Epoch 217/400 9/9 [==============================] - 0s 3ms/step - loss: 6.3261 - mae: 1.8522</p> <p>Epoch 218/400 9/9 [==============================] - 0s 3ms/step - loss: 6.2750 - mae: 1.8420</p> <p>Epoch 219/400 9/9 [==============================] - 0s 3ms/step - loss: 6.2780 - mae: 1.8364</p> <p>Epoch 220/400 9/9 [==============================] - 0s 2ms/step - loss: 6.2991 - mae: 1.8530</p> <p>Epoch 221/400 9/9 [==============================] - 0s 2ms/step - loss: 6.2668 - mae: 1.8361</p> <p>Epoch 222/400 9/9 [==============================] - 0s 2ms/step - loss: 6.2077 - mae: 1.8355</p> <p>Epoch 223/400 9/9 [==============================] - 0s 3ms/step - loss: 6.1889 - mae: 1.8245</p> <p>Epoch 224/400 9/9 [==============================] - 0s 2ms/step - loss: 6.2081 - mae: 1.8289</p> <p>Epoch 225/400 9/9 [==============================] - 0s 2ms/step - loss: 6.1629 - mae: 1.8108</p> <p>Epoch 226/400 9/9 [==============================] - 0s 2ms/step - loss: 6.1450 - mae: 1.8226</p> <p>Epoch 227/400 9/9 [==============================] - 0s 2ms/step - loss: 6.1505 - mae: 1.8359</p> <p>Epoch 228/400 9/9 [==============================] - 0s 2ms/step - loss: 6.1221 - mae: 1.8270</p> <p>Epoch 229/400 9/9 [==============================] - 0s 3ms/step - loss: 6.1809 - mae: 1.8272</p> <p>Epoch 230/400 9/9 [==============================] - 0s 3ms/step - loss: 6.0162 - mae: 1.8011</p> <p>Epoch 231/400 9/9 [==============================] - 0s 3ms/step - loss: 6.1452 - mae: 1.8393</p> <p>Epoch 232/400 9/9 [==============================] - 0s 3ms/step - loss: 6.0985 - mae: 1.8124</p> <p>Epoch 233/400 9/9 [==============================] - 0s 2ms/step - loss: 6.4570 - mae: 1.8844</p> <p>Epoch 234/400 9/9 [==============================] - 0s 1ms/step - loss: 6.2272 - mae: 1.8489</p> <p>Epoch 235/400 9/9 [==============================] - 0s 2ms/step - loss: 6.0741 - mae: 1.8166</p> <p>Epoch 236/400 9/9 [==============================] - 0s 4ms/step - loss: 6.0031 - mae: 1.8197</p> <p>Epoch 237/400 9/9 [==============================] - 0s 2ms/step - loss: 5.9739 - mae: 1.8037</p> <p>Epoch 238/400 9/9 [==============================] - 0s 2ms/step - loss: 6.0253 - mae: 1.8145</p> <p>Epoch 239/400 9/9 [==============================] - 0s 2ms/step - loss: 5.9134 - mae: 1.7873</p> <p>Epoch 240/400 9/9 [==============================] - 0s 4ms/step - loss: 5.8683 - mae: 1.7957</p> <p>Epoch 241/400 9/9 [==============================] - 0s 2ms/step - loss: 5.8370 - mae: 1.7853</p> <p>Epoch 242/400 9/9 [==============================] - 0s 2ms/step - loss: 5.6954 - mae: 1.7598</p> <p>Epoch 243/400 9/9 [==============================] - 0s 3ms/step - loss: 5.7053 - mae: 1.7696</p> <p>Epoch 244/400 9/9 [==============================] - 0s 2ms/step - loss: 5.6565 - mae: 1.7627</p> <p>Epoch 245/400 9/9 [==============================] - 0s 2ms/step - loss: 5.7158 - mae: 1.7734</p> <p>Epoch 246/400 9/9 [==============================] - 0s 3ms/step - loss: 5.6415 - mae: 1.7482</p> <p>Epoch 247/400 9/9 [==============================] - 0s 2ms/step - loss: 5.6077 - mae: 1.7508</p> <p>Epoch 248/400 9/9 [==============================] - 0s 2ms/step - loss: 5.7397 - mae: 1.7653</p> <p>Epoch 249/400 9/9 [==============================] - 0s 3ms/step - loss: 5.6152 - mae: 1.7499</p> <p>Epoch 250/400 9/9 [==============================] - 0s 2ms/step - loss: 5.6300 - mae: 1.7422</p> <p>Epoch 251/400 9/9 [==============================] - 0s 3ms/step - loss: 5.5146 - mae: 1.7228</p> <p>Epoch 252/400 9/9 [==============================] - 0s 2ms/step - loss: 5.5786 - mae: 1.7403</p> <p>Epoch 253/400 9/9 [==============================] - 0s 4ms/step - loss: 5.5123 - mae: 1.7385</p> <p>Epoch 254/400 9/9 [==============================] - 0s 3ms/step - loss: 5.4784 - mae: 1.7380</p> <p>Epoch 255/400 9/9 [==============================] - 0s 2ms/step - loss: 5.5062 - mae: 1.7488</p> <p>Epoch 256/400 9/9 [==============================] - 0s 2ms/step - loss: 5.5507 - mae: 1.7410</p> <p>Epoch 257/400 9/9 [==============================] - 0s 3ms/step - loss: 5.4626 - mae: 1.7239</p> <p>Epoch 258/400 9/9 [==============================] - 0s 2ms/step - loss: 5.4174 - mae: 1.7266</p> <p>Epoch 259/400 9/9 [==============================] - 0s 2ms/step - loss: 5.4086 - mae: 1.7221</p> <p>Epoch 260/400 9/9 [==============================] - 0s 2ms/step - loss: 5.4384 - mae: 1.7349</p> <p>Epoch 261/400 9/9 [==============================] - 0s 2ms/step - loss: 5.3345 - mae: 1.7105</p> <p>Epoch 262/400 9/9 [==============================] - 0s 2ms/step - loss: 5.4374 - mae: 1.7372</p> <p>Epoch 263/400 9/9 [==============================] - 0s 2ms/step - loss: 5.3719 - mae: 1.7141</p> <p>Epoch 264/400 9/9 [==============================] - 0s 3ms/step - loss: 5.3888 - mae: 1.7084</p> <p>Epoch 265/400 9/9 [==============================] - 0s 2ms/step - loss: 5.3843 - mae: 1.7203</p> <p>Epoch 266/400 9/9 [==============================] - 0s 3ms/step - loss: 5.2937 - mae: 1.6940</p> <p>Epoch 267/400 9/9 [==============================] - 0s 3ms/step - loss: 5.4328 - mae: 1.7181</p> <p>Epoch 268/400 9/9 [==============================] - 0s 3ms/step - loss: 5.4531 - mae: 1.7435</p> <p>Epoch 269/400 9/9 [==============================] - 0s 3ms/step - loss: 5.3654 - mae: 1.7205</p> <p>Epoch 270/400 9/9 [==============================] - 0s 3ms/step - loss: 5.2651 - mae: 1.6883</p> <p>Epoch 271/400 9/9 [==============================] - 0s 3ms/step - loss: 5.2156 - mae: 1.6878</p> <p>Epoch 272/400 9/9 [==============================] - 0s 3ms/step - loss: 5.1566 - mae: 1.6785</p> <p>Epoch 273/400 9/9 [==============================] - 0s 2ms/step - loss: 5.1215 - mae: 1.6799</p> <p>Epoch 274/400 9/9 [==============================] - 0s 2ms/step - loss: 5.2469 - mae: 1.7029</p> <p>Epoch 275/400 9/9 [==============================] - 0s 2ms/step - loss: 5.2710 - mae: 1.7097</p> <p>Epoch 276/400 9/9 [==============================] - 0s 3ms/step - loss: 5.2278 - mae: 1.7117</p> <p>Epoch 277/400 9/9 [==============================] - 0s 3ms/step - loss: 5.2271 - mae: 1.6952</p> <p>Epoch 278/400 9/9 [==============================] - 0s 4ms/step - loss: 5.2615 - mae: 1.6881</p> <p>Epoch 279/400 9/9 [==============================] - 0s 3ms/step - loss: 5.0883 - mae: 1.6659</p> <p>Epoch 280/400 9/9 [==============================] - 0s 3ms/step - loss: 5.0631 - mae: 1.6695</p> <p>Epoch 281/400 9/9 [==============================] - 0s 2ms/step - loss: 5.0413 - mae: 1.6467</p> <p>Epoch 282/400 9/9 [==============================] - 0s 2ms/step - loss: 5.0614 - mae: 1.6541</p> <p>Epoch 283/400 9/9 [==============================] - 0s 3ms/step - loss: 5.2651 - mae: 1.6999</p> <p>Epoch 284/400 9/9 [==============================] - 0s 3ms/step - loss: 5.0937 - mae: 1.6658</p> <p>Epoch 285/400 9/9 [==============================] - 0s 3ms/step - loss: 4.9900 - mae: 1.6483</p> <p>Epoch 286/400 9/9 [==============================] - 0s 3ms/step - loss: 4.9686 - mae: 1.6482</p> <p>Epoch 287/400 9/9 [==============================] - 0s 2ms/step - loss: 4.9377 - mae: 1.6493</p> <p>Epoch 288/400 9/9 [==============================] - 0s 3ms/step - loss: 4.9239 - mae: 1.6397</p> <p>Epoch 289/400 9/9 [==============================] - 0s 4ms/step - loss: 5.0049 - mae: 1.6458</p> <p>Epoch 290/400 9/9 [==============================] - 0s 3ms/step - loss: 5.0257 - mae: 1.6677</p> <p>Epoch 291/400 9/9 [==============================] - 0s 3ms/step - loss: 4.9595 - mae: 1.6502</p> <p>Epoch 292/400 9/9 [==============================] - 0s 3ms/step - loss: 4.8937 - mae: 1.6199</p> <p>Epoch 293/400 9/9 [==============================] - 0s 3ms/step - loss: 4.8048 - mae: 1.6054</p> <p>Epoch 294/400 9/9 [==============================] - 0s 3ms/step - loss: 4.8538 - mae: 1.6189</p> <p>Epoch 295/400 9/9 [==============================] - 0s 3ms/step - loss: 4.8086 - mae: 1.6214</p> <p>Epoch 296/400 9/9 [==============================] - 0s 3ms/step - loss: 4.9100 - mae: 1.6228</p> <p>Epoch 297/400 9/9 [==============================] - 0s 4ms/step - loss: 4.7689 - mae: 1.6057</p> <p>Epoch 298/400 9/9 [==============================] - 0s 3ms/step - loss: 4.7895 - mae: 1.6120</p> <p>Epoch 299/400 9/9 [==============================] - 0s 3ms/step - loss: 4.7679 - mae: 1.6074</p> <p>Epoch 300/400 9/9 [==============================] - 0s 3ms/step - loss: 4.9302 - mae: 1.6508</p> <p>Epoch 301/400 9/9 [==============================] - 0s 4ms/step - loss: 4.8806 - mae: 1.6316</p> <p>Epoch 302/400 9/9 [==============================] - 0s 4ms/step - loss: 4.7871 - mae: 1.6054</p> <p>Epoch 303/400 9/9 [==============================] - 0s 4ms/step - loss: 4.7296 - mae: 1.6088</p> <p>Epoch 304/400 9/9 [==============================] - 0s 3ms/step - loss: 4.8593 - mae: 1.6316</p> <p>Epoch 305/400 9/9 [==============================] - 0s 3ms/step - loss: 4.8702 - mae: 1.6265</p> <p>Epoch 306/400 9/9 [==============================] - 0s 4ms/step - loss: 4.9289 - mae: 1.6436</p> <p>Epoch 307/400 9/9 [==============================] - 0s 3ms/step - loss: 4.8258 - mae: 1.6364</p> <p>Epoch 308/400 9/9 [==============================] - 0s 3ms/step - loss: 4.7715 - mae: 1.6131</p> <p>Epoch 309/400 9/9 [==============================] - 0s 3ms/step - loss: 4.7257 - mae: 1.5808</p> <p>Epoch 310/400 9/9 [==============================] - 0s 3ms/step - loss: 4.9713 - mae: 1.6622</p> <p>Epoch 311/400 9/9 [==============================] - 0s 3ms/step - loss: 4.7670 - mae: 1.6311</p> <p>Epoch 312/400 9/9 [==============================] - 0s 3ms/step - loss: 4.7790 - mae: 1.6104</p> <p>Epoch 313/400 9/9 [==============================] - 0s 3ms/step - loss: 4.6748 - mae: 1.6186</p> <p>Epoch 314/400 9/9 [==============================] - 0s 3ms/step - loss: 4.7386 - mae: 1.6191</p> <p>Epoch 315/400 9/9 [==============================] - 0s 3ms/step - loss: 4.5862 - mae: 1.5769</p> <p>Epoch 316/400 9/9 [==============================] - 0s 3ms/step - loss: 4.6310 - mae: 1.5809</p> <p>Epoch 317/400 9/9 [==============================] - 0s 3ms/step - loss: 4.8212 - mae: 1.6367</p> <p>Epoch 318/400 9/9 [==============================] - 0s 3ms/step - loss: 4.4685 - mae: 1.5482</p> <p>Epoch 319/400 9/9 [==============================] - 0s 3ms/step - loss: 4.6965 - mae: 1.5876</p> <p>Epoch 320/400 9/9 [==============================] - 0s 3ms/step - loss: 4.7098 - mae: 1.5959</p> <p>Epoch 321/400 9/9 [==============================] - 0s 3ms/step - loss: 4.8441 - mae: 1.6635</p> <p>Epoch 322/400 9/9 [==============================] - 0s 3ms/step - loss: 4.5366 - mae: 1.5945</p> <p>Epoch 323/400 9/9 [==============================] - 0s 3ms/step - loss: 4.7188 - mae: 1.5974</p> <p>Epoch 324/400 9/9 [==============================] - 0s 3ms/step - loss: 4.5682 - mae: 1.5611</p> <p>Epoch 325/400 9/9 [==============================] - 0s 3ms/step - loss: 4.5609 - mae: 1.5801</p> <p>Epoch 326/400 9/9 [==============================] - 0s 3ms/step - loss: 4.5395 - mae: 1.5852</p> <p>Epoch 327/400 9/9 [==============================] - 0s 3ms/step - loss: 4.4885 - mae: 1.5625</p> <p>Epoch 328/400 9/9 [==============================] - 0s 3ms/step - loss: 4.3885 - mae: 1.5423</p> <p>Epoch 329/400 9/9 [==============================] - 0s 4ms/step - loss: 4.5206 - mae: 1.5739</p> <p>Epoch 330/400 9/9 [==============================] - 0s 7ms/step - loss: 4.4114 - mae: 1.5382</p> <p>Epoch 331/400 9/9 [==============================] - 0s 3ms/step - loss: 4.3323 - mae: 1.5197</p> <p>Epoch 332/400 9/9 [==============================] - 0s 3ms/step - loss: 4.3240 - mae: 1.5208</p> <p>Epoch 333/400 9/9 [==============================] - 0s 3ms/step - loss: 4.4238 - mae: 1.5322</p> <p>Epoch 334/400 9/9 [==============================] - 0s 3ms/step - loss: 4.3662 - mae: 1.5501</p> <p>Epoch 335/400 9/9 [==============================] - 0s 3ms/step - loss: 4.3211 - mae: 1.5324</p> <p>Epoch 336/400 9/9 [==============================] - 0s 3ms/step - loss: 4.2283 - mae: 1.5031</p> <p>Epoch 337/400 9/9 [==============================] - 0s 4ms/step - loss: 4.2960 - mae: 1.5352</p> <p>Epoch 338/400 9/9 [==============================] - 0s 3ms/step - loss: 4.2662 - mae: 1.5223</p> <p>Epoch 339/400 9/9 [==============================] - 0s 3ms/step - loss: 4.3856 - mae: 1.5406</p> <p>Epoch 340/400 9/9 [==============================] - 0s 3ms/step - loss: 4.3143 - mae: 1.5513</p> <p>Epoch 341/400 9/9 [==============================] - 0s 3ms/step - loss: 4.3948 - mae: 1.5666</p> <p>Epoch 342/400 9/9 [==============================] - 0s 3ms/step - loss: 4.3177 - mae: 1.5356</p> <p>Epoch 343/400 9/9 [==============================] - 0s 3ms/step - loss: 4.2848 - mae: 1.5331</p> <p>Epoch 344/400 9/9 [==============================] - 0s 3ms/step - loss: 4.2723 - mae: 1.5274</p> <p>Epoch 345/400 9/9 [==============================] - 0s 3ms/step - loss: 4.2018 - mae: 1.5079</p> <p>Epoch 346/400 9/9 [==============================] - 0s 3ms/step - loss: 4.2182 - mae: 1.5171</p> <p>Epoch 347/400 9/9 [==============================] - 0s 3ms/step - loss: 4.2083 - mae: 1.5251</p> <p>Epoch 348/400 9/9 [==============================] - 0s 3ms/step - loss: 4.2829 - mae: 1.5318</p> <p>Epoch 349/400 9/9 [==============================] - 0s 3ms/step - loss: 4.1793 - mae: 1.4975</p> <p>Epoch 350/400 9/9 [==============================] - 0s 3ms/step - loss: 4.1535 - mae: 1.5021</p> <p>Epoch 351/400 9/9 [==============================] - 0s 3ms/step - loss: 4.1689 - mae: 1.4901</p> <p>Epoch 352/400 9/9 [==============================] - 0s 3ms/step - loss: 4.1737 - mae: 1.5091</p> <p>Epoch 353/400 9/9 [==============================] - 0s 3ms/step - loss: 4.2916 - mae: 1.5423</p> <p>Epoch 354/400 9/9 [==============================] - 0s 3ms/step - loss: 4.2486 - mae: 1.5089</p> <p>Epoch 355/400 9/9 [==============================] - 0s 3ms/step - loss: 4.5061 - mae: 1.5545</p> <p>Epoch 356/400 9/9 [==============================] - 0s 4ms/step - loss: 4.1563 - mae: 1.5199</p> <p>Epoch 357/400 9/9 [==============================] - 0s 3ms/step - loss: 4.1927 - mae: 1.5353</p> <p>Epoch 358/400 9/9 [==============================] - 0s 3ms/step - loss: 4.0238 - mae: 1.4803</p> <p>Epoch 359/400 9/9 [==============================] - 0s 3ms/step - loss: 4.2785 - mae: 1.5282</p> <p>Epoch 360/400 9/9 [==============================] - 0s 3ms/step - loss: 4.1957 - mae: 1.5044</p> <p>Epoch 361/400 9/9 [==============================] - 0s 3ms/step - loss: 4.0877 - mae: 1.5101</p> <p>Epoch 362/400 9/9 [==============================] - 0s 3ms/step - loss: 3.9776 - mae: 1.4631</p> <p>Epoch 363/400 9/9 [==============================] - 0s 3ms/step - loss: 3.9758 - mae: 1.4540</p> <p>Epoch 364/400 9/9 [==============================] - 0s 3ms/step - loss: 3.9303 - mae: 1.4430</p> <p>Epoch 365/400 9/9 [==============================] - 0s 3ms/step - loss: 3.9630 - mae: 1.4558</p> <p>Epoch 366/400 9/9 [==============================] - 0s 3ms/step - loss: 3.8929 - mae: 1.4350</p> <p>Epoch 367/400 9/9 [==============================] - 0s 3ms/step - loss: 3.9009 - mae: 1.4355</p> <p>Epoch 368/400 9/9 [==============================] - 0s 3ms/step - loss: 3.9361 - mae: 1.4656</p> <p>Epoch 369/400 9/9 [==============================] - 0s 3ms/step - loss: 3.9120 - mae: 1.4496</p> <p>Epoch 370/400 9/9 [==============================] - 0s 3ms/step - loss: 3.8926 - mae: 1.4374</p> <p>Epoch 371/400 9/9 [==============================] - 0s 3ms/step - loss: 3.8675 - mae: 1.4317</p> <p>Epoch 372/400 9/9 [==============================] - 0s 4ms/step - loss: 3.8442 - mae: 1.4272</p> <p>Epoch 373/400 9/9 [==============================] - 0s 3ms/step - loss: 3.8265 - mae: 1.4365</p> <p>Epoch 374/400 9/9 [==============================] - 0s 3ms/step - loss: 3.7951 - mae: 1.4227</p> <p>Epoch 375/400 9/9 [==============================] - 0s 3ms/step - loss: 3.8109 - mae: 1.4185</p> <p>Epoch 376/400 9/9 [==============================] - 0s 4ms/step - loss: 3.8171 - mae: 1.4315</p> <p>Epoch 377/400 9/9 [==============================] - 0s 3ms/step - loss: 3.8079 - mae: 1.4224</p> <p>Epoch 378/400 9/9 [==============================] - 0s 3ms/step - loss: 3.9359 - mae: 1.4343</p> <p>Epoch 379/400 9/9 [==============================] - 0s 3ms/step - loss: 3.9052 - mae: 1.4712</p> <p>Epoch 380/400 9/9 [==============================] - 0s 3ms/step - loss: 3.9682 - mae: 1.4686</p> <p>Epoch 381/400 9/9 [==============================] - 0s 4ms/step - loss: 3.8712 - mae: 1.4372</p> <p>Epoch 382/400 9/9 [==============================] - 0s 10ms/step - loss: 3.7983 - mae: 1.4193</p> <p>Epoch 383/400 9/9 [==============================] - 0s 16ms/step - loss: 3.7823 - mae: 1.4226</p> <p>Epoch 384/400 9/9 [==============================] - 0s 5ms/step - loss: 3.7303 - mae: 1.4140</p> <p>Epoch 385/400 9/9 [==============================] - 0s 4ms/step - loss: 3.7204 - mae: 1.4044</p> <p>Epoch 386/400 9/9 [==============================] - 0s 3ms/step - loss: 3.7432 - mae: 1.4152</p> <p>Epoch 387/400 9/9 [==============================] - 0s 3ms/step - loss: 3.7204 - mae: 1.4045</p> <p>Epoch 388/400 9/9 [==============================] - 0s 3ms/step - loss: 3.7163 - mae: 1.3980</p> <p>Epoch 389/400 9/9 [==============================] - 0s 3ms/step - loss: 3.6538 - mae: 1.3896</p> <p>Epoch 390/400 9/9 [==============================] - 0s 3ms/step - loss: 3.6510 - mae: 1.3874</p> <p>Epoch 391/400 9/9 [==============================] - 0s 3ms/step - loss: 3.9399 - mae: 1.4741</p> <p>Epoch 392/400 9/9 [==============================] - 0s 3ms/step - loss: 3.8155 - mae: 1.4265</p> <p>Epoch 393/400 9/9 [==============================] - 0s 3ms/step - loss: 3.6893 - mae: 1.3884</p> <p>Epoch 394/400 9/9 [==============================] - 0s 3ms/step - loss: 3.6876 - mae: 1.4176</p> <p>Epoch 395/400 9/9 [==============================] - 0s 3ms/step - loss: 3.6896 - mae: 1.3905</p> <p>Epoch 396/400 9/9 [==============================] - 0s 3ms/step - loss: 3.6180 - mae: 1.3828</p> <p>Epoch 397/400 9/9 [==============================] - 0s 3ms/step - loss: 3.5933 - mae: 1.3773</p> <p>Epoch 398/400 9/9 [==============================] - 0s 3ms/step - loss: 3.5719 - mae: 1.3750</p> <p>Epoch 399/400 9/9 [==============================] - 0s 3ms/step - loss: 3.5381 - mae: 1.3641</p> <p>Epoch 400/400 9/9 [==============================] - 0s 3ms/step - loss: 3.6085 - mae: 1.3688</p> <p><pre><code># Applique le mod\u00e8le sur la data du test\npred_test = model.predict(X_test)\npred_test.shape\n</code></pre> <pre><code># Evaluation du mod\u00e8le\nresult_test = model.evaluate(X_test, y_test, verbose=0)\nprint('MSE test', round(result_test[0],2))\nprint('MAE test', round(result_test[1],2))\n</code></pre></p> Output <p>MSE test 10.72</p> <p>MAE test 2.11</p>"},{"location":"projects/boston%20datasets/#support-vector-regression-svr","title":"Support Vector Regression SVR","text":"<pre><code># D\u00e9finir le mod\u00e8le\nmodel_SVR = svm.SVR()\n# Lancer l\u2019apprentissage\nmodel_SVR.fit(X_train,y_train)\n</code></pre>"},{"location":"projects/boston%20datasets/#regression-lineaire-lr","title":"R\u00e9gression Lin\u00e9aire LR","text":"<p><pre><code># D\u00e9finir le mod\u00e8le\nregression=LinearRegression()\n# Lancer l\u2019apprentissage\nregression.fit(X_train,y_train)\n</code></pre> <pre><code># Afficher les coefficients \nprint(regression.coef_)\n</code></pre></p> Output <p>[-1.00213533  0.69626862  0.27806485  0.7187384  -2.0223194   3.14523956 -0.17604788 -3.0819076   2.25140666 -1.76701378 -2.03775151  1.12956831 -3.61165842]</p> <pre><code># Afficher the intercept\nprint(regression.intercept_)\n</code></pre> Output <p>23.023938223938224</p> <pre><code># Sur quels param\u00e8tres le mod\u00e8le a entrainn\u00e9\nregression.get_params()\n</code></pre> Output <p>{\u2018copy_X\u2019: True,</p> <p>\u2018fit_intercept\u2019: True,</p> <p>\u2018n_jobs\u2019: None,</p> <p>\u2018normalize\u2019: \u2018deprecated\u2019,</p> <p>\u2018positive\u2019: False}</p>"},{"location":"projects/ozone%20datasets/","title":"Ozone Datasets","text":""},{"location":"projects/ozone%20datasets/#introduction","title":"Introduction","text":"<p>Le jeu de donn\u00e9es contient 1464 observations (journali\u00e8res, du 01/04/1995 au 30/09/2002, \u00e0 Rennes).</p>"},{"location":"projects/ozone%20datasets/#preparation-des-donnees","title":"Pr\u00e9paration des donn\u00e9es","text":"<pre><code># Importer les biblioth\u00e8ques\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tensorflow import keras\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dropout\nfrom sklearn.metrics import accuracy_score\nfrom tensorflow.keras.layers import Dense\nfrom sklearn.metrics import mean_squared_error\n</code></pre> <p>Lors de l\u2019importation des donn\u00e9es, j\u2019ai remplac\u00e9 la colonne index par la colonne des dates.</p> <p><pre><code># Importer le datasets + remplacer la colonne des indexes par celle des dates\nozone = pd.read_csv(\"ozone_complet.csv\", sep=\";\", index_col='Unnamed: 0')\n</code></pre> <pre><code># Lire les 5 premi\u00e8re lignes\nozone.head()\n</code></pre></p>"},{"location":"projects/ozone%20datasets/#etude-exploratoire-des-donnees","title":"\u00c9tude exploratoire des donn\u00e9es","text":"<p><pre><code># Afficher quelques informations du dataset\nozone.info()\n</code></pre> <pre><code># Afficher quelques statistiques du dataset\nozone.describe()\n</code></pre> <pre><code># Analyse les distributions des donn\u00e9es\nozone.hist(bins=50, figsize=(20,15))\nplt.show()\n</code></pre></p> Output <p></p> <pre><code># Analyse des corr\u00e9lations\nmatriceCorr = ozone.corr().round(1)\nsns.heatmap(data=matriceCorr, annot = True)\n</code></pre> Output <p></p> <pre><code># Afficher le nombre des valeurs manquantes dans chaque colonne\nozone.isnull().sum()\n</code></pre> <p>J\u2019ai ensuite remarqu\u00e9 qu\u2019il y avait des valeurs manquantes dans l\u2019ensemble de donn\u00e9es. Pour r\u00e9soudre ce probl\u00e8me, j\u2019ai remplac\u00e9 ces valeurs par la moyenne en utilisant \u00ab SimpleImputer \u00bb.</p> <p><pre><code># Remplir les valeurs manquentes par la mayenne\nfrom sklearn.impute import SimpleImputer\nimputer = SimpleImputer(strategy=\"median\")\n</code></pre> <pre><code># Lancer l'entrainement de Imputer\nimputer.fit(ozone)\n</code></pre> <pre><code># Appliquer le mod\u00e8le Imputer sur le dataset ozone (la sortie est de type array)\nozone_complet = imputer.transform(ozone)\n</code></pre> <pre><code># Transformer le dataset (sortie de Imputer de type array) en data frame\nozone_complet = pd.DataFrame(ozone_complet, columns=ozone.columns)\n</code></pre> <pre><code># V\u00e9rifier qu'il n'ya plus de valeurs manquantes\nozone_complet.isnull().sum()\n</code></pre></p>"},{"location":"projects/ozone%20datasets/#implementation-dun-modele-de-reseau-de-neurones","title":"Impl\u00e9mentation d\u2019un mod\u00e8le de r\u00e9seau de neurones","text":"<p><pre><code># Division de donn\u00e9es en donn\u00e9es d'entrainement, du test et de validation\nozone_complet = ozone_complet.sample(frac=1, axis=0)\ndata_train_valid = ozone_complet.sample(frac=0.85, axis=0)\ndata_test = ozone_complet.drop(data_train_valid.index)\ndata_train = data_train_valid.sample(frac=0.8, axis=0)\ndata_valid = data_train_valid.drop(data_train.index)\nx_train = data_train.drop('maxO3', axis=1)\ny_train = data_train['maxO3']\nprint('Dimensions de X train :', x_train.shape)\nprint('Dimensions de Y train :', y_train.shape)\nx_valid = data_valid.drop('maxO3', axis=1)\ny_valid = data_valid['maxO3']\nprint('Dimensions de X valid :', x_valid.shape)\nprint('Dimensions de Y valid :', y_valid.shape)\nx_test = data_test.drop('maxO3', axis=1)\ny_test = data_test['maxO3']\nprint('Dimensions de X test :', x_test.shape)\nprint('Dimensions de Y test :', y_test.shape)\n</code></pre> <pre><code># Normalisation des donn\u00e9es\nmin_x_train = x_train.min()\nmax_x_train = x_train.max()\nprint(\"Min de x_train :\", min_x_train)\nprint(\"Max de x_train :\", max_x_train)\nx_train_norm = (x_train-min_x_train)/(max_x_train-min_x_train)\nx_test_norm = (x_test-min_x_train)/(max_x_train-min_x_train)\nx_val_norm = (x_valid-min_x_train)/(max_x_train-min_x_train)\n</code></pre></p> <p>La structure du perceptron se compose d\u2019une couche d\u2019entr\u00e9e avec 22 neurones correspondant \u00e0 chacune des 22 features, de deux couches cach\u00e9es avec 5 neurones par chacune et d\u2019une couche de sortie avec un seul neurone qui donnera la valeur pr\u00e9dite de \u00ab maxO3 \u00bb. La fonction ReLu a \u00e9t\u00e9 choisie comme fonction d\u2019activation pour chacune des trois couches, mean square error comme loss function, et l\u2019algorithme Adam optimizer pour son adaptative learning rate and momentum.</p> <p><pre><code>## Impl\u00e9mentation de mod\u00e8le DNN\nmodel = Sequential()\nmodel.add(Dense(22, input_dim=np.shape(x_train)[1], activation = 'relu'))\nmodel.add(Dropout(.5))\nmodel.add(Dense(5, activation = 'relu'))\nmodel.add(Dropout(.5))\nmodel.add(Dense(5, activation = 'relu'))\nmodel.add(Dropout(.5))\nmodel.add(Dense(1, activation = 'relu'))\nmodel.compile(loss = 'mean_squared_error', optimizer = 'adam', metrics=['mean_squared_error'])\nmodel.summary()\n</code></pre> <pre><code>callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=100)\nhist = model.fit(x_train_norm, y_train, epochs = 1000, batch_size = 9999, callbacks = callback)\n</code></pre> <pre><code># Performance du mod\u00e8le sur les donn\u00e9es du test\npred_train= model.predict(x_train_norm)\nprint(np.sqrt(mean_squared_error(y_train,pred_train)))\npred= model.predict(x_test_norm)\nprint(np.sqrt(mean_squared_error(y_test,pred)))\n</code></pre></p>"},{"location":"projects/ozone%20datasets/#implementation-dune-regression-lineaire","title":"Impl\u00e9mentation d\u2019une R\u00e9gression Lin\u00e9aire","text":"<p>J\u2019ai \u00e9galement mis en \u0153uvre une r\u00e9gression lin\u00e9aire et j\u2019ai obtenu un score de 0,625 pour les donn\u00e9es de test et un score de 0,646 pour les donn\u00e9es de validation.</p> <p><pre><code>from sklearn.linear_model import LinearRegression\nlin_reg = LinearRegression()\nlin_reg.fit(x_train_norm, y_train)\n</code></pre> <pre><code># Performance du mod\u00e8le sur les donn\u00e9es du test\nscore_test_lin_reg = lin_reg.score(x_test_norm, y_test)\nprint(\"Test Accuracy Score\", score_test_lin_reg)\n</code></pre> <pre><code># Performance du mod\u00e8le sur les donn\u00e9es de validation\nscore_valid_lin_reg = lin_reg.score(x_val_norm, y_valid)\nprint(\"Test Accuracy Score\", score_valid_lin_reg)\n</code></pre></p>"},{"location":"projects/ozone%20datasets/#implementation-dun-svr","title":"Impl\u00e9mentation d\u2019un SVR","text":"<p>Un SVR a \u00e9galement \u00e9t\u00e9 mis en place et a donn\u00e9 un score de 0,489 pour les donn\u00e9es de test et un score de 0,519 pour les donn\u00e9es de validation.</p> <p><pre><code>from sklearn.svm import SVR\nsvr = SVR()\nsvr.fit(x_train_norm, y_train)\n</code></pre> <pre><code># Performance du mod\u00e8le sur les donn\u00e9es du test\nscore_test_svr = svr.score(x_test_norm, y_test)\nprint(\"Test Accuracy Score\", score_test_svr)\n</code></pre> <pre><code># Performance du mod\u00e8le sur les donn\u00e9es de validation\nscore_valid_svr = svr.score(x_val_norm, y_valid)\nprint(\"Test Accuracy Score\", score_valid_svr)\n</code></pre></p>"},{"location":"projects/ozone%20datasets/#conclusion","title":"Conclusion","text":"<p>Pour conclure, voici un tableau qui r\u00e9sume les diff\u00e9rents scores de tous les mod\u00e8les que j\u2019ai mis en place :</p> Mod\u00e8le Score (test dataset) Score (validation dataset) R\u00e9seau de neurones (DNN) mean square error : 36.827398008235775 R\u00e9gression Lin\u00e9aire 0.6250066102296177 0.6463044934834267 SVM (SVR) 0.4895962389393179 0.5192747605192083"},{"location":"projects/projet%20R/","title":"Profilage des chauffeurs","text":""},{"location":"projects/projet%20R/#membres-du-groupe","title":"Membres du groupe","text":"<p>Membres du groupe</p> <ul> <li>Abdellatif BELMADY</li> <li>Fatine BOUSSATTINE</li> <li>Hamza HAJJINI</li> <li>Hamza Dribine</li> <li>Mohamed Ait Hajjoub</li> </ul>"},{"location":"projects/projet%20R/#importer-les-packages","title":"Importer les packages","text":"<pre><code>library(sf)           # manipulation des donn\u00e9es spatiales\nlibrary(osmdata)      # extraction des donn\u00e9es OpenStreetMap\nlibrary(leaflet)      # visualisation interactive avec leaflet\nlibrary(mapsf)        # cartographie statistique\nlibrary(lubridate)    # manipulation des dates\nlibrary(tidyverse)    # m\u00e9ta-package d'Hadley Wickham\n</code></pre> <p>getwd()</p> <p><code>getwd()</code> est une fonction qui permet de r\u00e9cup\u00e9rer le chemin absolu du r\u00e9pertoire de travail actuel.</p> <pre><code>getwd()\n</code></pre> Output <p>[1] \u201cC:/Users/abdel/Documents\u201d</p>"},{"location":"projects/projet%20R/#importer-la-data","title":"Importer la data","text":"<p>Importer la data</p> <ul> <li> <p>Le premier fichier, <code>casabound.geojson</code>, est lu \u00e0 l\u2019aide de la fonction st_read() de la biblioth\u00e8que sf. Cette fonction est utilis\u00e9e pour lire des fichiers de donn\u00e9es spatiales tels que des fichiers shapefile, des fichiers GeoJSON, etc. Ici, il lit un fichier GeoJSON nomm\u00e9 \u201ccasabound.geojson\u201d et stocke les donn\u00e9es dans un objet nomm\u00e9 casaBound.</p> </li> <li> <p>Le deuxi\u00e8me fichier, <code>heetchmarchcrop.Rds</code>, est lu \u00e0 l\u2019aide de la fonction readRDS(). Cette fonction est utilis\u00e9e pour lire des fichiers de donn\u00e9es R sauvegard\u00e9s en utilisant la fonction saveRDS(). Ici, il lit un fichier RDS nomm\u00e9 heetchmarchcrop.Rds et stocke les donn\u00e9es dans un objet nomm\u00e9 heetchPoints.</p> </li> <li> <p>Le troisi\u00e8me fichier, <code>osmfeatures.Rds</code>, est \u00e9galement lu \u00e0 l\u2019aide de la fonction readRDS(). Comme le deuxi\u00e8me fichier, il s\u2019agit d\u2019un fichier RDS et est lu dans un objet nomm\u00e9 osmFeatures.</p> </li> </ul> <pre><code>casaBound &lt;- st_read(\"DATA/casabound.geojson\")\nheetchPoints &lt;- readRDS(\"DATA/heetchmarchcrop.Rds\")\nosmFeatures &lt;- readRDS(\"DATA/osmfeatures.Rds\")\n</code></pre> Output <p></p>"},{"location":"projects/projet%20R/#definir-la-problematique","title":"D\u00e9finir la probl\u00e9matique","text":"<p>Probl\u00e9matique</p> <p>A travers ce travail, nous cherchons \u00e0 identifier les conducteurs qui respectent les r\u00e8gles de conduite et \u00e0 \u00e9valuer leur s\u00e9curit\u00e9 sur la route, pour ce faire, nous nous concentrerons sur le calcul de la vitesse moyenne des conducteurs.</p>"},{"location":"projects/projet%20R/#resoudre-la-problematique","title":"R\u00e9soudre la probl\u00e9matique","text":"<p>Nombre de chauffeurs</p> <p>Ce code R <code>length(unique(heetchPoints$driver_id))</code> calcule le nombre de valeurs uniques dans la colonne driver_id de l\u2019objet heetchPoints.</p> <p>La fonction unique() est utilis\u00e9e pour extraire les valeurs uniques de la colonne driver_id. Ensuite, la fonction length() est utilis\u00e9e pour renvoyer le nombre d\u2019\u00e9l\u00e9ments dans le vecteur r\u00e9sultant.</p> Nombre de chauffeurs<pre><code>length(unique(heetchPoints$driver_id))\n</code></pre> Output <p>[1] 1309</p> <p>D\u00e9fenir la fonction qui calcul la moyenne des vitesses d\u2019un chauffeur sur un jour</p> <p>Le code R pr\u00e9sent\u00e9 ci-dessous est une fonction appel\u00e9e <code>my_function</code>, qui prend un argument id_driver. La fonction effectue les op\u00e9rations suivantes:</p> <ol> <li> <p>Initialise une variable i \u00e0 z\u00e9ro.</p> </li> <li> <p>Affiche la valeur de i.</p> </li> <li> <p>Filtre la table heetchPoints en fonction de la valeur id_driver.</p> </li> <li> <p>Trier la table driver en fonction de la colonne location_at_local_time.</p> </li> <li> <p>Effectue une projection de la table driver_tri dans une projection cartographique sp\u00e9cifique (crs = 26191).</p> </li> <li> <p>Calcule les distances entre tous les points dans la table driver_tri \u00e0 l\u2019aide de la fonction st_distance.</p> </li> <li> <p>Calcule la diff\u00e9rence de temps entre chaque deux points cons\u00e9cutifs dans la table driver_tri \u00e0 l\u2019aide de la fonction difftime.</p> </li> <li> <p>Filtre la table driver_tri pour conserver uniquement les points ayant une diff\u00e9rence de temps entre 0.016 et 0.025 heures.</p> </li> <li> <p>Calcule la vitesse entre chaque deux points successifs en divisant la distance sur le temps.</p> </li> <li> <p>Filtre la table driver_tri_2 pour ne conserver que les points ayant une vitesse entre 6 et 120 km/h.</p> </li> <li> <p>Retourne la moyenne des vitesses de la table driver_tri_3.</p> </li> </ol> D\u00e9fenir la fonction qui calcul la moyenne des vitesses d'un chauffeur sur un jour<pre><code>i = 0\nmy_function &lt;- function (id_driver){\ni=i+1\nprint(i)\ndriver &lt;- heetchPoints %&gt;% filter(driver_id == id_driver) # Prendre le premier jour + classer par location_at_local_time\n#  jour &lt;- driver %&gt;% \n#   filter(substr(driver$location_at_local_time, start = 9, stop = 10) == \"01\")\n#plot(driver$geometry, border = \"red\", lwd = 2)\n#  time_tri &lt;- order(jour$location_at_local_time)\n# jour_tri &lt;- jour[time_tri,]\n#Triage temporel de la table driver \ndriver_tri_index &lt;- order(driver$location_at_local_time)\ndriver_tri &lt;- driver[driver_tri_index,]\n# Projection des points\ndriver_tri &lt;- st_transform(x = driver_tri, crs = 26191)\n# Calculons les distances entres tous les points\nn &lt;- nrow(driver_tri)  n\nlist_distance &lt;- list()\nfor( i in 1:(n-1)){\ndistance &lt;- st_distance(x = driver_tri[i, ],\ny = driver_tri[i+1, ],\nby_element = TRUE)\nunits(distance) &lt;- \"km\"\nlist_distance &lt;- append (list_distance, list(distance))\n}\nlength (list_distance)\nlist_distance &lt;- c(0, list_distance)\ndriver_tri$distdiff &lt;- list_distance\nlist_time &lt;- list()\nfor( i in 1:(n-1)){\ndate_point1 &lt;- driver_tri$location_at_local_time[i]\ndate_point2 &lt;- driver_tri$location_at_local_time[i+1]\ndiff?rence &lt;- difftime(date_point2, date_point1, units = \"hours\")\nlist_time &lt;- append (list_time, list(diff?rence))\n}\nlist_time &lt;- c(0, list_time)\ndriver_tri$timediff &lt;- list_time\n#Calculons la liste des vitesse entre chaque deux points successifs en divisant la distance sur le temps\ndriver_tri_2 &lt;- driver_tri[driver_tri$timediff &gt; 0.016 &amp; driver_tri$timediff &lt; 0.025, ]\nclass(driver_tri_2$distdiff)\nclass(driver_tri_2$timediff)\ndriver_tri_2$distdiff &lt;- as.numeric(driver_tri_2$distdiff)\ndriver_tri_2$timediff &lt;- as.numeric(driver_tri_2$timediff)\ndriver_tri_2$vitesse &lt;- driver_tri_2$distdiff / driver_tri_2$timediff\ndriver_tri_3 &lt;- driver_tri_2[driver_tri_2$vitesse &gt;= 6 &amp; driver_tri_2$vitesse &lt;= 120, ]\nreturn (mean(driver_tri_3$vitesse))\n}\n</code></pre> <p>Calculons la moyenne des vitesse de tous les chauffeurs</p> <p>Le code ci-dessous commence par cr\u00e9er un objet de type data.frame appel\u00e9 vitesse_table \u00e0 l\u2019aide de la fonction data.frame().</p> <p>Ensuite, la boucle for est utilis\u00e9e pour it\u00e9rer sur une liste de trois valeurs de l\u2019ID de conducteur driver_id comprises entre 10 et 12 inclusivement.</p> <p>\u00c0 chaque it\u00e9ration, le code cr\u00e9e une liste driver_list avec deux \u00e9l\u00e9ments : le premier est l\u2019ID du conducteur et le deuxi\u00e8me est le r\u00e9sultat de la fonction my_function() avec l\u2019ID du conducteur en argument.</p> <p>Enfin, la fonction rbind() est utilis\u00e9e pour ajouter la liste driver_list en tant que nouvelle ligne \u00e0 la fin du data.frame vitesse_table.</p> <p>Ainsi, \u00e0 la fin de la boucle for, vitesse_table contiendra une liste de conducteurs avec leurs ID et la valeur de la vitesse obtenue \u00e0 l\u2019aide de la fonction my_function().</p> Calculons la moyenne des vitesse de tous les chauffeurs<pre><code>vitesse_table &lt;- data.frame()\nfor (driver_id in unique(heetchPoints$driver_id)[10:12]){\ndriver_list &lt;- list(driver_id, my_function (driver_id))\nvitesse_table &lt;- rbind(vitesse_table, driver_list)\n}\n</code></pre>"},{"location":"projects/spam%20datasets/","title":"Spam Datasets","text":""},{"location":"projects/spam%20datasets/#introduction","title":"Introduction","text":"<p>Membres du groupe</p> <p>L\u2019objectif de ce projet \u00e9tait d\u2019entra\u00eener un r\u00e9seau neuronal \u00e0 classer les courriels comme \u00ab spam \u00bb ou \u00ab non spam \u00bb. Ceci a \u00e9t\u00e9 fait sur le jeu de donn\u00e9es Spambase     fourni par le r\u00e9f\u00e9rentiel d\u2019apprentissage automatique de l\u2019UCI, qui contient 57 features repr\u00e9sentant la fr\u00e9quence des mots dans 4601 emails.</p> <p>Pour notre label (Spam) ; \u00ab spam \u00bb a \u00e9t\u00e9 cod\u00e9 comme 1 pour la classe positive et \u00ab non spam \u00bb a \u00e9t\u00e9 a \u00e9t\u00e9 cod\u00e9 comme 0 pour la classe n\u00e9gative.</p>"},{"location":"projects/spam%20datasets/#preparation-des-donnees","title":"Pr\u00e9paration des donn\u00e9es","text":"<p><pre><code># Importer les biblioth\u00e8ques\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tensorflow import keras\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dropout\nfrom sklearn.metrics import accuracy_score\nfrom tensorflow.keras.layers import Dense\n</code></pre> <pre><code># Importer le datasets \nspam = pd.read_csv(\"spam.csv\")\n</code></pre> <pre><code># Lire les 5 premi\u00e8re lignes\nspam.head(5)\n</code></pre></p>"},{"location":"projects/spam%20datasets/#etude-exploratoire-des-donnees","title":"\u00c9tude exploratoire des donn\u00e9es","text":"<pre><code># Afficher quelques informations du dataset\nspam.info()\n</code></pre> <p>D\u2019apr\u00e8s le r\u00e9sultat de la m\u00e9thode \u00ab info() \u00bb, il appara\u00eet que tous les features sont de type float ce qui facilitera notre \u00e9tude ult\u00e9rieure (pas besoin de faire une feature engineering).</p> <pre><code># Afficher quelques statistiques du dataset\nspam.describe()\n</code></pre> <p>J\u2019ai \u00e9galement fait une analyse des distributions des donn\u00e9es pour avoir une id\u00e9e sur les lois suivies par les diff\u00e9rents features, ainsi veuillez trouver ci-dessous le r\u00e9sultat obtenu et qui montre que la plupart des features ne suivent pas une distribution gaussienne.</p> <pre><code># Afficher quelques statistiques du dataset\nspam.describe()\n</code></pre> Output <p></p> <pre><code># Analyse des corr\u00e9lations\nmatriceCorr = spam.corr().round(1)\nsns.heatmap(data=matriceCorr, annot = True)\n</code></pre> Output <p></p>"},{"location":"projects/spam%20datasets/#implementation-dun-modele-de-reseau-de-neurones","title":"Impl\u00e9mentation d\u2019un mod\u00e8le de r\u00e9seau de neurones","text":"<p><pre><code># Division de donn\u00e9es en donn\u00e9es d'entrainement, du test et de validation\nspam = spam.sample(frac=1, axis=0)\ndata_train_valid = spam.sample(frac=0.85, axis=0)\ndata_test = spam.drop(data_train_valid.index)\ndata_train = data_train_valid.sample(frac=0.8, axis=0)\ndata_valid = data_train_valid.drop(data_train.index)\nx_train = data_train.drop('spam', axis=1)\ny_train = data_train['spam']\nprint('Dimensions de X train :', x_train.shape)\nprint('Dimensions de Y train :', y_train.shape)\nx_valid = data_valid.drop('spam', axis=1)\ny_valid = data_valid['spam']\nprint('Dimensions de X valid :', x_valid.shape)\nprint('Dimensions de Y valid :', y_valid.shape)\nx_test = data_test.drop('spam', axis=1)\ny_test = data_test['spam']\nprint('Dimensions de X test :', x_test.shape)\nprint('Dimensions de Y test :', y_test.shape)\n</code></pre> <pre><code># Normalisation des donn\u00e9es\nmin_x_train = x_train.min()\nmax_x_train = x_train.max()\nprint(\"Min de x_train :\", min_x_train)\nprint(\"Max de x_train :\", max_x_train)\nx_train_norm = (x_train-min_x_train)/(max_x_train-min_x_train)\nx_test_norm = (x_test-min_x_train)/(max_x_train-min_x_train)\nx_val_norm = (x_valid-min_x_train)/(max_x_train-min_x_train)\n</code></pre></p> <p>La structure du perceptron se compose d\u2019une couche d\u2019entr\u00e9e avec 57 neurones correspondant \u00e0 chacune des 57 features, d\u2019une couche cach\u00e9e avec 12 neurones et d\u2019une couche de sortie avec 2 neurones : le premier peut \u00eatre interpr\u00e9t\u00e9 comme la probabilit\u00e9 qu\u2019un email soit \u00ab non-spam \u00bb et le second comme la probabilit\u00e9 de \u201cspam\u201d. Le neurone de sortie ayant la probabilit\u00e9 la plus \u00e9lev\u00e9e d\u00e9termine la classification d\u2019un email.</p> <p>La fonction sigmo\u00efde a \u00e9t\u00e9 choisie comme fonction d\u2019activation pour chacune des trois couches, l\u2019entropie crois\u00e9e binaire comme loss function, et l\u2019algorithme Adam optimizer pour son adaptative learning rate and momentum.</p> <p></p> <p><pre><code>## Impl\u00e9mentation de mod\u00e8le DNN\nmodel = Sequential()\nmodel.add(Dense(57, input_dim=np.shape(x_train)[1], activation = 'sigmoid'))\nmodel.add(Dropout(.5))\nmodel.add(Dense(12, activation = 'sigmoid'))\nmodel.add(Dropout(.5))\nmodel.add(Dense(1, activation = 'sigmoid'))\nmodel.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])\nmodel.summary()\n</code></pre> <pre><code>callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=1000)\nhist = model.fit(x_train_norm, y_train, epochs = 10100, batch_size = 99999, callbacks = callback)\n</code></pre> <pre><code># Performance du mod\u00e8le sur les donn\u00e9es du test\npreds = model.predict(x_test_norm)\npreds = [1 if x[0] &gt; 0.5 else 0 for x in preds]\nscore_test_dnn = accuracy_score(y_test, preds)\nprint(score_test_dnn)\n</code></pre> <pre><code># Performance du mod\u00e8le sur les donn\u00e9es de validation\npreds = model.predict(x_val_norm)\npreds = [1 if x[0] &gt; 0.5 else 0 for x in preds]\nscore_valid_dnn = accuracy_score(y_valid, preds)\nprint(score_valid_dnn)\n</code></pre> <pre><code>figure = plt.gcf()\nfigure.set_size_inches((20, 10))\nplt.title('Analyse des erreurs')\nplt.xlabel('Epoch')\nplt.ylabel('Entropie crois\u00e9e')\nplt.plot(range(1, len(hist.history['loss']) + 1), hist.history['loss'])\nplt.legend(['Entropie crois\u00e9e train'])\nplt.show()\n</code></pre></p> Output <p></p> <pre><code>figure = plt.gcf()\nfigure.set_size_inches((20, 10))\nplt.title('Analyse des erreurs')\nplt.xlabel('Epoch')\nplt.ylabel('Pr\u00e9cision')\nplt.plot(range(1, len(hist.history['accuracy']) + 1), hist.history['accuracy'])\nplt.legend([\"Pr\u00e9cision d'apprentissage\"])\nplt.show()\n</code></pre> Output <p></p> <p>Ce mod\u00e8le de r\u00e9seau neuronal a donn\u00e9 un score de 0,924 pour les donn\u00e9es de test et un score de 0,937 pour les donn\u00e9es de validation, ce qui est tr\u00e8s satisfaisant.</p>"},{"location":"projects/spam%20datasets/#implementation-dune-regression-logistique","title":"Impl\u00e9mentation d\u2019une R\u00e9gression Logistique","text":"<p><pre><code>from sklearn.linear_model import LogisticRegression\nlog_reg = LogisticRegression()\nlog_reg.fit(x_train_norm, y_train)\n</code></pre> <pre><code># Performance du mod\u00e8le sur les donn\u00e9es du test\nscore_test_log_reg = log_reg.score(x_test_norm, y_test)\nprint(\"Test Accuracy Score\", score_test_log_reg)\n</code></pre> <pre><code># Performance du mod\u00e8le sur les donn\u00e9es de validation\nscore_valid_log_reg = log_reg.score(x_val_norm, y_valid)\nprint(\"Test Accuracy Score\", score_valid_log_reg)\n</code></pre></p> <p>J\u2019ai \u00e9galement mis en \u0153uvre une r\u00e9gression logistique et j\u2019ai obtenu un score de 0,876 pour les donn\u00e9es de test et un score de 0,895 pour les donn\u00e9es de validation.</p>"},{"location":"projects/spam%20datasets/#implementation-dun-svm","title":"Impl\u00e9mentation d\u2019un SVM","text":"<p><pre><code>from sklearn import svm\nsvm = svm.SVC()\nsvm.fit(x_train_norm, y_train)\n</code></pre> <pre><code># Performance du mod\u00e8le sur les donn\u00e9es du test\nscore_test_svc = svm.score(x_test_norm, y_test)\nprint(\"Test Accuracy Score\", score_test_svc)\n</code></pre> <pre><code># Performance du mod\u00e8le sur les donn\u00e9es de validation\nscore_valid_svc = svm.score(x_val_norm, y_valid)\nprint(\"Test Accuracy Score\", score_valid_svc)\n</code></pre></p> <p>Un SVC a \u00e9galement \u00e9t\u00e9 mis en place et a donn\u00e9 un score de 0,931 pour les donn\u00e9es de test et un score de 0,932 pour les donn\u00e9es de validation.</p>"},{"location":"projects/spam%20datasets/#implementation-dun-random-forest","title":"Impl\u00e9mentation d\u2019un Random Forest","text":"<p><pre><code>from sklearn.ensemble import RandomForestClassifier\nrdf = RandomForestClassifier(max_depth=2, random_state=0)\nrdf.fit(x_train_norm, y_train)\n</code></pre> <pre><code># Performance du mod\u00e8le sur les donn\u00e9es du test\nscore_test_rdf = rdf.score(x_test_norm, y_test)\nprint(\"Test Accuracy Score\", score_test_rdf)\n</code></pre> <pre><code># Performance du mod\u00e8le sur les donn\u00e9es de validation\nscore_valid_rdf = rdf.score(x_val_norm, y_valid)\nprint(\"Test Accuracy Score\", score_valid_rdf)\n</code></pre></p> <p>Pour avoir une id\u00e9e de tous les mod\u00e8les de machine learning, j\u2019ai mis en \u0153uvre un Random Forest qui a donn\u00e9 un score de 0,884 pour les donn\u00e9es de test et un score de 0,904 pour les donn\u00e9es de validation.</p>"},{"location":"projects/spam%20datasets/#conclusion","title":"Conclusion","text":"<p>Conclusion</p> <p>Pour conclure, voici un tableau qui r\u00e9sume les diff\u00e9rents scores de tous les mod\u00e8les que j\u2019ai mis en place :</p> Mod\u00e8le Score (test dataset) Score (validation dataset) R\u00e9seau de neurones (DNN) 0.9246376811594202 0.9246376811594202 R\u00e9gression Logistique 0.8768115942028986 0.8951406649616368 SVM (SVC) 0.9318840579710145 0.9322250639386189 Random Forest 0.8840579710144928 0.9040920716112532"},{"location":"projects/tp_gnn/","title":"TP: R\u00e9seaux de neurones graphiques","text":"<p>Dans ce TP, on va appliquer les concepts d\u2019extraction de caract\u00e9ristiques et de node embedding sur un dataset classique Karate Club Network.</p>"},{"location":"projects/tp_gnn/#representation-graphique-avec-networkx","title":"Repr\u00e9sentation graphique avec networkx","text":"<pre><code>import networkx as nx\n</code></pre>"},{"location":"projects/tp_gnn/#zacharys-karate-club-network","title":"Zachary\u2019s karate club network","text":"<p>Zachary\u2019s karate club est un graphe d\u00e9crivant un r\u00e9seau social de 34 membres d\u2019un club de karat\u00e9. Les liens repr\u00e9sentent les interactions entre les membres en dehors du club.</p> <pre><code>G = nx.karate_club_graph()\nnx.draw(G, with_labels = True)\n</code></pre> Output <p></p>"},{"location":"projects/tp_gnn/#question-1-quel-est-le-degre-moyen-du-karate-club","title":"Question 1 : quel est le degr\u00e9 moyen du karat\u00e9 club ?","text":"<pre><code>def average_degree(num_edges, num_nodes):\n# Cette fonction retourne le degr\u00e9 moyen du graphe.\navg_degree = 0\navg_degree = round(2 * num_edges/num_nodes)\nreturn avg_degree\nnum_edges = G.number_of_edges()\nnum_nodes = G.number_of_nodes()\nprint(\"Nombre d'ar\u00eates :\", num_edges, \"Nombre de noeuds :\", num_nodes)\navg_degree = average_degree(num_edges, num_nodes)\nprint(\"Le degr\u00e9 moyen du karat\u00e9 club est : {}\".format(avg_degree))\n</code></pre> Output <p>Nombre d\u2019ar\u00eates : 78 Nombre de noeuds : 34 Le degr\u00e9 moyen du karat\u00e9 club est : 5</p>"},{"location":"projects/tp_gnn/#question-2-quel-est-le-coefficient-de-clustering-moyen-du-karate-club","title":"Question 2 : quel est le coefficient de clustering moyen du karat\u00e9 club ?","text":"<pre><code>def average_clust_coef(G):\n# Cette fonction retourne le coefficient de clustring moyen du caract\u00e9 club \n####### Code ########\navg_cluster_coef = nx.algorithms.cluster.average_clustering(G)\n#####################\nreturn avg_cluster_coef\navg_cluster_coef = average_clust_coef(G)\nprint(\"Le coefficient de clustering moyen du karat\u00e9 club est : {}\".format(avg_cluster_coef))\n</code></pre> Output <p>Le coefficient de clustering moyen du karat\u00e9 club est : 0.5706384782076823</p>"},{"location":"projects/tp_gnn/#question-3-quelle-est-la-centralite-de-proximite-du-noeud-numero-5","title":"Question 3 : quelle est la centralit\u00e9 de proximit\u00e9 du noeud num\u00e9ro 5 ?","text":"Output <p>La centralit\u00e9 de proximit\u00e9 est d\u00e9finie par :  \\(c(v) = \\frac{1}{\\sum_{u \\neq v}\\text{le chemin le plus court entre } u \\text{ and } v}\\)</p> <pre><code>def closeness_centrality(G, node = 5):\n# Cette fonction retourne la centralit\u00e9 de proximit\u00e9 d'un noeud donn\u00e9\n###### Code #######\ndegree_centrality = nx.algorithms.centrality.closeness_centrality(G)\ncloseness = degree_centrality[node]\n###################\nreturn closeness\nnode = 5\ncloseness = closeness_centrality(G, node=node)\nprint(\"La centralit\u00e9 de proximit\u00e9 du noeud num\u00e9ro 5 est : {}\".format(closeness))\n</code></pre> Output <p>La centralit\u00e9 de proximit\u00e9 du noeud num\u00e9ro 5 est : 0.38372093023255816</p>"},{"location":"projects/tp_gnn/#question-4-quelle-est-la-centralite-intermediaire-associee-a-un-noeud-donne-du-karacte-club","title":"Question 4 : quelle est la centralit\u00e9 interm\u00e9diaire associ\u00e9e \u00e0 un noeud donn\u00e9 du karact\u00e9 club ?","text":"<pre><code>def betweeness_centrality(G, node = 5):\n# Cette fonction retourne la centralit\u00e9 interm\u00e9diaire d'un noeud donn\u00e9\n####### Code ########\nbtw_centrality = nx.algorithms.centrality.betweenness_centrality(G)\nbetweeness = btw_centrality[node]\n#####################\nreturn betweeness\nnode = 5\nbetweeness = betweeness_centrality(G, node=node)\nprint(\"La centralit\u00e9 interm\u00e9diaire du noeud num\u00e9ro 5 est : {}\".format(closeness))\n</code></pre> Output <p>La centralit\u00e9 interm\u00e9diaire du noeud num\u00e9ro 5 est : 0.38372093023255816</p>"},{"location":"projects/tp_gnn/#2-graphe-en-tenseur","title":"2 Graphe en Tenseur","text":"<p>Nous allons transformer le graphe  G  en tenseur Pytorch.</p> <pre><code>import torch\n</code></pre>"},{"location":"projects/tp_gnn/#question-5-liste-des-aretes-du-karate-club-en-format-torchlongtensor-quel-le-nombe-daretes-positives","title":"Question 5 : Liste des ar\u00eates du Karat\u00e9 club en format torch.LongTensor. Quel le nombe d\u2019ar\u00eates positives ?","text":"<pre><code>def graph_to_edge_list(G):\n# Cette fonction retourne la liste des ar\u00eates d'un graphe sous forme\n# de couplet compos\u00e9 de deux noeuds.\nedge_list = []\nlst1 = []\nlst2 = []\n############# Code ############\nedge_list = list(G.edges())\n#########################################\nreturn edge_list\ndef edge_list_to_tensor(edge_list):\n# Cette fonction transforme un liste d'ar\u00eates en Tenseur Pytorch\n# de dimension [2 x len(edge_list)]\nedge_index = torch.tensor([])\n############# Code ############\nedge_index = torch.tensor(edge_list, dtype = torch.long).permute((1,0))\n#########################################\nreturn edge_index\npos_edge_list = graph_to_edge_list(G)\n# print(pos_edge_list)\npos_edge_index = edge_list_to_tensor(pos_edge_list)\nprint(\"La dimension de pos_edge_index est : {}\".format(pos_edge_index.shape))\nprint(\"La somme des valeurs de pos_edge_index : {}\".format(torch.sum(pos_edge_index)))\n</code></pre> Output <p>La dimension de pos_edge_index est : torch.Size([2, 78]) La somme des valeurs de pos_edge_index : 2535</p>"},{"location":"projects/tp_gnn/#question-6-ecrire-une-fonction-qui-retourne-les-aretes-negatives","title":"Question 6 : Ecrire une fonction qui retourne les ar\u00eates n\u00e9gatives.","text":"<pre><code>import random\ndef sample_negative_edges(G, num_neg_samples):\n# Cette fonction retourne la liste des ar\u00eates n\u00e9gatives. \nneg_edge_list = []\npos_set = set(G.edges())\nvisited_set = set()\n############# Code ############\nfor n_i in G.nodes():\nfor n_j in G.nodes():\nif n_i == n_j or (n_i,n_j) in pos_set or (n_j,n_i) in pos_set or (n_i,n_j) in visited_set or (n_j, n_i) is visited_set:\ncontinue\nneg_edge_list.append((n_i,n_j))\nvisited_set.add((n_i,n_j))\nvisited_set.add((n_j,n_i))\nif len(neg_edge_list) == num_neg_samples:\nbreak\n###############################\nreturn neg_edge_list\n# Echantillon de 78 ar\u00eates n\u00e9gatives\nneg_edge_list = sample_negative_edges(G, len(pos_edge_list))\n# Convertir la liste des ar\u00eates n\u00e9gatives en tenseur\nneg_edge_index = edge_list_to_tensor(neg_edge_list)\nprint(\"Le tenseur neg_edge_index est de dimension {}\".format(neg_edge_index.shape))\n# Quelles sont les ar\u00eates n\u00e9gatives parmi les ar\u00eates suivantes ?\nedge_1 = (7, 1)\nedge_2 = (1, 33)\nedge_3 = (33, 22)\nedge_4 = (0, 4)\nedge_5 = (4, 2)\n</code></pre> Output <p>Le tenseur neg_edge_index est de dimension torch.Size([2, 483])</p> <pre><code>a = nx.negative_edge_cycle(G)\nprint(a)\n</code></pre> Output <p>False</p>"},{"location":"projects/tp_gnn/#node-embeddings","title":"Node Embeddings","text":"<pre><code>import torch\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\n</code></pre> <p>On va utiliser ici le module nn.Embedding de PyTorch.</p> <pre><code># Initialisation de la couche d'embeddings\n# avec, par exemple, 4 objets de dimension 8 chacun\nemb_sample = nn.Embedding(num_embeddings=4, embedding_dim=8)\nprint('Embedding layer: {}'.format(emb_sample))\n</code></pre> Output <p>Embedding layer: Embedding(4, 8)</p> <p>On peut s\u00e9lectionner l\u2019embedding d\u2019un objet en utilisant l\u2019indice correspondant.</p> <pre><code># S\u00e9lectionner un seul embedding\nid = torch.LongTensor([1])\nprint(emb_sample(id))\n# S\u00e9lectionner plusieurs embeddings\nids = torch.LongTensor([1, 3])\nprint(emb_sample(ids))\n# Obtenir la dimension de la mtrice de poids de l'embedding\nshape = emb_sample.weight.data.shape\nprint(shape)\n# Affecter de nouvelles valeurs \u00e0 la matrice de poids (ici des 1)\nemb_sample.weight.data = torch.ones(shape)\n# V\u00e9rifier la nouvelle affectation\nids = torch.LongTensor([0, 3])\nprint(emb_sample(ids))\n</code></pre> Output <p>tensor([[-0.6316,  0.5919,  0.3717, -0.0679, -1.0768,  0.7879, -0.3337,  1.6544]],        grad_fn=) tensor([[-0.6316,  0.5919,  0.3717, -0.0679, -1.0768,  0.7879, -0.3337,  1.6544],         [ 1.4465,  0.5489, -0.5271, -1.6461,  0.5401, -0.8992,  0.6385,  0.8055]],        grad_fn=) torch.Size([4, 8]) tensor([[1., 1., 1., 1., 1., 1., 1., 1.],         [1., 1., 1., 1., 1., 1., 1., 1.]], grad_fn=) <p>On va appliquer \u00e0 cela au jeu de donn\u00e9es Zachary\u2019s karat\u00e9 club.</p> <p>On veut associer un vecteur de dimension 16 \u00e0 chaque noeud du graphe. on veut initialiser la matrice avec une distribution uniforme dans  [0,1]  en utilisant torch.rand.</p> <pre><code>torch.manual_seed(1)\ndef create_node_emb(num_node=34, embedding_dim=16):\n# Ecrire une fonction qui impl\u00e9mente la matrice d'embeddings pour les noeuds.\n# La fonction doit retourner un embedding de format torch.nn initalis\u00e9 selon\n# une loi uniforme dans [0,1].\nemb = None\n############# Code ############\nemb = nn.Embedding(num_embeddings=num_nodes, embedding_dim=embedding_dim)\nshape = emb.weight.data.shape\nemb.weight.data = torch.rand(shape)\n###############################\nreturn emb\nemb = create_node_emb()\nids = torch.LongTensor([0, 3])\nprint(\"Embedding: {}\".format(emb))\nprint(emb(ids))\n</code></pre> Output <p>Embedding: Embedding(34, 16) tensor([[0.2114, 0.7335, 0.1433, 0.9647, 0.2933, 0.7951, 0.5170, 0.2801, 0.8339,          0.1185, 0.2355, 0.5599, 0.8966, 0.2858, 0.1955, 0.1808],         [0.7486, 0.6546, 0.3843, 0.9820, 0.6012, 0.3710, 0.4929, 0.9915, 0.8358,          0.4629, 0.9902, 0.7196, 0.2338, 0.0450, 0.7906, 0.9689]],     grad_fn=)"},{"location":"projects/tp_gnn/#visualisation-des-embeddings","title":"Visualisation des embeddings","text":"<p>Nous allons projet les embeddings inialis\u00e9s ci-dessous en deux dimensions afin de les visualiser.</p> <pre><code>def visualize_emb(emb):\nX = emb.weight.data.numpy()\npca = PCA(n_components=2)\ncomponents = pca.fit_transform(X)\nplt.figure(figsize=(6, 6))\nclub1_x = []\nclub1_y = []\nclub2_x = []\nclub2_y = []\nfor node in G.nodes(data=True):\nif node[1]['club'] == 'Mr. Hi':\nclub1_x.append(components[node[0]][0])\nclub1_y.append(components[node[0]][1])\nelse:\nclub2_x.append(components[node[0]][0])\nclub2_y.append(components[node[0]][1])\nplt.scatter(club1_x, club1_y, color=\"red\", label=\"Mr. Hi\")\nplt.scatter(club2_x, club2_y, color=\"blue\", label=\"Officer\")\nplt.legend()\nplt.show()\n# Visualize the initial random embeddding\nvisualize_emb(emb)\n</code></pre> Output <p></p>"},{"location":"projects/tp_gnn/#question-7-calcul-des-embeddings-par-descente-du-gradient","title":"Question 7 : calcul des embeddings par descente du gradient.","text":"<pre><code>from torch.optim import SGD\ndef accuracy(pred, label):\n# Cette fonction prend les pr\u00e9dictions r\u00e9alis\u00e9es, \n# les arrondit et calcul la pr\u00e9cision du mod\u00e8le.\naccu = 0.0\naccu = torch.sum(torch.round(pred) == label) / pred.shape[0]\nreturn accu\ndef train(emb, loss_fn, sigmoid, train_label, train_edge):\n# Cette fonction entra\u00eene les embeddings par SGD.\n# A faire :\n# 1 : r\u00e9cup\u00e9rer les embeddings respectifs des noeuds \u00e0 partir de train_edge\n# 2 : Calculer le produit scalaire des embeddings de chaque paire de noeuds\n# 3 : Appliquer une fonction sigmo\u00efde au produit scalaire calcul\u00e9\n# 4 : Appliquer la loss_fn au r\u00e9sultat de la fonction sigmo\u00efde\n# 5 : Imprimer la fonction loss et la pr\u00e9cision \u00e0 chaque epoch. \n# (as a sanity check, the loss should decrease during training)\nepochs = 500\nlearning_rate = 0.1\noptimizer = SGD(emb.parameters(), lr=learning_rate, momentum=0.9)\nfor i in range(epochs):\n############# Code ###########\noptimizer.zero_grad()  # Clear gradients.\nproduct = torch.sum(torch.mul(emb(train_edge[0]),emb(train_edge[1])), axis = 1)\npred = torch.sigmoid(product)\nloss = loss_fn(pred, train_label)\nloss.backward()  # Derive gradients.\noptimizer.step()  # Update parameters based on gradients.\nwith torch.no_grad():\naccu = accuracy(pred, train_label)\nif i % 100 == 0:\nvisualize_emb(emb)\nprint(\"loss: {}, accuracy: {}\".format(loss.item(), accu))\n##############################\nloss_fn = nn.BCELoss()\nsigmoid = nn.Sigmoid()\n# G\u00e9n\u00e9rer les labels positifs et n\u00e9gatifs\npos_label = torch.ones(pos_edge_index.shape[1], )\nneg_label = torch.zeros(neg_edge_index.shape[1], )\n# Concat\u00e9ner les labels positifs and n\u00e9gatifs dans le m\u00eame tenseur\ntrain_label = torch.cat([pos_label, neg_label], dim=0)\ntrain_edge = torch.cat([pos_edge_index, neg_edge_index], dim=1)\ntrain(emb, loss_fn, sigmoid, train_label, train_edge)\n</code></pre> Output <p>loss: 3.468411684036255, accuracy: 0.13903743028640747 loss: 3.43456768989563, accuracy: 0.13903743028640747 loss: 3.371028184890747, accuracy: 0.13903743028640747 loss: 3.282146453857422, accuracy: 0.13903743028640747 loss: 3.1723263263702393, accuracy: 0.13903743028640747 loss: 3.045901298522949, accuracy: 0.13903743028640747 loss: 2.907038450241089, accuracy: 0.13903743028640747 loss: 2.7596638202667236, accuracy: 0.13903743028640747 loss: 2.6074018478393555, accuracy: 0.13903743028640747 loss: 2.4535279273986816, accuracy: 0.13903743028640747 loss: 2.3009305000305176, accuracy: 0.13903743028640747 loss: 2.152082920074463, accuracy: 0.13903743028640747 loss: 2.009026050567627, accuracy: 0.13903743028640747 loss: 1.8733632564544678, accuracy: 0.13903743028640747 loss: 1.7462693452835083, accuracy: 0.13903743028640747 loss: 1.6285123825073242, accuracy: 0.13903743028640747 loss: 1.5204927921295166, accuracy: 0.14260248839855194 loss: 1.4222900867462158, accuracy: 0.14438502490520477 loss: 1.3337185382843018, accuracy: 0.14973261952400208 loss: 1.254386305809021, accuracy: 0.15508021414279938 loss: 1.183752417564392, accuracy: 0.16399286687374115 loss: 1.1211791038513184, accuracy: 0.17290551960468292 loss: 1.0659770965576172, accuracy: 0.18538324534893036 loss: 1.0174411535263062, accuracy: 0.20677362382411957 loss: 0.9748789668083191, accuracy: 0.22281639277935028 loss: 0.937629222869873, accuracy: 0.2442067712545395 loss: 0.9050756096839905, accuracy: 0.2549019753932953 loss: 0.8766528964042664, accuracy: 0.27807486057281494 loss: 0.8518502116203308, accuracy: 0.3030303120613098 loss: 0.8302105069160461, accuracy: 0.3333333432674408 loss: 0.8113287091255188, accuracy: 0.35650622844696045 loss: 0.7948473691940308, accuracy: 0.38324421644210815 loss: 0.7804537415504456, accuracy: 0.40463459491729736 loss: 0.7678741216659546, accuracy: 0.4153297543525696 loss: 0.7568702101707458, accuracy: 0.4367201328277588 loss: 0.7472350597381592, accuracy: 0.4474153220653534 loss: 0.7387885451316833, accuracy: 0.45989304780960083 loss: 0.731374979019165, accuracy: 0.4777183532714844 loss: 0.7248587012290955, accuracy: 0.48663100600242615 loss: 0.7191224098205566, accuracy: 0.5080214142799377 loss: 0.714064359664917, accuracy: 0.5222816467285156 loss: 0.7095963358879089, accuracy: 0.5204991102218628 loss: 0.7056415677070618, accuracy: 0.531194269657135 loss: 0.7021337151527405, accuracy: 0.5347593426704407 loss: 0.6990148425102234, accuracy: 0.5436720252037048 loss: 0.6962348818778992, accuracy: 0.5472370982170105 loss: 0.6937502026557922, accuracy: 0.5490196347236633 loss: 0.6915227174758911, accuracy: 0.554367184638977 loss: 0.689519464969635, accuracy: 0.5561497211456299 loss: 0.6877117156982422, accuracy: 0.5561497211456299 loss: 0.686074435710907, accuracy: 0.565062403678894 loss: 0.6845855712890625, accuracy: 0.5704099535942078 loss: 0.683226466178894, accuracy: 0.5739750266075134 loss: 0.6819803714752197, accuracy: 0.5757575631141663 loss: 0.68083256483078, accuracy: 0.5739750266075134 loss: 0.6797709465026855, accuracy: 0.5739750266075134 loss: 0.6787840723991394, accuracy: 0.5757575631141663 loss: 0.6778624653816223, accuracy: 0.5793226361274719 loss: 0.6769978404045105, accuracy: 0.5793226361274719 loss: 0.6761825680732727, accuracy: 0.5828877091407776 loss: 0.6754106283187866, accuracy: 0.5846702456474304 loss: 0.6746761202812195, accuracy: 0.5846702456474304 loss: 0.6739742159843445, accuracy: 0.5882353186607361 loss: 0.6733008027076721, accuracy: 0.5900177955627441 loss: 0.672652006149292, accuracy: 0.591800332069397 loss: 0.6720245480537415, accuracy: 0.5900177955627441 loss: 0.6714155673980713, accuracy: 0.5900177955627441 loss: 0.6708226799964905, accuracy: 0.5900177955627441 loss: 0.670243501663208, accuracy: 0.5900177955627441 loss: 0.6696761846542358, accuracy: 0.5935828685760498 loss: 0.6691192388534546, accuracy: 0.591800332069397 loss: 0.6685709357261658, accuracy: 0.5900177955627441 loss: 0.6680300831794739, accuracy: 0.5900177955627441 loss: 0.6674955487251282, accuracy: 0.5900177955627441 loss: 0.6669663190841675, accuracy: 0.591800332069397 loss: 0.6664415597915649, accuracy: 0.591800332069397 loss: 0.6659204363822937, accuracy: 0.5935828685760498 loss: 0.6654024720191956, accuracy: 0.5935828685760498 loss: 0.6648867726325989, accuracy: 0.5935828685760498 loss: 0.664372980594635, accuracy: 0.5971479415893555 loss: 0.6638606786727905, accuracy: 0.5989304780960083 loss: 0.6633493900299072, accuracy: 0.602495551109314 loss: 0.6628386974334717, accuracy: 0.6042780876159668 loss: 0.6623283624649048, accuracy: 0.6078431606292725 loss: 0.6618180274963379, accuracy: 0.6114081740379333 loss: 0.6613075137138367, accuracy: 0.6131907105445862 loss: 0.6607966423034668, accuracy: 0.614973247051239 loss: 0.6602851748466492, accuracy: 0.6167557835578918 loss: 0.6597728729248047, accuracy: 0.6167557835578918 loss: 0.6592594981193542, accuracy: 0.614973247051239 loss: 0.6587451696395874, accuracy: 0.6167557835578918 loss: 0.6582295298576355, accuracy: 0.6167557835578918 loss: 0.6577125191688538, accuracy: 0.6185383200645447 loss: 0.6571941375732422, accuracy: 0.6185383200645447 loss: 0.6566741466522217, accuracy: 0.6185383200645447 loss: 0.6561526656150818, accuracy: 0.6221033930778503 loss: 0.6556293368339539, accuracy: 0.6238859295845032 loss: 0.6551043391227722, accuracy: 0.625668466091156 loss: 0.6545774936676025, accuracy: 0.625668466091156 loss: 0.6540487408638, accuracy: 0.6274510025978088</p> <p></p> <p>loss: 0.65351802110672, accuracy: 0.6274510025978088 loss: 0.6529853940010071, accuracy: 0.6274510025978088 loss: 0.6524505615234375, accuracy: 0.6292335391044617 loss: 0.6519137620925903, accuracy: 0.6292335391044617 loss: 0.6513748168945312, accuracy: 0.6310160160064697 loss: 0.650833785533905, accuracy: 0.6345810890197754 loss: 0.6502905488014221, accuracy: 0.6327985525131226 loss: 0.6497451663017273, accuracy: 0.6345810890197754 loss: 0.6491974592208862, accuracy: 0.638146162033081 loss: 0.6486475467681885, accuracy: 0.638146162033081 loss: 0.6480953693389893, accuracy: 0.6434937715530396 loss: 0.6475409865379333, accuracy: 0.6434937715530396 loss: 0.6469841599464417, accuracy: 0.6417112350463867 loss: 0.6464250683784485, accuracy: 0.6434937715530396 loss: 0.6458637714385986, accuracy: 0.6452763080596924 loss: 0.645300030708313, accuracy: 0.6452763080596924 loss: 0.6447339057922363, accuracy: 0.6452763080596924 loss: 0.6441654562950134, accuracy: 0.6452763080596924 loss: 0.6435947418212891, accuracy: 0.6452763080596924 loss: 0.6430215835571289, accuracy: 0.6452763080596924 loss: 0.6424461603164673, accuracy: 0.648841381072998 loss: 0.6418682932853699, accuracy: 0.6524063944816589 loss: 0.6412880420684814, accuracy: 0.6541889309883118 loss: 0.6407055258750916, accuracy: 0.6541889309883118 loss: 0.6401206254959106, accuracy: 0.6524063944816589 loss: 0.6395334601402283, accuracy: 0.6524063944816589 loss: 0.6389438509941101, accuracy: 0.6524063944816589 loss: 0.6383520364761353, accuracy: 0.6559714674949646 loss: 0.6377577781677246, accuracy: 0.6559714674949646 loss: 0.6371612548828125, accuracy: 0.6559714674949646 loss: 0.6365625858306885, accuracy: 0.6559714674949646 loss: 0.6359614133834839, accuracy: 0.6595365405082703 loss: 0.6353582143783569, accuracy: 0.6595365405082703 loss: 0.6347528100013733, accuracy: 0.6595365405082703 loss: 0.6341450214385986, accuracy: 0.6595365405082703 loss: 0.6335352063179016, accuracy: 0.6613190770149231 loss: 0.6329231262207031, accuracy: 0.6631016135215759 loss: 0.6323089599609375, accuracy: 0.6613190770149231 loss: 0.6316927075386047, accuracy: 0.6631016135215759 loss: 0.6310743093490601, accuracy: 0.6631016135215759 loss: 0.6304540038108826, accuracy: 0.6648841500282288 loss: 0.6298316717147827, accuracy: 0.6666666865348816 loss: 0.6292073130607605, accuracy: 0.6648841500282288 loss: 0.6285809278488159, accuracy: 0.6648841500282288 loss: 0.6279527544975281, accuracy: 0.6648841500282288 loss: 0.6273227334022522, accuracy: 0.6648841500282288 loss: 0.6266907453536987, accuracy: 0.6666666865348816 loss: 0.6260570287704468, accuracy: 0.6666666865348816 loss: 0.6254215836524963, accuracy: 0.6702316999435425 loss: 0.624784529209137, accuracy: 0.6720142364501953 loss: 0.6241457462310791, accuracy: 0.6702316999435425 loss: 0.6235052347183228, accuracy: 0.6737967729568481 loss: 0.6228633522987366, accuracy: 0.675579309463501 loss: 0.6222198009490967, accuracy: 0.6773618459701538 loss: 0.6215748190879822, accuracy: 0.6809269189834595 loss: 0.6209284067153931, accuracy: 0.6809269189834595 loss: 0.6202806830406189, accuracy: 0.6809269189834595 loss: 0.6196316480636597, accuracy: 0.6827094554901123 loss: 0.6189813613891602, accuracy: 0.6827094554901123 loss: 0.6183297634124756, accuracy: 0.6827094554901123 loss: 0.6176772117614746, accuracy: 0.6844919919967651 loss: 0.6170234680175781, accuracy: 0.686274528503418 loss: 0.6163687109947205, accuracy: 0.6880570650100708 loss: 0.6157130002975464, accuracy: 0.6898396015167236 loss: 0.6150563955307007, accuracy: 0.6916220784187317 loss: 0.6143988966941833, accuracy: 0.6916220784187317 loss: 0.6137406826019287, accuracy: 0.6934046149253845 loss: 0.6130816340446472, accuracy: 0.6951871514320374 loss: 0.6124221086502075, accuracy: 0.6951871514320374 loss: 0.6117619276046753, accuracy: 0.6951871514320374 loss: 0.6111010909080505, accuracy: 0.6969696879386902 loss: 0.6104399561882019, accuracy: 0.6969696879386902 loss: 0.6097782850265503, accuracy: 0.7005347609519958 loss: 0.6091163754463196, accuracy: 0.698752224445343 loss: 0.6084542870521545, accuracy: 0.7005347609519958 loss: 0.6077919602394104, accuracy: 0.698752224445343 loss: 0.6071293950080872, accuracy: 0.7005347609519958 loss: 0.6064668297767639, accuracy: 0.7005347609519958 loss: 0.6058043241500854, accuracy: 0.7040998339653015 loss: 0.6051419377326965, accuracy: 0.7040998339653015 loss: 0.6044796109199524, accuracy: 0.7040998339653015 loss: 0.6038175225257874, accuracy: 0.7040998339653015 loss: 0.6031557321548462, accuracy: 0.7058823704719543 loss: 0.6024941802024841, accuracy: 0.7076649069786072 loss: 0.601833164691925, accuracy: 0.70944744348526 loss: 0.601172685623169, accuracy: 0.70944744348526 loss: 0.6005127429962158, accuracy: 0.7112299203872681 loss: 0.5998533368110657, accuracy: 0.70944744348526 loss: 0.5991947054862976, accuracy: 0.70944744348526 loss: 0.5985367298126221, accuracy: 0.70944744348526 loss: 0.5978797078132629, accuracy: 0.7112299203872681 loss: 0.5972235202789307, accuracy: 0.7112299203872681 loss: 0.5965683460235596, accuracy: 0.7112299203872681 loss: 0.5959141254425049, accuracy: 0.70944744348526 loss: 0.5952609777450562, accuracy: 0.7147949934005737 loss: 0.5946089625358582, accuracy: 0.7147949934005737 loss: 0.5939582586288452, accuracy: 0.7112299203872681 loss: 0.593308687210083, accuracy: 0.7147949934005737 loss: 0.5926604866981506, accuracy: 0.7130124568939209 loss: 0.5920137763023376, accuracy: 0.7130124568939209</p> <p></p> <p>loss: 0.5913684368133545, accuracy: 0.7130124568939209 loss: 0.5907245874404907, accuracy: 0.7130124568939209 loss: 0.5900822281837463, accuracy: 0.7147949934005737 loss: 0.58944171667099, accuracy: 0.7183600664138794 loss: 0.5888026356697083, accuracy: 0.7147949934005737 loss: 0.5881654024124146, accuracy: 0.7147949934005737 loss: 0.5875298976898193, accuracy: 0.7147949934005737 loss: 0.5868962407112122, accuracy: 0.7147949934005737 loss: 0.5862644910812378, accuracy: 0.7147949934005737 loss: 0.5856345891952515, accuracy: 0.7147949934005737 loss: 0.5850067138671875, accuracy: 0.7147949934005737 loss: 0.5843808054924011, accuracy: 0.7147949934005737 loss: 0.5837571024894714, accuracy: 0.7147949934005737 loss: 0.5831353068351746, accuracy: 0.7147949934005737 loss: 0.5825158357620239, accuracy: 0.7165775299072266 loss: 0.5818983912467957, accuracy: 0.7147949934005737 loss: 0.5812832713127136, accuracy: 0.7147949934005737 loss: 0.5806704163551331, accuracy: 0.7147949934005737 loss: 0.5800597667694092, accuracy: 0.7165775299072266 loss: 0.5794515609741211, accuracy: 0.7165775299072266 loss: 0.5788455605506897, accuracy: 0.7165775299072266 loss: 0.5782421231269836, accuracy: 0.7165775299072266 loss: 0.577640950679779, accuracy: 0.7147949934005737 loss: 0.577042281627655, accuracy: 0.7147949934005737 loss: 0.5764461755752563, accuracy: 0.7130124568939209 loss: 0.5758525133132935, accuracy: 0.7147949934005737 loss: 0.5752614140510559, accuracy: 0.7147949934005737 loss: 0.5746727585792542, accuracy: 0.7147949934005737 loss: 0.5740866661071777, accuracy: 0.7165775299072266 loss: 0.5735033750534058, accuracy: 0.7165775299072266 loss: 0.5729224681854248, accuracy: 0.7165775299072266 loss: 0.5723443031311035, accuracy: 0.7183600664138794 loss: 0.5717687606811523, accuracy: 0.7183600664138794 loss: 0.5711959004402161, accuracy: 0.7165775299072266 loss: 0.5706256031990051, accuracy: 0.7147949934005737 loss: 0.5700580477714539, accuracy: 0.7147949934005737 loss: 0.5694931745529175, accuracy: 0.7147949934005737 loss: 0.568930983543396, accuracy: 0.7147949934005737 loss: 0.5683714747428894, accuracy: 0.7147949934005737 loss: 0.5678147077560425, accuracy: 0.7130124568939209 loss: 0.5672606229782104, accuracy: 0.7130124568939209 loss: 0.5667092204093933, accuracy: 0.7130124568939209 loss: 0.5661605596542358, accuracy: 0.7183600664138794 loss: 0.5656147003173828, accuracy: 0.7183600664138794 loss: 0.5650715231895447, accuracy: 0.7183600664138794 loss: 0.5645310282707214, accuracy: 0.7183600664138794 loss: 0.5639932155609131, accuracy: 0.7165775299072266 loss: 0.5634582042694092, accuracy: 0.7165775299072266 loss: 0.5629258155822754, accuracy: 0.7165775299072266 loss: 0.562396228313446, accuracy: 0.7165775299072266 loss: 0.5618692636489868, accuracy: 0.7147949934005737 loss: 0.5613449811935425, accuracy: 0.7147949934005737 loss: 0.5608234405517578, accuracy: 0.7147949934005737 loss: 0.5603045225143433, accuracy: 0.7147949934005737 loss: 0.5597882866859436, accuracy: 0.7165775299072266 loss: 0.5592747330665588, accuracy: 0.7165775299072266 loss: 0.5587638020515442, accuracy: 0.7147949934005737 loss: 0.5582554936408997, accuracy: 0.7165775299072266 loss: 0.5577497482299805, accuracy: 0.7165775299072266 loss: 0.5572466850280762, accuracy: 0.7165775299072266 loss: 0.5567461848258972, accuracy: 0.7147949934005737 loss: 0.5562481880187988, accuracy: 0.7147949934005737 loss: 0.5557528138160706, accuracy: 0.7147949934005737 loss: 0.5552600026130676, accuracy: 0.7147949934005737 loss: 0.55476975440979, accuracy: 0.7147949934005737 loss: 0.5542818903923035, accuracy: 0.7183600664138794 loss: 0.5537965893745422, accuracy: 0.7165775299072266 loss: 0.5533138513565063, accuracy: 0.7201426029205322 loss: 0.5528334975242615, accuracy: 0.7201426029205322 loss: 0.5523555874824524, accuracy: 0.7254902124404907 loss: 0.5518800020217896, accuracy: 0.7254902124404907 loss: 0.551406979560852, accuracy: 0.7254902124404907 loss: 0.5509361624717712, accuracy: 0.7272727489471436 loss: 0.5504679083824158, accuracy: 0.7254902124404907 loss: 0.550001859664917, accuracy: 0.7254902124404907 loss: 0.5495381951332092, accuracy: 0.7254902124404907 loss: 0.5490767955780029, accuracy: 0.7254902124404907 loss: 0.5486176609992981, accuracy: 0.7254902124404907 loss: 0.5481607913970947, accuracy: 0.7272727489471436 loss: 0.5477061867713928, accuracy: 0.7272727489471436 loss: 0.5472538471221924, accuracy: 0.7272727489471436 loss: 0.5468035936355591, accuracy: 0.7272727489471436 loss: 0.5463555455207825, accuracy: 0.7272727489471436 loss: 0.5459097027778625, accuracy: 0.7272727489471436 loss: 0.545465886592865, accuracy: 0.7272727489471436 loss: 0.5450242757797241, accuracy: 0.7272727489471436 loss: 0.5445848107337952, accuracy: 0.7272727489471436 loss: 0.544147253036499, accuracy: 0.7272727489471436 loss: 0.54371178150177, accuracy: 0.7272727489471436 loss: 0.5432783365249634, accuracy: 0.7272727489471436 loss: 0.5428469777107239, accuracy: 0.7290552854537964 loss: 0.5424174666404724, accuracy: 0.7290552854537964 loss: 0.5419899821281433, accuracy: 0.7290552854537964 loss: 0.541564404964447, accuracy: 0.7308377623558044 loss: 0.5411407351493835, accuracy: 0.7326202988624573 loss: 0.5407189726829529, accuracy: 0.7326202988624573 loss: 0.5402990579605103, accuracy: 0.7326202988624573 loss: 0.5398810505867004, accuracy: 0.7326202988624573 loss: 0.5394647121429443, accuracy: 0.7326202988624573 loss: 0.5390503406524658, accuracy: 0.7326202988624573</p> <p></p> <p>loss: 0.5386376976966858, accuracy: 0.7344028353691101 loss: 0.538226842880249, accuracy: 0.7344028353691101 loss: 0.5378177165985107, accuracy: 0.7344028353691101 loss: 0.537410318851471, accuracy: 0.7344028353691101 loss: 0.5370044708251953, accuracy: 0.7344028353691101 loss: 0.5366004705429077, accuracy: 0.7344028353691101 loss: 0.536198079586029, accuracy: 0.7344028353691101 loss: 0.5357974171638489, accuracy: 0.7344028353691101 loss: 0.5353982448577881, accuracy: 0.7361853718757629 loss: 0.535000741481781, accuracy: 0.7361853718757629 loss: 0.5346047878265381, accuracy: 0.7361853718757629 loss: 0.5342103838920593, accuracy: 0.7361853718757629 loss: 0.5338175296783447, accuracy: 0.7361853718757629 loss: 0.5334262251853943, accuracy: 0.7361853718757629 loss: 0.5330364108085632, accuracy: 0.7361853718757629 loss: 0.532647967338562, accuracy: 0.7379679083824158 loss: 0.5322611331939697, accuracy: 0.7379679083824158 loss: 0.5318756699562073, accuracy: 0.7344028353691101 loss: 0.5314916968345642, accuracy: 0.7361853718757629 loss: 0.531109094619751, accuracy: 0.7361853718757629 loss: 0.5307279229164124, accuracy: 0.7361853718757629 loss: 0.5303480625152588, accuracy: 0.7361853718757629 loss: 0.5299695730209351, accuracy: 0.7361853718757629 loss: 0.5295924544334412, accuracy: 0.7361853718757629 loss: 0.5292166471481323, accuracy: 0.7361853718757629 loss: 0.5288420915603638, accuracy: 0.7361853718757629 loss: 0.528468906879425, accuracy: 0.7361853718757629 loss: 0.5280970335006714, accuracy: 0.7361853718757629 loss: 0.5277262926101685, accuracy: 0.7361853718757629 loss: 0.5273568630218506, accuracy: 0.7344028353691101 loss: 0.5269885659217834, accuracy: 0.7344028353691101 loss: 0.5266215801239014, accuracy: 0.7361853718757629 loss: 0.5262557864189148, accuracy: 0.7361853718757629 loss: 0.5258911848068237, accuracy: 0.7361853718757629 loss: 0.5255276560783386, accuracy: 0.7379679083824158 loss: 0.5251653790473938, accuracy: 0.7397504448890686 loss: 0.5248041749000549, accuracy: 0.7379679083824158 loss: 0.524444043636322, accuracy: 0.7379679083824158 loss: 0.5240850448608398, accuracy: 0.7379679083824158 loss: 0.5237272381782532, accuracy: 0.7379679083824158 loss: 0.5233704447746277, accuracy: 0.7379679083824158 loss: 0.5230147242546082, accuracy: 0.7379679083824158 loss: 0.5226598978042603, accuracy: 0.7397504448890686 loss: 0.5223063230514526, accuracy: 0.7397504448890686 loss: 0.5219537019729614, accuracy: 0.7397504448890686 loss: 0.5216020941734314, accuracy: 0.7397504448890686 loss: 0.5212514996528625, accuracy: 0.7397504448890686 loss: 0.5209018588066101, accuracy: 0.7397504448890686 loss: 0.5205531716346741, accuracy: 0.7397504448890686 loss: 0.5202054381370544, accuracy: 0.7397504448890686 loss: 0.519858717918396, accuracy: 0.7397504448890686 loss: 0.5195128917694092, accuracy: 0.7397504448890686 loss: 0.5191680192947388, accuracy: 0.7415329813957214 loss: 0.51882404088974, accuracy: 0.7450980544090271 loss: 0.5184809565544128, accuracy: 0.7433155179023743 loss: 0.5181388258934021, accuracy: 0.7433155179023743 loss: 0.5177974700927734, accuracy: 0.7433155179023743 loss: 0.5174570083618164, accuracy: 0.7433155179023743 loss: 0.5171175003051758, accuracy: 0.7433155179023743 loss: 0.5167787671089172, accuracy: 0.7433155179023743 loss: 0.5164408683776855, accuracy: 0.7433155179023743 loss: 0.5161037445068359, accuracy: 0.7433155179023743 loss: 0.515767514705658, accuracy: 0.7433155179023743 loss: 0.5154321193695068, accuracy: 0.7450980544090271 loss: 0.515097439289093, accuracy: 0.7468805909156799 loss: 0.5147635340690613, accuracy: 0.7486631274223328 loss: 0.514430582523346, accuracy: 0.7504456043243408 loss: 0.5140981674194336, accuracy: 0.7504456043243408 loss: 0.5137667059898376, accuracy: 0.7504456043243408 loss: 0.5134359002113342, accuracy: 0.7504456043243408 loss: 0.5131058096885681, accuracy: 0.7504456043243408 loss: 0.5127764940261841, accuracy: 0.7504456043243408 loss: 0.5124478936195374, accuracy: 0.7486631274223328 loss: 0.5121200680732727, accuracy: 0.7486631274223328 loss: 0.5117928385734558, accuracy: 0.7486631274223328 loss: 0.5114663243293762, accuracy: 0.7486631274223328 loss: 0.5111406445503235, accuracy: 0.7504456043243408 loss: 0.5108155012130737, accuracy: 0.7486631274223328 loss: 0.5104910731315613, accuracy: 0.7468805909156799 loss: 0.5101673603057861, accuracy: 0.7468805909156799 loss: 0.5098442435264587, accuracy: 0.7468805909156799 loss: 0.5095217823982239, accuracy: 0.7486631274223328 loss: 0.5092000365257263, accuracy: 0.7486631274223328 loss: 0.5088788866996765, accuracy: 0.7486631274223328 loss: 0.5085583329200745, accuracy: 0.7504456043243408 loss: 0.5082384943962097, accuracy: 0.7504456043243408 loss: 0.5079192519187927, accuracy: 0.7504456043243408 loss: 0.5076005458831787, accuracy: 0.7504456043243408 loss: 0.5072824954986572, accuracy: 0.7504456043243408 loss: 0.5069650411605835, accuracy: 0.7504456043243408 loss: 0.5066481828689575, accuracy: 0.7504456043243408 loss: 0.5063318610191345, accuracy: 0.7504456043243408 loss: 0.506016194820404, accuracy: 0.7504456043243408 loss: 0.5057010650634766, accuracy: 0.7504456043243408 loss: 0.505386471748352, accuracy: 0.7504456043243408 loss: 0.5050725340843201, accuracy: 0.7522281408309937 loss: 0.5047590732574463, accuracy: 0.7540106773376465 loss: 0.5044461488723755, accuracy: 0.7557932138442993 loss: 0.5041337609291077, accuracy: 0.7557932138442993 loss: 0.5038220286369324, accuracy: 0.7557932138442993</p> <p></p> <p>loss: 0.5035106539726257, accuracy: 0.7557932138442993 loss: 0.5031999349594116, accuracy: 0.7557932138442993 loss: 0.5028897523880005, accuracy: 0.7557932138442993 loss: 0.5025800466537476, accuracy: 0.7557932138442993 loss: 0.5022708773612976, accuracy: 0.7540106773376465 loss: 0.5019621849060059, accuracy: 0.7540106773376465 loss: 0.5016539096832275, accuracy: 0.7540106773376465 loss: 0.501346230506897, accuracy: 0.7522281408309937 loss: 0.5010391473770142, accuracy: 0.7522281408309937 loss: 0.5007324814796448, accuracy: 0.7522281408309937 loss: 0.5004262328147888, accuracy: 0.7522281408309937 loss: 0.5001205205917358, accuracy: 0.7522281408309937 loss: 0.4998152554035187, accuracy: 0.7540106773376465 loss: 0.4995104670524597, accuracy: 0.7540106773376465 loss: 0.49920615553855896, accuracy: 0.7540106773376465 loss: 0.498902291059494, accuracy: 0.7540106773376465 loss: 0.4985989034175873, accuracy: 0.7540106773376465 loss: 0.49829596281051636, accuracy: 0.7540106773376465 loss: 0.49799349904060364, accuracy: 0.7522281408309937 loss: 0.49769142270088196, accuracy: 0.7522281408309937 loss: 0.49738985300064087, accuracy: 0.7522281408309937 loss: 0.4970887005329132, accuracy: 0.7522281408309937 loss: 0.49678799510002136, accuracy: 0.7540106773376465 loss: 0.49648764729499817, accuracy: 0.7540106773376465 loss: 0.49618786573410034, accuracy: 0.7540106773376465 loss: 0.49588844180107117, accuracy: 0.7540106773376465 loss: 0.4955894351005554, accuracy: 0.7540106773376465 loss: 0.4952908158302307, accuracy: 0.7540106773376465 loss: 0.494992733001709, accuracy: 0.7540106773376465 loss: 0.49469494819641113, accuracy: 0.7540106773376465 loss: 0.4943976104259491, accuracy: 0.7540106773376465 loss: 0.4941006302833557, accuracy: 0.7540106773376465 loss: 0.4938041567802429, accuracy: 0.7540106773376465 loss: 0.493507981300354, accuracy: 0.7557932138442993 loss: 0.4932122528553009, accuracy: 0.7557932138442993 loss: 0.49291694164276123, accuracy: 0.7575757503509521 loss: 0.49262192845344543, accuracy: 0.7575757503509521 loss: 0.49232742190361023, accuracy: 0.7575757503509521 loss: 0.4920332133769989, accuracy: 0.7575757503509521 loss: 0.491739422082901, accuracy: 0.7575757503509521 loss: 0.49144604802131653, accuracy: 0.759358286857605 loss: 0.4911530017852783, accuracy: 0.759358286857605 loss: 0.49086034297943115, accuracy: 0.759358286857605 loss: 0.4905681610107422, accuracy: 0.759358286857605 loss: 0.49027615785598755, accuracy: 0.759358286857605 loss: 0.4899846315383911, accuracy: 0.7611408233642578 loss: 0.4896934926509857, accuracy: 0.7611408233642578 loss: 0.4894026219844818, accuracy: 0.7611408233642578 loss: 0.4891121983528137, accuracy: 0.7611408233642578 loss: 0.4888221323490143, accuracy: 0.7611408233642578 loss: 0.4885323941707611, accuracy: 0.7611408233642578 loss: 0.48824307322502136, accuracy: 0.7611408233642578 loss: 0.4879539906978607, accuracy: 0.759358286857605 loss: 0.4876653552055359, accuracy: 0.759358286857605 loss: 0.4873770475387573, accuracy: 0.759358286857605 loss: 0.48708903789520264, accuracy: 0.7629233598709106 loss: 0.48680150508880615, accuracy: 0.7629233598709106 loss: 0.4865141212940216, accuracy: 0.7647058963775635 loss: 0.4862271547317505, accuracy: 0.7647058963775635 loss: 0.4859405755996704, accuracy: 0.7647058963775635 loss: 0.485654354095459, accuracy: 0.7647058963775635 loss: 0.48536837100982666, accuracy: 0.7647058963775635 loss: 0.4850827753543854, accuracy: 0.7647058963775635 loss: 0.48479750752449036, accuracy: 0.7647058963775635 loss: 0.4845125079154968, accuracy: 0.7664884328842163 loss: 0.4842279553413391, accuracy: 0.7647058963775635 loss: 0.4839436113834381, accuracy: 0.7647058963775635 loss: 0.48365965485572815, accuracy: 0.7664884328842163 loss: 0.48337602615356445, accuracy: 0.7664884328842163 loss: 0.483092725276947, accuracy: 0.7664884328842163 loss: 0.48280972242355347, accuracy: 0.7664884328842163 loss: 0.4825270175933838, accuracy: 0.7664884328842163 loss: 0.48224470019340515, accuracy: 0.7682709693908691 loss: 0.481962651014328, accuracy: 0.7682709693908691 loss: 0.48168089985847473, accuracy: 0.7682709693908691 loss: 0.4813995063304901, accuracy: 0.7700534462928772 loss: 0.481118381023407, accuracy: 0.7700534462928772 loss: 0.4808375835418701, accuracy: 0.7682709693908691 loss: 0.48055708408355713, accuracy: 0.7682709693908691 loss: 0.48027682304382324, accuracy: 0.7700534462928772 loss: 0.4799969494342804, accuracy: 0.7700534462928772 loss: 0.47971734404563904, accuracy: 0.77183598279953 loss: 0.4794381260871887, accuracy: 0.7736185193061829 loss: 0.4791591167449951, accuracy: 0.7736185193061829 loss: 0.4788804352283478, accuracy: 0.7736185193061829 loss: 0.4786020517349243, accuracy: 0.7736185193061829 loss: 0.47832396626472473, accuracy: 0.7754010558128357 loss: 0.478046178817749, accuracy: 0.7754010558128357 loss: 0.4777686893939972, accuracy: 0.7754010558128357 loss: 0.4774914085865021, accuracy: 0.7754010558128357 loss: 0.4772144556045532, accuracy: 0.7754010558128357 loss: 0.4769378900527954, accuracy: 0.7736185193061829 loss: 0.4766616225242615, accuracy: 0.7754010558128357 loss: 0.4763854742050171, accuracy: 0.7754010558128357 loss: 0.4761098027229309, accuracy: 0.7754010558128357 loss: 0.47583428025245667, accuracy: 0.7754010558128357 loss: 0.4755590558052063, accuracy: 0.7754010558128357 loss: 0.4752841889858246, accuracy: 0.7754010558128357 loss: 0.47500959038734436, accuracy: 0.7754010558128357 loss: 0.4747351408004761, accuracy: 0.7754010558128357</p>"},{"location":"projects/tp_gnn/#visualisation-des-embeddings-calcules","title":"Visualisation des embeddings calcul\u00e9s","text":"<pre><code>visualize_emb(emb)\n</code></pre> Output"},{"location":"services/documentation/","title":"Services","text":"<p>Creation of professional documentation</p> <p>If you are a PhD student, researcher or scientist and you want to <code>document your projects in a professional way</code> then I congratulate you because you are in the right place, you just need to contact me and your documentations will be ready in 2 days :</p> <ul> <li><code>abdellatif.belmady@gmail.com</code></li> <li>My phone number : (+212)6 41 49 86 81</li> </ul> <p>For those interested, please visit my latest documentations :</p> <ul> <li> <p> Boston Datasets : https://abdellatif-belmady.github.io/Boston-documentation/</p> </li> <li> <p> Mini Project : https://abdellatif-belmady.github.io/Mini-Project/</p> </li> <li> <p> Big Data Project : https://abdellatif-belmady.github.io/Project_Big-Data_documentation/</p> </li> <li> <p> Others Projects : https://abdellatif-belmady.github.io/abdellatif-belmady/projects/spam%20datasets/</p> </li> </ul>"}]}